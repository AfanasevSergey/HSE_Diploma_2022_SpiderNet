{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing, GridSearch and Training DenseNet-8 on Open data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import math\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.pyplot import cm\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import collections\n",
    "from collections import OrderedDict, Counter\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import normaltest, kstest, ttest_ind, ttest_rel, mannwhitneyu, wilcoxon, levene, bartlett\n",
    "from scipy.stats import chi2_contingency, fisher_exact, mode, pearsonr, f_oneway, kruskal, spearmanr\n",
    "\n",
    "from rfpimp import *\n",
    "\n",
    "from datetime import datetime\n",
    "import re\n",
    "from seaborn import heatmap\n",
    "import random\n",
    "import statsmodels.distributions.empirical_distribution as edf\n",
    "from scipy.interpolate import interp1d\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from functools import reduce\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n",
    "\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, log_loss, recall_score\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler, PowerTransformer\n",
    "\n",
    "from sklearn.utils import check_consistent_length, column_or_1d, assert_all_finite\n",
    "from sklearn.utils.extmath import stable_cumsum\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import gc\n",
    "import os\n",
    "\n",
    "#from sklearn.externals import joblib\n",
    "import joblib\n",
    "\n",
    "from importlib import reload\n",
    "import Filter_and_Grid_Search\n",
    "Filter_and_Grid_Search = reload(Filter_and_Grid_Search)\n",
    "from Filter_and_Grid_Search import stratified_split\n",
    "from Filter_and_Grid_Search import attributes_list, attributes_list_new\n",
    "from Filter_and_Grid_Search import get_s_stat, get_PSI_stat, get_stats_by_month, get_stats, stable_unstable\n",
    "from Filter_and_Grid_Search import stable_unstable_by_month_divide, union_datas, individual_hists_all \n",
    "from Filter_and_Grid_Search import paired_time_hists_by_month, statistics_with_target\n",
    "from Filter_and_Grid_Search import receive_correlations, find_doubles_corr\n",
    "from Filter_and_Grid_Search import statistics_with_target, attributes_list, attributes_list_new, make_standard\n",
    "from Filter_and_Grid_Search import data_preprocessing_train, data_preprocessing_test\n",
    "from Filter_and_Grid_Search import receive_correlations, find_doubles_corr\n",
    "from Filter_and_Grid_Search import stratified_split, two_forests, turn_variables_with_values\n",
    "from Filter_and_Grid_Search import find_meta_params, calculate_vif#, find_meta_params_mem\n",
    "from Filter_and_Grid_Search import plot_meta_2d, data_preprocessing, find_ouliers_iqr\n",
    "from Filter_and_Grid_Search import train_model_receive_stats, simple_b_score_risk\n",
    "from Filter_and_Grid_Search import max_prof_corve, by_month_gini, check_attribute_list_cases\n",
    "\n",
    "from Filter_and_Grid_Search import to_zip, br_correction, br_stat\n",
    "\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import pathlib\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'D:/Share/safanasev/Python-notebook/AF_ML_chinese/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'LABEL'\n",
    "index_month = 'MONTH'\n",
    "list_of_vars_for_strat = ['MONTH']\n",
    "sort_by_var = 'ID'\n",
    "\n",
    "necessary_fields = [target, index_month, sort_by_var]\n",
    "\n",
    "COL_DEL = ['Unnamed: 0'] \n",
    "COL_DEL = [x.upper() for x in COL_DEL]\n",
    "COL_TRG = target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_for = pd.read_csv(PATH + 'china_train_128_prep.csv')\n",
    "valid_for = pd.read_csv(PATH + 'china_val_128_prep.csv')\n",
    "test_for = pd.read_csv(PATH + 'china_test_128_prep.csv')\n",
    "\n",
    "\n",
    "y_train = train_for[target]\n",
    "y_test = valid_for[target]\n",
    "y_val = test_for[target]\n",
    "\n",
    "train_for.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "valid_for.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "test_for.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "col = train_for.columns.to_list()\n",
    "col.remove(target)\n",
    "\n",
    "\n",
    "X_1_2 = train_for[col]\n",
    "X_2_2 = valid_for[col]\n",
    "X_3_2 = test_for[col]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col = X_2_2.columns\n",
    "y_col = 'LABEL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((792004, 128), (792004, 129), 792004)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#проверка корректности\n",
    "X_1_2.shape, train_for.shape, len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#проверка корректности, должно быть везде True\n",
    "print(X_1_2.shape[0] == train_for.shape[0])\n",
    "print(X_1_2.shape[1] == train_for.shape[1] - 1)\n",
    "print(len(y_train) == train_for.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (Input, Activation, Dense, Flatten, Dropout)\n",
    "from tensorflow.keras.layers import (Conv1D, MaxPooling1D, AveragePooling1D)\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import ReLU, Concatenate, GlobalAveragePooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задаем seed_value для воспроизводимости\n",
    "# Можно использовать разные seed_value для разных систем\n",
    "seed_value= 29\n",
    "\n",
    "\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.set_random_seed(seed_value)\n",
    "\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "# for later versions:\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, Callback, LearningRateScheduler\n",
    "\n",
    "# объявляем класс метрик\n",
    "\n",
    "class E_time(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        tm = datetime.strftime(datetime.now(), \"%d.%m.%Y %H:%M:%S\")\n",
    "        print ('train_begin', '| time: ' , tm)\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        tm = datetime.strftime(datetime.now(), \"%d.%m.%Y %H:%M:%S\")\n",
    "        print ('epoch_end', '| time: ' , tm)\n",
    "    \n",
    "        return\n",
    "\n",
    "_time = E_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#если alpha не задано, то не делаем br_correction\n",
    "\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self,  dataset, x_col, y_col,  batch_size=256, num_classes=2, alpha = 0.1, random_state = 42, \n",
    "                 shuffle=True, class_w = None):\n",
    "        self.batch_size = batch_size\n",
    "        self.dataset = dataset\n",
    "        self.x_col = x_col\n",
    "        self.y_col = y_col\n",
    "        self.indices = self.dataset.index.tolist()\n",
    "        self.num_classes = num_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.alpha = alpha\n",
    "        self.random_state = random_state\n",
    "        self.class_w = class_w\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.indices) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        index = self.index[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch = [self.indices[k] for k in index]\n",
    "        \n",
    "        data_tmp = self.dataset.loc[batch]\n",
    "        data_tmp_b = data_tmp[data_tmp[self.y_col] == 1]\n",
    "        data_tmp_b_all = self.dataset[self.dataset[self.y_col] == 1]\n",
    "        X_tmp = data_tmp.head(0)\n",
    "        \n",
    "        \n",
    "        #print(data_tmp_b.shape[0], data_tmp.shape[0], data_tmp_b_all.shape[0])\n",
    "        if (self.alpha is None) and (self.class_w is None):\n",
    "            X = data_tmp[self.x_col] #.reshape(-1)\n",
    "            y = data_tmp[self.y_col] \n",
    "            \n",
    "        elif (self.alpha is None) and self.class_w > 0:\n",
    "            k = (self.class_w*self.batch_size)/(1-self.class_w)\n",
    "            k = k - data_tmp_b.shape[0]\n",
    "            if int(k) < 1:\n",
    "                k = k+1\n",
    "            ix2 = np.random.RandomState(self.random_state + int(k)).choice(data_tmp_b_all.shape[0], int(k))\n",
    "            X_tmp = data_tmp_b_all.iloc[ix2]\n",
    "            data_tmp = data_tmp.append(X_tmp, ignore_index=True)\n",
    "            X = data_tmp[self.x_col] #.reshape(-1)\n",
    "            y = data_tmp[self.y_col]\n",
    "            #print(data_tmp_b.shape[0], data_tmp.shape[0],  data_tmp_b.shape[0]/(data_tmp.shape[0] - X_tmp.shape[0]), np.mean(y)) \n",
    "            \n",
    "            \n",
    "            \n",
    "        else:\n",
    "            if data_tmp_b.shape[0] > 0:\n",
    "                k=(self.alpha*self.batch_size/data_tmp_b.shape[0] -1 )/(1-self.alpha)\n",
    "                for i in range(0,int(k)):\n",
    "                    X_tmp = X_tmp.append(data_tmp_b, ignore_index=True)\n",
    "            else:\n",
    "                k = (self.alpha*self.batch_size)/(1-self.alpha)\n",
    "                ix2 = np.random.RandomState(self.random_state + int(k)).choice(data_tmp_b_all.shape[0], int(k))\n",
    "                X_tmp = data_tmp_b_all.iloc[ix2]\n",
    "                data_tmp_b = X_tmp\n",
    "\n",
    "    #         print('Добавим дробное число строк')    \n",
    "            k_fraction = k - int(k)\n",
    "            n_samples = int(round(data_tmp_b.shape[0]*k_fraction))\n",
    "    #         print(k_fraction, n_samples)\n",
    "\n",
    "            ix = np.random.RandomState(self.random_state).choice(data_tmp_b.shape[0], n_samples)\n",
    "            data_add_fraction = data_tmp_b.iloc[ix]\n",
    "            X_tmp.append(data_add_fraction, ignore_index=True)\n",
    "\n",
    "            data_tmp = data_tmp.append(X_tmp, ignore_index=True)\n",
    "\n",
    "\n",
    "            X = data_tmp[self.x_col] #.reshape(-1)\n",
    "            y = data_tmp[self.y_col]   \n",
    "        \n",
    "        if self.num_classes > 1:\n",
    "            y = np_utils.to_categorical( y, self.num_classes)\n",
    "            \n",
    "        return [np.array(X)], np.array(y)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.index = np.arange(len(self.indices))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# здесь батчсайз надо указывать тот, который получился по гридсерч сетке\n",
    "training_generator = DataGenerator(train_for, x_col, y_col, batch_size=512, alpha = None, class_w = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_2 = np_utils.to_categorical(y_test, 2) # преобразовываем в 2 класса "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012246150271968324"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_train)/y_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet-8 (1D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, Conv1D, Concatenate, AveragePooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функции для 1D-DenseNet\n",
    "# надо по гридсерч сетке подобрать параметры:\n",
    "# 1) k (количетсво фильтров): сделать параметры адекватные для 1D (по умолчанию стоят от 2D)\n",
    "# 2) kernel_width (размер фильтра/свертки): сделать параметры адекватные для 1D (по умолчанию стоят от 2D)\n",
    "# 3) bottleneck_size - это мультпликатор для кол-ва фильтров k.\n",
    "# 4) num_layers - количество сверток в денз-блоке (нужно 3 и 4 - соотвествует спайдеру/2)\n",
    "\n",
    "\"\"\" \n",
    "blocks/one_d.py\n",
    "Author: Ankit Gupta\n",
    "\n",
    "Implementations of various DenseNet blocks for 1D sequences\n",
    "\n",
    "This module contains helper functions that define the various subcomponents of a DenseNet. \n",
    "This includes dense blocks and transition blocks.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#from tf.keras.layers import BatchNormalization, Activation, Conv1D, Concatenate, AveragePooling1D\n",
    "\n",
    "\n",
    "def H_l(k, bottleneck_size, kernel_width):\n",
    "    \"\"\" \n",
    "    A single convolutional \"layer\" as defined by Huang et al. Defined as H_l in the original paper\n",
    "    \n",
    "    :param k: int representing the \"growth rate\" of the DenseNet\n",
    "    :param bottleneck_size: int representing the size of the bottleneck, as a multiple of k. \n",
    "    Set to 0 for no bottleneck.\n",
    "    :param kernel_width: int representing the width of the main convolutional kernel\n",
    "    :return a function wrapping the keras layers for H_l\n",
    "    \"\"\"\n",
    "\n",
    "    use_bottleneck = bottleneck_size > 0\n",
    "    num_bottleneck_output_filters = k * bottleneck_size\n",
    "\n",
    "    def f(x):\n",
    "        if use_bottleneck:\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Activation(\"relu\")(x)\n",
    "            x = Conv1D(\n",
    "                num_bottleneck_output_filters,\n",
    "                1,\n",
    "                strides=1,\n",
    "                padding=\"same\",\n",
    "                dilation_rate=1)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Conv1D(\n",
    "            k,\n",
    "            kernel_width,\n",
    "            strides=1,\n",
    "            padding=\"same\",\n",
    "            dilation_rate=1)(x)\n",
    "        return x\n",
    "    return f\n",
    "\n",
    "\n",
    "def dense_block(k, num_layers, kernel_width, bottleneck_size):\n",
    "    \"\"\"\n",
    "    A single dense block of the DenseNet\n",
    "    \n",
    "    :param k: int representing the \"growth rate\" of the DenseNet\n",
    "    :param num_layers: int represending the number of layers in the block\n",
    "    :param kernel_width: int representing the width of the main convolutional kernel\n",
    "    :param bottleneck_size: int representing the size of the bottleneck, as a multiple of k. Set to 0 for no bottleneck.\n",
    "    :return a function wrapping the entire dense block\n",
    "    \"\"\"\n",
    "    def f(x):\n",
    "        layers_to_concat = [x]\n",
    "        for _ in range(num_layers):\n",
    "            x = H_l(k, bottleneck_size, kernel_width)(x)\n",
    "            layers_to_concat.append(x)\n",
    "            x = Concatenate(axis=-1)(layers_to_concat)\n",
    "        return x\n",
    "    return f\n",
    "\n",
    "\n",
    "def transition_block(pool_size=2, stride=2, theta=0.5):\n",
    "    \"\"\"\n",
    "    A single transition block of the DenseNet\n",
    "    \n",
    "    :param pool_size: int represending the width of the average pool\n",
    "    :param stride: int represending the stride of the average pool\n",
    "    :param theta: int representing the amount of compression in the 1x1 convolution. Set to 1 for no compression.\n",
    "    :return a function wrapping the entire transition block\n",
    "    \"\"\"    \n",
    "    assert theta > 0 and theta <= 1\n",
    "\n",
    "    def f(x):\n",
    "        num_transition_output_filters = int(int(x.shape[2]) * float(theta))\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = Conv1D(\n",
    "            num_transition_output_filters,\n",
    "            1,\n",
    "            strides=1,\n",
    "            padding=\"same\",\n",
    "            dilation_rate=1)(x)\n",
    "        x = AveragePooling1D(\n",
    "            pool_size=pool_size,\n",
    "            strides=stride,\n",
    "            padding=\"same\")(x)\n",
    "        return x\n",
    "    return f\n",
    "\n",
    "\n",
    "def DenseNet_1(\n",
    "        k,\n",
    "        block_sizes,\n",
    "        conv_kernel_width,\n",
    "        bottleneck_size,\n",
    "        transition_pool_size,\n",
    "        transition_pool_stride,\n",
    "        theta,\n",
    "        initial_conv_width,\n",
    "        initial_stride,\n",
    "        initial_filters,\n",
    "        initial_pool_width,\n",
    "        initial_pool_stride,\n",
    "        use_global_pooling):\n",
    "    def f(x):\n",
    "        x = Conv1D(\n",
    "            initial_filters,\n",
    "            initial_conv_width,\n",
    "            strides=initial_stride,\n",
    "            padding=\"same\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = MaxPooling1D(\n",
    "            pool_size=initial_pool_width,\n",
    "            strides=initial_pool_stride,\n",
    "            padding=\"same\")(x)\n",
    "\n",
    "        # Add all but the last dense block\n",
    "        for block_size in block_sizes[:-1]:\n",
    "            x = dense_block(\n",
    "                k,\n",
    "                block_size,\n",
    "                conv_kernel_width,\n",
    "                bottleneck_size)(x)\n",
    "            x = transition_block(\n",
    "                pool_size=transition_pool_size,\n",
    "                stride=transition_pool_stride,\n",
    "                theta=theta)(x)\n",
    "\n",
    "        # Add the last dense block\n",
    "        final_block_size = block_sizes[-1]\n",
    "        x = dense_block(\n",
    "            k,\n",
    "            final_block_size,\n",
    "            conv_kernel_width,\n",
    "            bottleneck_size)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        if use_global_pooling:\n",
    "            x = GlobalAveragePooling1D()(x)\n",
    "        return x\n",
    "    return f\n",
    "\n",
    "\n",
    "\n",
    "class DenseNetCustom(tensorflow.keras.models.Model):\n",
    "    \"\"\"  \n",
    "    Create a Keras Model Object that is an implementation of DenseNet with a custom number of parameters. The number of layers \n",
    "    per dense block can be specified by block_sizes.\n",
    "    :param input_shape: The shape of the inputs without the batch dimension. This should be a valid 1D sequence, \n",
    "    such as (244, 25). \n",
    "    :param num_outputs: the number of classes to predict\n",
    "    :param k: The \"growth rate\" of the DenseNet model\n",
    "    :param block_sizes: A list of ints with the number of layers in each block. Example: [5, 10, 25, 17].\n",
    "    :param conv_kernel_width: The kernel width of each convolution in the dense blocks.\n",
    "    :param bottleneck_size: The size of the bottleneck, as a multiple of k. Set to 0 for no bottleneck.\n",
    "    :param transition_pool_size: pool_size in the transition layer\n",
    "    :param transition_pool_stride: pooling stride in the transition layer\n",
    "    :param theta: Amount of compression in the transition layer. Set to 1 for no compression.\n",
    "    :param initial_conv_width: Kernel width for the one convolution before the dense blocks\n",
    "    :param initial_stride: Stride for the one convolution before the dense blocks\n",
    "    :param initial_filters: Number of filters for the one convolution before the dense blocks\n",
    "    :param initial_pool_width: pool_size for the one pooling before the dense blocks\n",
    "    :param initial_pool_stride: stride for the one pooling before the dense blocks \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_shape,\n",
    "            num_outputs=1000,  # здесь нужно 2 (1000 классов - это из ImageNet)\n",
    "            k=32,  # количество фильтров нужно 5-10\n",
    "            block_sizes=None,\n",
    "            conv_kernel_width=3,  # размер фильтра нужно 5 (можно подобрать). 3х3 - это из 2D взяли.\n",
    "            bottleneck_size=4,  # этот мультипликатор для k лучше взять 2-3(общая формула Х = initial_filters + k * bottleneck_size (k={0,n}))\n",
    "            transition_pool_size=2,\n",
    "            transition_pool_stride=2, # здесь лучше поставить страйд = 1 (2 - из 2D)\n",
    "            theta=0.5, # это параметр для баттлнек сверток 1х1, мб настроить парочку из списка: {0.4, 0.5, 0.6, 1}\n",
    "            initial_conv_width=7,  # здесь лучше поставить 5 (7 - для 2D)\n",
    "            initial_stride=2, # здесь лучше 1 взять (2 - из 2D)\n",
    "            initial_filters=64,  # количество фильтров лучше взять 10-20 (64 - из 2D)\n",
    "            initial_pool_width=3, # этот пулинг лучше 2 взять (3 - из 2D)\n",
    "            initial_pool_stride=2):  # здесь лучше поставить страйд = 1, а то размерность будет быстро уменьшаться\n",
    "        if not block_sizes:\n",
    "            raise ValueError(\"block_sizes must be specified\")\n",
    "        model_input = Input(shape=input_shape)\n",
    "        output = DenseNet_1(\n",
    "            k,\n",
    "            block_sizes,\n",
    "            conv_kernel_width,\n",
    "            bottleneck_size,\n",
    "            transition_pool_size,\n",
    "            transition_pool_stride,\n",
    "            theta,\n",
    "            initial_conv_width,\n",
    "            initial_stride,\n",
    "            initial_filters,\n",
    "            initial_pool_width,\n",
    "            initial_pool_stride,\n",
    "            use_global_pooling=True)(model_input)\n",
    "        output = Dense(num_outputs, activation=\"softmax\")(output)\n",
    "        super(DenseNetCustom, self).__init__(model_input, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Гридсерч сетку настроить:\n",
    "# k = {5, 10}\n",
    "# initial_filters = {5, 10}, # количество фильтров лучше взять 5-10-20 (64 - из 2D)\n",
    "# block_sizes = [3, 3] - для Spider-6; [4, 4] - для Spider-8\n",
    "# conv_kernel_width = w, где for w in [5, 6] \n",
    "# bottleneck_size=2, лучше взять 2-3(общая формула Х = initial_filters + k * bottleneck_size (k={0,n}))\n",
    "# transition_pool_size=2,\n",
    "# transition_pool_stride=2, # здесь лучше поставить страйд = 1 (2 - из 2D)\n",
    "# theta=0.5, # это параметр для баттлнек сверток 1х1, мб настроить парочку из списка: {0.4, 0.5, 0.6, 1}\n",
    "# initial_conv_width=5,  # здесь лучше поставить 5 (7 - для 2D)\n",
    "# initial_stride=2, # здесь лучше 1 взять (2 - из 2D)\n",
    "# initial_pool_width=3, # этот пулинг лучше 2 взять (3 - из 2D)\n",
    "# initial_pool_stride=2  # здесь лучше поставить страйд = 1, а то размерность будет быстро уменьшаться\n",
    "\n",
    "\n",
    "n_features = 128\n",
    "model_dense = DenseNetCustom(input_shape = (n_features, 1),\n",
    "                             num_outputs=2,\n",
    "                             block_sizes= [3, 3],\n",
    "                             initial_filters=5,\n",
    "                             k=10, \n",
    "                             conv_kernel_width=5,\n",
    "                             bottleneck_size=2,\n",
    "                             transition_pool_stride=1,\n",
    "                             theta=0.5,\n",
    "                             initial_conv_width=5,\n",
    "                             initial_stride=1,\n",
    "                             initial_pool_width=2,\n",
    "                             initial_pool_stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dense_net_custom\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 128, 5)       30          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 128, 5)       20          conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 128, 5)       0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 64, 5)        0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 5)        20          max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 5)        0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 64, 20)       120         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64, 20)       80          conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 20)       0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 64, 10)       1010        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64, 15)       0           max_pooling1d[0][0]              \n",
      "                                                                 conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 15)       60          concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 64, 15)       0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 64, 20)       320         activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 20)       80          conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 64, 20)       0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 64, 10)       1010        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 25)       0           max_pooling1d[0][0]              \n",
      "                                                                 conv1d_2[0][0]                   \n",
      "                                                                 conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 25)       100         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 64, 25)       0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 64, 20)       520         activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 20)       80          conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 20)       0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 64, 10)       1010        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 35)       0           max_pooling1d[0][0]              \n",
      "                                                                 conv1d_2[0][0]                   \n",
      "                                                                 conv1d_4[0][0]                   \n",
      "                                                                 conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 35)       140         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 35)       0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 64, 17)       612         activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d (AveragePooli (None, 64, 17)       0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 64, 17)       68          average_pooling1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, 17)       0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 64, 20)       360         activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 64, 20)       80          conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 64, 20)       0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 64, 10)       1010        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 64, 27)       0           average_pooling1d[0][0]          \n",
      "                                                                 conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 64, 27)       108         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 64, 27)       0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 64, 20)       560         activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64, 20)       80          conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 64, 20)       0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 64, 10)       1010        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 64, 37)       0           average_pooling1d[0][0]          \n",
      "                                                                 conv1d_9[0][0]                   \n",
      "                                                                 conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 37)       148         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 37)       0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 64, 20)       760         activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 20)       80          conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 20)       0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 64, 10)       1010        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 64, 47)       0           average_pooling1d[0][0]          \n",
      "                                                                 conv1d_9[0][0]                   \n",
      "                                                                 conv1d_11[0][0]                  \n",
      "                                                                 conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 64, 47)       188         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 64, 47)       0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 47)           0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2)            96          global_average_pooling1d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 10,770\n",
      "Trainable params: 10,104\n",
      "Non-trainable params: 666\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_dense.compile(loss='categorical_crossentropy', #optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
    "                 optimizer=tf.keras.optimizers.Adam(learning_rate=0.005),\n",
    "              #optimizer='adam', \n",
    "              metrics=['accuracy', tf.keras.metrics.AUC(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "model_dense.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:\\\\Program Files (x86)\\\\Graphviz2.38\\\\bin\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# здесь батчсайз и class_w надо указывать тот, который получился по гридсерч сетке\n",
    "training_generator = DataGenerator(train_for, x_col, y_col, batch_size=512, alpha = None, class_w = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# anealing - снижение ленингрэйта (на Спайдере не дает доп.эффекта)\n",
    "#learning_rate=0.005\n",
    "initial_learning_rate = 0.05\n",
    "\n",
    "def lr_step_decay(epoch, lr):\n",
    "    drop_rate = 0.2\n",
    "    epochs_drop = 20.0\n",
    "    \n",
    "    return initial_learning_rate * math.pow(drop_rate, math.floor(epoch/epochs_drop))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch for DenseNet-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_begin | time:  12.04.2021 15:50:27\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 163, 1) for input Tensor(\"input_2:0\", shape=(None, 163, 1), dtype=float32), but it was called on an input with incompatible shape (None, 128, 1).\n",
      "epoch_end | time:  12.04.2021 16:06:28\n",
      "1547/1547 - 956s - loss: 0.0330 - accuracy: 0.9285 - auc_1: 0.9773 - precision_1: 0.9285 - recall_1: 0.9285 - val_loss: 0.2182 - val_accuracy: 0.9270 - val_auc_1: 0.9756 - val_precision_1: 0.9270 - val_recall_1: 0.9270\n",
      "Epoch 2/100\n",
      "epoch_end | time:  12.04.2021 16:21:18\n",
      "1547/1547 - 890s - loss: 0.0231 - accuracy: 0.9568 - auc_1: 0.9878 - precision_1: 0.9568 - recall_1: 0.9568 - val_loss: 0.1318 - val_accuracy: 0.9563 - val_auc_1: 0.9881 - val_precision_1: 0.9563 - val_recall_1: 0.9563\n",
      "Epoch 3/100\n",
      "epoch_end | time:  12.04.2021 16:34:28\n",
      "1547/1547 - 789s - loss: 0.0211 - accuracy: 0.9618 - auc_1: 0.9896 - precision_1: 0.9618 - recall_1: 0.9618 - val_loss: 0.0736 - val_accuracy: 0.9766 - val_auc_1: 0.9955 - val_precision_1: 0.9766 - val_recall_1: 0.9766\n",
      "Epoch 4/100\n",
      "epoch_end | time:  12.04.2021 16:49:41\n",
      "1547/1547 - 912s - loss: 0.0200 - accuracy: 0.9641 - auc_1: 0.9906 - precision_1: 0.9641 - recall_1: 0.9641 - val_loss: 0.0831 - val_accuracy: 0.9721 - val_auc_1: 0.9948 - val_precision_1: 0.9721 - val_recall_1: 0.9721\n",
      "Epoch 5/100\n",
      "epoch_end | time:  12.04.2021 17:03:22\n",
      "1547/1547 - 821s - loss: 0.0194 - accuracy: 0.9660 - auc_1: 0.9912 - precision_1: 0.9660 - recall_1: 0.9660 - val_loss: 0.0681 - val_accuracy: 0.9790 - val_auc_1: 0.9957 - val_precision_1: 0.9790 - val_recall_1: 0.9790\n",
      "Epoch 6/100\n",
      "epoch_end | time:  12.04.2021 17:16:23\n",
      "1547/1547 - 780s - loss: 0.0189 - accuracy: 0.9670 - auc_1: 0.9914 - precision_1: 0.9670 - recall_1: 0.9670 - val_loss: 0.1508 - val_accuracy: 0.9492 - val_auc_1: 0.9856 - val_precision_1: 0.9492 - val_recall_1: 0.9492\n",
      "Epoch 7/100\n",
      "epoch_end | time:  12.04.2021 17:29:07\n",
      "1547/1547 - 764s - loss: 0.0183 - accuracy: 0.9683 - auc_1: 0.9920 - precision_1: 0.9683 - recall_1: 0.9683 - val_loss: 0.1387 - val_accuracy: 0.9556 - val_auc_1: 0.9866 - val_precision_1: 0.9556 - val_recall_1: 0.9556\n",
      "Epoch 8/100\n",
      "epoch_end | time:  12.04.2021 17:44:45\n",
      "1547/1547 - 937s - loss: 0.0179 - accuracy: 0.9691 - auc_1: 0.9923 - precision_1: 0.9691 - recall_1: 0.9691 - val_loss: 0.0966 - val_accuracy: 0.9699 - val_auc_1: 0.9931 - val_precision_1: 0.9699 - val_recall_1: 0.9699\n",
      "Epoch 9/100\n",
      "epoch_end | time:  12.04.2021 18:01:34\n",
      "1547/1547 - 1008s - loss: 0.0176 - accuracy: 0.9699 - auc_1: 0.9926 - precision_1: 0.9699 - recall_1: 0.9699 - val_loss: 0.2025 - val_accuracy: 0.9332 - val_auc_1: 0.9750 - val_precision_1: 0.9332 - val_recall_1: 0.9332\n",
      "Epoch 10/100\n",
      "epoch_end | time:  12.04.2021 18:15:19\n",
      "1547/1547 - 824s - loss: 0.0171 - accuracy: 0.9705 - auc_1: 0.9929 - precision_1: 0.9705 - recall_1: 0.9705 - val_loss: 0.1276 - val_accuracy: 0.9592 - val_auc_1: 0.9880 - val_precision_1: 0.9592 - val_recall_1: 0.9592\n",
      "Epoch 11/100\n",
      "epoch_end | time:  12.04.2021 18:29:55\n",
      "1547/1547 - 875s - loss: 0.0171 - accuracy: 0.9709 - auc_1: 0.9930 - precision_1: 0.9709 - recall_1: 0.9709 - val_loss: 0.0992 - val_accuracy: 0.9685 - val_auc_1: 0.9923 - val_precision_1: 0.9685 - val_recall_1: 0.9685\n",
      "Epoch 12/100\n",
      "epoch_end | time:  12.04.2021 18:44:22\n",
      "1547/1547 - 867s - loss: 0.0168 - accuracy: 0.9717 - auc_1: 0.9932 - precision_1: 0.9717 - recall_1: 0.9717 - val_loss: 0.3279 - val_accuracy: 0.8941 - val_auc_1: 0.9431 - val_precision_1: 0.8941 - val_recall_1: 0.8941\n",
      "Epoch 13/100\n",
      "epoch_end | time:  12.04.2021 18:59:41\n",
      "1547/1547 - 918s - loss: 0.0164 - accuracy: 0.9728 - auc_1: 0.9935 - precision_1: 0.9728 - recall_1: 0.9728 - val_loss: 0.0622 - val_accuracy: 0.9804 - val_auc_1: 0.9964 - val_precision_1: 0.9804 - val_recall_1: 0.9804\n",
      "Epoch 14/100\n",
      "epoch_end | time:  12.04.2021 19:13:51\n",
      "1547/1547 - 849s - loss: 0.0164 - accuracy: 0.9722 - auc_1: 0.9935 - precision_1: 0.9722 - recall_1: 0.9722 - val_loss: 0.0568 - val_accuracy: 0.9826 - val_auc_1: 0.9969 - val_precision_1: 0.9826 - val_recall_1: 0.9826\n",
      "Epoch 15/100\n",
      "epoch_end | time:  12.04.2021 19:26:42\n",
      "1547/1547 - 769s - loss: 0.0161 - accuracy: 0.9731 - auc_1: 0.9937 - precision_1: 0.9731 - recall_1: 0.9731 - val_loss: 0.2471 - val_accuracy: 0.9212 - val_auc_1: 0.9656 - val_precision_1: 0.9212 - val_recall_1: 0.9212\n",
      "Epoch 16/100\n",
      "epoch_end | time:  12.04.2021 19:39:39\n",
      "1547/1547 - 776s - loss: 0.0159 - accuracy: 0.9734 - auc_1: 0.9939 - precision_1: 0.9734 - recall_1: 0.9734 - val_loss: 0.1029 - val_accuracy: 0.9672 - val_auc_1: 0.9919 - val_precision_1: 0.9672 - val_recall_1: 0.9672\n",
      "Epoch 17/100\n",
      "epoch_end | time:  12.04.2021 19:52:20\n",
      "1547/1547 - 761s - loss: 0.0159 - accuracy: 0.9732 - auc_1: 0.9938 - precision_1: 0.9732 - recall_1: 0.9732 - val_loss: 0.0584 - val_accuracy: 0.9816 - val_auc_1: 0.9970 - val_precision_1: 0.9816 - val_recall_1: 0.9816\n",
      "Epoch 18/100\n",
      "epoch_end | time:  12.04.2021 20:05:09\n",
      "1547/1547 - 768s - loss: 0.0157 - accuracy: 0.9739 - auc_1: 0.9940 - precision_1: 0.9739 - recall_1: 0.9739 - val_loss: 0.1148 - val_accuracy: 0.9637 - val_auc_1: 0.9901 - val_precision_1: 0.9637 - val_recall_1: 0.9637\n",
      "Epoch 19/100\n",
      "epoch_end | time:  12.04.2021 20:17:12\n",
      "1547/1547 - 723s - loss: 0.0157 - accuracy: 0.9739 - auc_1: 0.9941 - precision_1: 0.9739 - recall_1: 0.9739 - val_loss: 0.0846 - val_accuracy: 0.9734 - val_auc_1: 0.9943 - val_precision_1: 0.9734 - val_recall_1: 0.9734\n",
      "Epoch 20/100\n",
      "epoch_end | time:  12.04.2021 20:29:17\n",
      "1547/1547 - 725s - loss: 0.0154 - accuracy: 0.9744 - auc_1: 0.9943 - precision_1: 0.9744 - recall_1: 0.9744 - val_loss: 0.0884 - val_accuracy: 0.9719 - val_auc_1: 0.9939 - val_precision_1: 0.9719 - val_recall_1: 0.9719\n",
      "Epoch 21/100\n",
      "epoch_end | time:  12.04.2021 20:41:20\n",
      "1547/1547 - 722s - loss: 0.0155 - accuracy: 0.9746 - auc_1: 0.9942 - precision_1: 0.9746 - recall_1: 0.9746 - val_loss: 0.0716 - val_accuracy: 0.9782 - val_auc_1: 0.9955 - val_precision_1: 0.9782 - val_recall_1: 0.9782\n",
      "Epoch 22/100\n",
      "epoch_end | time:  12.04.2021 20:53:20\n",
      "1547/1547 - 720s - loss: 0.0152 - accuracy: 0.9748 - auc_1: 0.9944 - precision_1: 0.9748 - recall_1: 0.9748 - val_loss: 0.1231 - val_accuracy: 0.9612 - val_auc_1: 0.9885 - val_precision_1: 0.9612 - val_recall_1: 0.9612\n",
      "Epoch 23/100\n",
      "epoch_end | time:  12.04.2021 21:05:19\n",
      "1547/1547 - 718s - loss: 0.0152 - accuracy: 0.9745 - auc_1: 0.9943 - precision_1: 0.9745 - recall_1: 0.9745 - val_loss: 0.0724 - val_accuracy: 0.9775 - val_auc_1: 0.9955 - val_precision_1: 0.9775 - val_recall_1: 0.9775\n",
      "Epoch 24/100\n",
      "epoch_end | time:  12.04.2021 21:17:16\n",
      "1547/1547 - 716s - loss: 0.0150 - accuracy: 0.9755 - auc_1: 0.9945 - precision_1: 0.9755 - recall_1: 0.9755 - val_loss: 0.0748 - val_accuracy: 0.9768 - val_auc_1: 0.9951 - val_precision_1: 0.9768 - val_recall_1: 0.9768\n",
      "Epoch 25/100\n",
      "epoch_end | time:  12.04.2021 21:29:11\n",
      "1547/1547 - 714s - loss: 0.0150 - accuracy: 0.9753 - auc_1: 0.9945 - precision_1: 0.9753 - recall_1: 0.9753 - val_loss: 0.0553 - val_accuracy: 0.9836 - val_auc_1: 0.9974 - val_precision_1: 0.9836 - val_recall_1: 0.9836\n",
      "Epoch 26/100\n",
      "epoch_end | time:  12.04.2021 21:41:09\n",
      "1547/1547 - 717s - loss: 0.0148 - accuracy: 0.9756 - auc_1: 0.9946 - precision_1: 0.9756 - recall_1: 0.9756 - val_loss: 0.0878 - val_accuracy: 0.9720 - val_auc_1: 0.9939 - val_precision_1: 0.9720 - val_recall_1: 0.9720\n",
      "Epoch 27/100\n",
      "epoch_end | time:  12.04.2021 21:53:09\n",
      "1547/1547 - 719s - loss: 0.0148 - accuracy: 0.9758 - auc_1: 0.9946 - precision_1: 0.9758 - recall_1: 0.9758 - val_loss: 0.0540 - val_accuracy: 0.9829 - val_auc_1: 0.9974 - val_precision_1: 0.9829 - val_recall_1: 0.9829\n",
      "Epoch 28/100\n",
      "epoch_end | time:  12.04.2021 22:05:10\n",
      "1547/1547 - 721s - loss: 0.0147 - accuracy: 0.9756 - auc_1: 0.9947 - precision_1: 0.9756 - recall_1: 0.9756 - val_loss: 0.1076 - val_accuracy: 0.9659 - val_auc_1: 0.9911 - val_precision_1: 0.9659 - val_recall_1: 0.9659\n",
      "Epoch 29/100\n",
      "epoch_end | time:  12.04.2021 22:17:09\n",
      "1547/1547 - 718s - loss: 0.0147 - accuracy: 0.9759 - auc_1: 0.9947 - precision_1: 0.9759 - recall_1: 0.9759 - val_loss: 0.0975 - val_accuracy: 0.9689 - val_auc_1: 0.9929 - val_precision_1: 0.9689 - val_recall_1: 0.9689\n",
      "Epoch 30/100\n",
      "epoch_end | time:  12.04.2021 22:29:07\n",
      "1547/1547 - 718s - loss: 0.0146 - accuracy: 0.9760 - auc_1: 0.9948 - precision_1: 0.9760 - recall_1: 0.9760 - val_loss: 0.0728 - val_accuracy: 0.9783 - val_auc_1: 0.9952 - val_precision_1: 0.9783 - val_recall_1: 0.9783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "epoch_end | time:  12.04.2021 22:41:05\n",
      "1547/1547 - 717s - loss: 0.0146 - accuracy: 0.9761 - auc_1: 0.9948 - precision_1: 0.9761 - recall_1: 0.9761 - val_loss: 0.1208 - val_accuracy: 0.9613 - val_auc_1: 0.9893 - val_precision_1: 0.9613 - val_recall_1: 0.9613\n",
      "Epoch 32/100\n",
      "epoch_end | time:  12.04.2021 22:53:06\n",
      "1547/1547 - 720s - loss: 0.0145 - accuracy: 0.9764 - auc_1: 0.9949 - precision_1: 0.9764 - recall_1: 0.9764 - val_loss: 0.0666 - val_accuracy: 0.9793 - val_auc_1: 0.9961 - val_precision_1: 0.9793 - val_recall_1: 0.9793\n",
      "Epoch 33/100\n",
      "epoch_end | time:  12.04.2021 23:05:04\n",
      "1547/1547 - 718s - loss: 0.0145 - accuracy: 0.9764 - auc_1: 0.9949 - precision_1: 0.9764 - recall_1: 0.9764 - val_loss: 0.0822 - val_accuracy: 0.9733 - val_auc_1: 0.9944 - val_precision_1: 0.9733 - val_recall_1: 0.9733\n",
      "Epoch 34/100\n",
      "epoch_end | time:  12.04.2021 23:17:03\n",
      "1547/1547 - 718s - loss: 0.0144 - accuracy: 0.9766 - auc_1: 0.9949 - precision_1: 0.9766 - recall_1: 0.9766 - val_loss: 0.0703 - val_accuracy: 0.9784 - val_auc_1: 0.9956 - val_precision_1: 0.9784 - val_recall_1: 0.9784\n",
      "Epoch 35/100\n",
      "epoch_end | time:  12.04.2021 23:29:02\n",
      "1547/1547 - 719s - loss: 0.0144 - accuracy: 0.9765 - auc_1: 0.9950 - precision_1: 0.9765 - recall_1: 0.9765 - val_loss: 0.0623 - val_accuracy: 0.9813 - val_auc_1: 0.9968 - val_precision_1: 0.9813 - val_recall_1: 0.9813\n",
      "Epoch 36/100\n",
      "epoch_end | time:  12.04.2021 23:40:59\n",
      "1547/1547 - 716s - loss: 0.0143 - accuracy: 0.9766 - auc_1: 0.9949 - precision_1: 0.9766 - recall_1: 0.9766 - val_loss: 0.1118 - val_accuracy: 0.9615 - val_auc_1: 0.9911 - val_precision_1: 0.9615 - val_recall_1: 0.9615\n",
      "Epoch 37/100\n",
      "epoch_end | time:  12.04.2021 23:53:00\n",
      "1547/1547 - 720s - loss: 0.0142 - accuracy: 0.9768 - auc_1: 0.9951 - precision_1: 0.9768 - recall_1: 0.9768 - val_loss: 0.1006 - val_accuracy: 0.9700 - val_auc_1: 0.9915 - val_precision_1: 0.9700 - val_recall_1: 0.9700\n",
      "Epoch 38/100\n",
      "epoch_end | time:  13.04.2021 00:05:02\n",
      "1547/1547 - 722s - loss: 0.0141 - accuracy: 0.9771 - auc_1: 0.9952 - precision_1: 0.9771 - recall_1: 0.9771 - val_loss: 0.0632 - val_accuracy: 0.9806 - val_auc_1: 0.9965 - val_precision_1: 0.9806 - val_recall_1: 0.9806\n",
      "Epoch 39/100\n",
      "epoch_end | time:  13.04.2021 00:17:02\n",
      "1547/1547 - 720s - loss: 0.0142 - accuracy: 0.9768 - auc_1: 0.9951 - precision_1: 0.9768 - recall_1: 0.9768 - val_loss: 0.0577 - val_accuracy: 0.9823 - val_auc_1: 0.9969 - val_precision_1: 0.9823 - val_recall_1: 0.9823\n",
      "Epoch 40/100\n",
      "epoch_end | time:  13.04.2021 00:29:03\n",
      "1547/1547 - 720s - loss: 0.0142 - accuracy: 0.9768 - auc_1: 0.9951 - precision_1: 0.9768 - recall_1: 0.9768 - val_loss: 0.1023 - val_accuracy: 0.9693 - val_auc_1: 0.9912 - val_precision_1: 0.9693 - val_recall_1: 0.9693\n",
      "Epoch 41/100\n",
      "epoch_end | time:  13.04.2021 00:41:05\n",
      "1547/1547 - 722s - loss: 0.0141 - accuracy: 0.9772 - auc_1: 0.9952 - precision_1: 0.9772 - recall_1: 0.9772 - val_loss: 0.0670 - val_accuracy: 0.9805 - val_auc_1: 0.9964 - val_precision_1: 0.9805 - val_recall_1: 0.9805\n",
      "Epoch 42/100\n",
      "epoch_end | time:  13.04.2021 00:53:07\n",
      "1547/1547 - 721s - loss: 0.0142 - accuracy: 0.9769 - auc_1: 0.9952 - precision_1: 0.9769 - recall_1: 0.9769 - val_loss: 0.0662 - val_accuracy: 0.9808 - val_auc_1: 0.9963 - val_precision_1: 0.9808 - val_recall_1: 0.9808\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 163, 1) for input Tensor(\"input_2:0\", shape=(None, 163, 1), dtype=float32), but it was called on an input with incompatible shape (None, 128, 1).\n",
      "=========================================\n",
      "VALIDATION: APS: 0.3956746908628054 AUC_ROC: 0.9583063168571302 GINI: 0.9166126337142604\n",
      "TEST: APS: 0.3887488741057905 AUC_ROC: 0.9579702042724729 GINI: 0.9159404085449458\n",
      "=========================================\n",
      "\n",
      "train_begin | time:  13.04.2021 00:53:40\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 163, 1) for input Tensor(\"input_3:0\", shape=(None, 163, 1), dtype=float32), but it was called on an input with incompatible shape (None, 128, 1).\n",
      "epoch_end | time:  13.04.2021 01:05:52\n",
      "1547/1547 - 727s - loss: 0.0339 - accuracy: 0.9235 - auc_2: 0.9765 - precision_2: 0.9235 - recall_2: 0.9235 - val_loss: 0.2553 - val_accuracy: 0.9126 - val_auc_2: 0.9605 - val_precision_2: 0.9126 - val_recall_2: 0.9126\n",
      "Epoch 2/100\n",
      "epoch_end | time:  13.04.2021 01:17:59\n",
      "1547/1547 - 726s - loss: 0.0235 - accuracy: 0.9566 - auc_2: 0.9876 - precision_2: 0.9566 - recall_2: 0.9566 - val_loss: 0.1227 - val_accuracy: 0.9601 - val_auc_2: 0.9894 - val_precision_2: 0.9601 - val_recall_2: 0.9601\n",
      "Epoch 3/100\n",
      "epoch_end | time:  13.04.2021 01:29:57\n",
      "1547/1547 - 717s - loss: 0.0215 - accuracy: 0.9616 - auc_2: 0.9893 - precision_2: 0.9616 - recall_2: 0.9616 - val_loss: 0.1720 - val_accuracy: 0.9458 - val_auc_2: 0.9798 - val_precision_2: 0.9458 - val_recall_2: 0.9458\n",
      "Epoch 4/100\n",
      "epoch_end | time:  13.04.2021 01:41:56\n",
      "1547/1547 - 718s - loss: 0.0202 - accuracy: 0.9643 - auc_2: 0.9905 - precision_2: 0.9643 - recall_2: 0.9643 - val_loss: 0.1682 - val_accuracy: 0.9481 - val_auc_2: 0.9808 - val_precision_2: 0.9481 - val_recall_2: 0.9481\n",
      "Epoch 5/100\n",
      "epoch_end | time:  13.04.2021 01:53:56\n",
      "1547/1547 - 719s - loss: 0.0194 - accuracy: 0.9662 - auc_2: 0.9910 - precision_2: 0.9662 - recall_2: 0.9662 - val_loss: 0.2053 - val_accuracy: 0.9377 - val_auc_2: 0.9762 - val_precision_2: 0.9377 - val_recall_2: 0.9377\n",
      "Epoch 6/100\n",
      "epoch_end | time:  13.04.2021 02:05:56\n",
      "1547/1547 - 720s - loss: 0.0188 - accuracy: 0.9674 - auc_2: 0.9915 - precision_2: 0.9674 - recall_2: 0.9674 - val_loss: 0.2652 - val_accuracy: 0.9220 - val_auc_2: 0.9658 - val_precision_2: 0.9220 - val_recall_2: 0.9220\n",
      "Epoch 7/100\n",
      "epoch_end | time:  13.04.2021 02:17:55\n",
      "1547/1547 - 719s - loss: 0.0185 - accuracy: 0.9678 - auc_2: 0.9917 - precision_2: 0.9678 - recall_2: 0.9678 - val_loss: 0.1078 - val_accuracy: 0.9676 - val_auc_2: 0.9908 - val_precision_2: 0.9676 - val_recall_2: 0.9676\n",
      "Epoch 8/100\n",
      "epoch_end | time:  13.04.2021 02:29:58\n",
      "1547/1547 - 722s - loss: 0.0178 - accuracy: 0.9695 - auc_2: 0.9923 - precision_2: 0.9695 - recall_2: 0.9695 - val_loss: 0.1531 - val_accuracy: 0.9526 - val_auc_2: 0.9834 - val_precision_2: 0.9526 - val_recall_2: 0.9526\n",
      "Epoch 9/100\n",
      "epoch_end | time:  13.04.2021 02:41:59\n",
      "1547/1547 - 721s - loss: 0.0178 - accuracy: 0.9695 - auc_2: 0.9924 - precision_2: 0.9695 - recall_2: 0.9695 - val_loss: 0.2550 - val_accuracy: 0.9145 - val_auc_2: 0.9587 - val_precision_2: 0.9145 - val_recall_2: 0.9145\n",
      "Epoch 10/100\n",
      "epoch_end | time:  13.04.2021 02:53:59\n",
      "1547/1547 - 719s - loss: 0.0176 - accuracy: 0.9701 - auc_2: 0.9925 - precision_2: 0.9701 - recall_2: 0.9701 - val_loss: 0.0554 - val_accuracy: 0.9843 - val_auc_2: 0.9973 - val_precision_2: 0.9843 - val_recall_2: 0.9843\n",
      "Epoch 11/100\n",
      "epoch_end | time:  13.04.2021 03:05:37\n",
      "1547/1547 - 697s - loss: 0.0173 - accuracy: 0.9708 - auc_2: 0.9926 - precision_2: 0.9708 - recall_2: 0.9708 - val_loss: 0.0837 - val_accuracy: 0.9746 - val_auc_2: 0.9942 - val_precision_2: 0.9746 - val_recall_2: 0.9746\n",
      "Epoch 12/100\n",
      "epoch_end | time:  13.04.2021 03:16:53\n",
      "1547/1547 - 676s - loss: 0.0170 - accuracy: 0.9717 - auc_2: 0.9929 - precision_2: 0.9717 - recall_2: 0.9717 - val_loss: 0.3563 - val_accuracy: 0.8933 - val_auc_2: 0.9432 - val_precision_2: 0.8933 - val_recall_2: 0.8933\n",
      "Epoch 13/100\n",
      "epoch_end | time:  13.04.2021 03:28:06\n",
      "1547/1547 - 672s - loss: 0.0169 - accuracy: 0.9716 - auc_2: 0.9930 - precision_2: 0.9716 - recall_2: 0.9716 - val_loss: 0.0799 - val_accuracy: 0.9754 - val_auc_2: 0.9944 - val_precision_2: 0.9754 - val_recall_2: 0.9754\n",
      "Epoch 14/100\n",
      "epoch_end | time:  13.04.2021 03:39:21\n",
      "1547/1547 - 675s - loss: 0.0166 - accuracy: 0.9722 - auc_2: 0.9933 - precision_2: 0.9722 - recall_2: 0.9722 - val_loss: 0.0998 - val_accuracy: 0.9720 - val_auc_2: 0.9910 - val_precision_2: 0.9720 - val_recall_2: 0.9720\n",
      "Epoch 15/100\n",
      "epoch_end | time:  13.04.2021 03:50:36\n",
      "1547/1547 - 675s - loss: 0.0166 - accuracy: 0.9722 - auc_2: 0.9932 - precision_2: 0.9722 - recall_2: 0.9722 - val_loss: 0.1433 - val_accuracy: 0.9526 - val_auc_2: 0.9860 - val_precision_2: 0.9526 - val_recall_2: 0.9526\n",
      "Epoch 16/100\n",
      "epoch_end | time:  13.04.2021 04:01:50\n",
      "1547/1547 - 673s - loss: 0.0164 - accuracy: 0.9727 - auc_2: 0.9934 - precision_2: 0.9727 - recall_2: 0.9727 - val_loss: 0.1369 - val_accuracy: 0.9597 - val_auc_2: 0.9862 - val_precision_2: 0.9597 - val_recall_2: 0.9597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100\n",
      "epoch_end | time:  13.04.2021 04:13:05\n",
      "1547/1547 - 675s - loss: 0.0162 - accuracy: 0.9730 - auc_2: 0.9935 - precision_2: 0.9730 - recall_2: 0.9730 - val_loss: 0.0895 - val_accuracy: 0.9712 - val_auc_2: 0.9936 - val_precision_2: 0.9712 - val_recall_2: 0.9712\n",
      "Epoch 18/100\n",
      "epoch_end | time:  13.04.2021 04:24:22\n",
      "1547/1547 - 676s - loss: 0.0161 - accuracy: 0.9729 - auc_2: 0.9935 - precision_2: 0.9729 - recall_2: 0.9729 - val_loss: 0.1480 - val_accuracy: 0.9527 - val_auc_2: 0.9843 - val_precision_2: 0.9527 - val_recall_2: 0.9527\n",
      "Epoch 19/100\n",
      "epoch_end | time:  13.04.2021 04:35:35\n",
      "1547/1547 - 673s - loss: 0.0161 - accuracy: 0.9732 - auc_2: 0.9936 - precision_2: 0.9732 - recall_2: 0.9732 - val_loss: 0.0815 - val_accuracy: 0.9748 - val_auc_2: 0.9943 - val_precision_2: 0.9748 - val_recall_2: 0.9748\n",
      "Epoch 20/100\n",
      "epoch_end | time:  13.04.2021 04:46:52\n",
      "1547/1547 - 676s - loss: 0.0159 - accuracy: 0.9734 - auc_2: 0.9937 - precision_2: 0.9734 - recall_2: 0.9734 - val_loss: 0.0968 - val_accuracy: 0.9701 - val_auc_2: 0.9925 - val_precision_2: 0.9701 - val_recall_2: 0.9701\n",
      "Epoch 21/100\n",
      "epoch_end | time:  13.04.2021 04:58:08\n",
      "1547/1547 - 676s - loss: 0.0157 - accuracy: 0.9740 - auc_2: 0.9940 - precision_2: 0.9740 - recall_2: 0.9740 - val_loss: 0.0883 - val_accuracy: 0.9735 - val_auc_2: 0.9933 - val_precision_2: 0.9735 - val_recall_2: 0.9735\n",
      "Epoch 22/100\n",
      "epoch_end | time:  13.04.2021 05:09:20\n",
      "1547/1547 - 672s - loss: 0.0155 - accuracy: 0.9744 - auc_2: 0.9940 - precision_2: 0.9744 - recall_2: 0.9744 - val_loss: 0.0855 - val_accuracy: 0.9740 - val_auc_2: 0.9938 - val_precision_2: 0.9740 - val_recall_2: 0.9740\n",
      "Epoch 23/100\n",
      "epoch_end | time:  13.04.2021 05:20:35\n",
      "1547/1547 - 675s - loss: 0.0157 - accuracy: 0.9740 - auc_2: 0.9939 - precision_2: 0.9740 - recall_2: 0.9740 - val_loss: 0.0816 - val_accuracy: 0.9755 - val_auc_2: 0.9941 - val_precision_2: 0.9755 - val_recall_2: 0.9755\n",
      "Epoch 24/100\n",
      "epoch_end | time:  13.04.2021 05:31:55\n",
      "1547/1547 - 680s - loss: 0.0156 - accuracy: 0.9743 - auc_2: 0.9940 - precision_2: 0.9743 - recall_2: 0.9743 - val_loss: 0.0783 - val_accuracy: 0.9759 - val_auc_2: 0.9949 - val_precision_2: 0.9759 - val_recall_2: 0.9759\n",
      "Epoch 25/100\n",
      "epoch_end | time:  13.04.2021 05:43:10\n",
      "1547/1547 - 674s - loss: 0.0154 - accuracy: 0.9745 - auc_2: 0.9942 - precision_2: 0.9745 - recall_2: 0.9745 - val_loss: 0.1622 - val_accuracy: 0.9482 - val_auc_2: 0.9819 - val_precision_2: 0.9482 - val_recall_2: 0.9482\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 163, 1) for input Tensor(\"input_3:0\", shape=(None, 163, 1), dtype=float32), but it was called on an input with incompatible shape (None, 128, 1).\n",
      "=========================================\n",
      "VALIDATION: APS: 0.41573348636456875 AUC_ROC: 0.954527110924184 GINI: 0.9090542218483679\n",
      "TEST: APS: 0.40615914854556384 AUC_ROC: 0.956034949594967 GINI: 0.9120698991899341\n",
      "=========================================\n",
      "\n",
      "train_begin | time:  13.04.2021 05:43:40\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 163, 1) for input Tensor(\"input_4:0\", shape=(None, 163, 1), dtype=float32), but it was called on an input with incompatible shape (None, 128, 1).\n",
      "epoch_end | time:  13.04.2021 05:57:00\n",
      "1547/1547 - 795s - loss: 0.0320 - accuracy: 0.9322 - auc_3: 0.9785 - precision_3: 0.9322 - recall_3: 0.9322 - val_loss: 0.1533 - val_accuracy: 0.9490 - val_auc_3: 0.9839 - val_precision_3: 0.9490 - val_recall_3: 0.9490\n",
      "Epoch 2/100\n",
      "epoch_end | time:  13.04.2021 06:10:21\n",
      "1547/1547 - 800s - loss: 0.0226 - accuracy: 0.9593 - auc_3: 0.9882 - precision_3: 0.9593 - recall_3: 0.9593 - val_loss: 0.2569 - val_accuracy: 0.9154 - val_auc_3: 0.9637 - val_precision_3: 0.9154 - val_recall_3: 0.9154\n",
      "Epoch 3/100\n",
      "epoch_end | time:  13.04.2021 06:23:40\n",
      "1547/1547 - 799s - loss: 0.0203 - accuracy: 0.9640 - auc_3: 0.9903 - precision_3: 0.9640 - recall_3: 0.9640 - val_loss: 0.3243 - val_accuracy: 0.8947 - val_auc_3: 0.9434 - val_precision_3: 0.8947 - val_recall_3: 0.8947\n",
      "Epoch 4/100\n",
      "epoch_end | time:  13.04.2021 06:36:58\n",
      "1547/1547 - 797s - loss: 0.0191 - accuracy: 0.9669 - auc_3: 0.9912 - precision_3: 0.9669 - recall_3: 0.9669 - val_loss: 0.0973 - val_accuracy: 0.9725 - val_auc_3: 0.9919 - val_precision_3: 0.9725 - val_recall_3: 0.9725\n",
      "Epoch 5/100\n",
      "epoch_end | time:  13.04.2021 06:50:19\n",
      "1547/1547 - 801s - loss: 0.0182 - accuracy: 0.9682 - auc_3: 0.9919 - precision_3: 0.9682 - recall_3: 0.9682 - val_loss: 0.2602 - val_accuracy: 0.9150 - val_auc_3: 0.9628 - val_precision_3: 0.9150 - val_recall_3: 0.9150\n",
      "Epoch 6/100\n",
      "epoch_end | time:  13.04.2021 07:03:39\n",
      "1547/1547 - 800s - loss: 0.0176 - accuracy: 0.9700 - auc_3: 0.9924 - precision_3: 0.9700 - recall_3: 0.9700 - val_loss: 0.1125 - val_accuracy: 0.9631 - val_auc_3: 0.9906 - val_precision_3: 0.9631 - val_recall_3: 0.9631\n",
      "Epoch 7/100\n",
      "epoch_end | time:  13.04.2021 07:16:59\n",
      "1547/1547 - 799s - loss: 0.0172 - accuracy: 0.9708 - auc_3: 0.9927 - precision_3: 0.9708 - recall_3: 0.9708 - val_loss: 0.1122 - val_accuracy: 0.9626 - val_auc_3: 0.9911 - val_precision_3: 0.9626 - val_recall_3: 0.9626\n",
      "Epoch 8/100\n",
      "epoch_end | time:  13.04.2021 07:30:18\n",
      "1547/1547 - 798s - loss: 0.0169 - accuracy: 0.9711 - auc_3: 0.9930 - precision_3: 0.9711 - recall_3: 0.9711 - val_loss: 0.0948 - val_accuracy: 0.9709 - val_auc_3: 0.9929 - val_precision_3: 0.9709 - val_recall_3: 0.9709\n",
      "Epoch 9/100\n",
      "epoch_end | time:  13.04.2021 07:43:38\n",
      "1547/1547 - 799s - loss: 0.0166 - accuracy: 0.9721 - auc_3: 0.9932 - precision_3: 0.9721 - recall_3: 0.9721 - val_loss: 0.0661 - val_accuracy: 0.9801 - val_auc_3: 0.9958 - val_precision_3: 0.9801 - val_recall_3: 0.9801\n",
      "Epoch 10/100\n",
      "epoch_end | time:  13.04.2021 07:56:57\n",
      "1547/1547 - 798s - loss: 0.0162 - accuracy: 0.9728 - auc_3: 0.9935 - precision_3: 0.9728 - recall_3: 0.9728 - val_loss: 0.2125 - val_accuracy: 0.9340 - val_auc_3: 0.9712 - val_precision_3: 0.9340 - val_recall_3: 0.9340\n",
      "Epoch 11/100\n",
      "epoch_end | time:  13.04.2021 08:10:18\n",
      "1547/1547 - 801s - loss: 0.0160 - accuracy: 0.9733 - auc_3: 0.9936 - precision_3: 0.9733 - recall_3: 0.9733 - val_loss: 0.1816 - val_accuracy: 0.9404 - val_auc_3: 0.9774 - val_precision_3: 0.9404 - val_recall_3: 0.9404\n",
      "Epoch 12/100\n",
      "epoch_end | time:  13.04.2021 08:23:39\n",
      "1547/1547 - 800s - loss: 0.0159 - accuracy: 0.9735 - auc_3: 0.9938 - precision_3: 0.9735 - recall_3: 0.9735 - val_loss: 0.1660 - val_accuracy: 0.9486 - val_auc_3: 0.9806 - val_precision_3: 0.9486 - val_recall_3: 0.9486\n",
      "Epoch 13/100\n",
      "epoch_end | time:  13.04.2021 08:36:59\n",
      "1547/1547 - 799s - loss: 0.0154 - accuracy: 0.9744 - auc_3: 0.9941 - precision_3: 0.9744 - recall_3: 0.9744 - val_loss: 0.2097 - val_accuracy: 0.9354 - val_auc_3: 0.9719 - val_precision_3: 0.9354 - val_recall_3: 0.9354\n",
      "Epoch 14/100\n",
      "epoch_end | time:  13.04.2021 08:50:22\n",
      "1547/1547 - 803s - loss: 0.0154 - accuracy: 0.9746 - auc_3: 0.9941 - precision_3: 0.9746 - recall_3: 0.9746 - val_loss: 0.3383 - val_accuracy: 0.8818 - val_auc_3: 0.9437 - val_precision_3: 0.8818 - val_recall_3: 0.8818\n",
      "Epoch 15/100\n",
      "epoch_end | time:  13.04.2021 09:03:43\n",
      "1547/1547 - 800s - loss: 0.0153 - accuracy: 0.9746 - auc_3: 0.9942 - precision_3: 0.9746 - recall_3: 0.9746 - val_loss: 0.0733 - val_accuracy: 0.9787 - val_auc_3: 0.9948 - val_precision_3: 0.9787 - val_recall_3: 0.9787\n",
      "Epoch 16/100\n",
      "epoch_end | time:  13.04.2021 09:17:04\n",
      "1547/1547 - 801s - loss: 0.0151 - accuracy: 0.9753 - auc_3: 0.9944 - precision_3: 0.9753 - recall_3: 0.9753 - val_loss: 0.1091 - val_accuracy: 0.9675 - val_auc_3: 0.9908 - val_precision_3: 0.9675 - val_recall_3: 0.9675\n",
      "Epoch 17/100\n",
      "epoch_end | time:  13.04.2021 09:30:26\n",
      "1547/1547 - 801s - loss: 0.0148 - accuracy: 0.9758 - auc_3: 0.9945 - precision_3: 0.9758 - recall_3: 0.9758 - val_loss: 0.1090 - val_accuracy: 0.9679 - val_auc_3: 0.9906 - val_precision_3: 0.9679 - val_recall_3: 0.9679\n",
      "Epoch 18/100\n",
      "epoch_end | time:  13.04.2021 09:44:28\n",
      "1547/1547 - 842s - loss: 0.0149 - accuracy: 0.9756 - auc_3: 0.9945 - precision_3: 0.9756 - recall_3: 0.9756 - val_loss: 0.0981 - val_accuracy: 0.9699 - val_auc_3: 0.9921 - val_precision_3: 0.9699 - val_recall_3: 0.9699\n",
      "Epoch 19/100\n",
      "epoch_end | time:  13.04.2021 10:00:50\n",
      "1547/1547 - 981s - loss: 0.0147 - accuracy: 0.9758 - auc_3: 0.9945 - precision_3: 0.9758 - recall_3: 0.9758 - val_loss: 0.0827 - val_accuracy: 0.9765 - val_auc_3: 0.9936 - val_precision_3: 0.9765 - val_recall_3: 0.9765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n",
      "epoch_end | time:  13.04.2021 10:15:01\n",
      "1547/1547 - 850s - loss: 0.0145 - accuracy: 0.9763 - auc_3: 0.9948 - precision_3: 0.9763 - recall_3: 0.9763 - val_loss: 0.0809 - val_accuracy: 0.9765 - val_auc_3: 0.9939 - val_precision_3: 0.9765 - val_recall_3: 0.9765\n",
      "Epoch 21/100\n",
      "epoch_end | time:  13.04.2021 10:29:18\n",
      "1547/1547 - 857s - loss: 0.0145 - accuracy: 0.9761 - auc_3: 0.9949 - precision_3: 0.9761 - recall_3: 0.9761 - val_loss: 0.1234 - val_accuracy: 0.9632 - val_auc_3: 0.9883 - val_precision_3: 0.9632 - val_recall_3: 0.9632\n",
      "Epoch 22/100\n",
      "epoch_end | time:  13.04.2021 10:43:42\n",
      "1547/1547 - 863s - loss: 0.0143 - accuracy: 0.9767 - auc_3: 0.9949 - precision_3: 0.9767 - recall_3: 0.9767 - val_loss: 0.1487 - val_accuracy: 0.9520 - val_auc_3: 0.9847 - val_precision_3: 0.9520 - val_recall_3: 0.9520\n",
      "Epoch 23/100\n",
      "epoch_end | time:  13.04.2021 10:57:48\n",
      "1547/1547 - 845s - loss: 0.0143 - accuracy: 0.9769 - auc_3: 0.9950 - precision_3: 0.9769 - recall_3: 0.9769 - val_loss: 0.0856 - val_accuracy: 0.9742 - val_auc_3: 0.9937 - val_precision_3: 0.9742 - val_recall_3: 0.9742\n",
      "Epoch 24/100\n",
      "epoch_end | time:  13.04.2021 11:11:51\n",
      "1547/1547 - 842s - loss: 0.0143 - accuracy: 0.9766 - auc_3: 0.9950 - precision_3: 0.9766 - recall_3: 0.9766 - val_loss: 0.0874 - val_accuracy: 0.9750 - val_auc_3: 0.9933 - val_precision_3: 0.9750 - val_recall_3: 0.9750\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 163, 1) for input Tensor(\"input_4:0\", shape=(None, 163, 1), dtype=float32), but it was called on an input with incompatible shape (None, 128, 1).\n",
      "=========================================\n",
      "VALIDATION: APS: 0.4491602656262703 AUC_ROC: 0.964257328544009 GINI: 0.9285146570880181\n",
      "TEST: APS: 0.4431040614077657 AUC_ROC: 0.9651044271631799 GINI: 0.9302088543263598\n",
      "=========================================\n",
      "\n",
      "train_begin | time:  13.04.2021 11:12:24\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 163, 1) for input Tensor(\"input_5:0\", shape=(None, 163, 1), dtype=float32), but it was called on an input with incompatible shape (None, 128, 1).\n",
      "epoch_end | time:  13.04.2021 11:26:42\n",
      "1547/1547 - 854s - loss: 0.0321 - accuracy: 0.9306 - auc_4: 0.9783 - precision_4: 0.9306 - recall_4: 0.9306 - val_loss: 0.2101 - val_accuracy: 0.9298 - val_auc_4: 0.9739 - val_precision_4: 0.9298 - val_recall_4: 0.9298\n",
      "Epoch 2/100\n",
      "epoch_end | time:  13.04.2021 11:43:33\n",
      "1547/1547 - 1010s - loss: 0.0219 - accuracy: 0.9604 - auc_4: 0.9890 - precision_4: 0.9604 - recall_4: 0.9604 - val_loss: 0.2111 - val_accuracy: 0.9253 - val_auc_4: 0.9730 - val_precision_4: 0.9253 - val_recall_4: 0.9253\n",
      "Epoch 3/100\n",
      "epoch_end | time:  13.04.2021 12:00:59\n",
      "1547/1547 - 1046s - loss: 0.0200 - accuracy: 0.9650 - auc_4: 0.9905 - precision_4: 0.9650 - recall_4: 0.9650 - val_loss: 0.0704 - val_accuracy: 0.9794 - val_auc_4: 0.9956 - val_precision_4: 0.9794 - val_recall_4: 0.9794\n",
      "Epoch 4/100\n",
      "epoch_end | time:  13.04.2021 12:18:03\n",
      "1547/1547 - 1023s - loss: 0.0191 - accuracy: 0.9673 - auc_4: 0.9914 - precision_4: 0.9673 - recall_4: 0.9673 - val_loss: 0.1991 - val_accuracy: 0.9356 - val_auc_4: 0.9748 - val_precision_4: 0.9356 - val_recall_4: 0.9356\n",
      "Epoch 5/100\n",
      "epoch_end | time:  13.04.2021 12:34:05\n",
      "1547/1547 - 961s - loss: 0.0183 - accuracy: 0.9694 - auc_4: 0.9921 - precision_4: 0.9694 - recall_4: 0.9694 - val_loss: 0.1266 - val_accuracy: 0.9645 - val_auc_4: 0.9872 - val_precision_4: 0.9645 - val_recall_4: 0.9645\n",
      "Epoch 6/100\n",
      "epoch_end | time:  13.04.2021 12:50:50\n",
      "1547/1547 - 1004s - loss: 0.0178 - accuracy: 0.9706 - auc_4: 0.9926 - precision_4: 0.9706 - recall_4: 0.9706 - val_loss: 0.0672 - val_accuracy: 0.9789 - val_auc_4: 0.9960 - val_precision_4: 0.9789 - val_recall_4: 0.9789\n",
      "Epoch 7/100\n",
      "epoch_end | time:  13.04.2021 13:07:17\n",
      "1547/1547 - 987s - loss: 0.0173 - accuracy: 0.9714 - auc_4: 0.9929 - precision_4: 0.9714 - recall_4: 0.9714 - val_loss: 0.1679 - val_accuracy: 0.9487 - val_auc_4: 0.9814 - val_precision_4: 0.9487 - val_recall_4: 0.9487\n",
      "Epoch 8/100\n",
      "epoch_end | time:  13.04.2021 13:23:59\n",
      "1547/1547 - 1001s - loss: 0.0171 - accuracy: 0.9718 - auc_4: 0.9931 - precision_4: 0.9718 - recall_4: 0.9718 - val_loss: 0.0751 - val_accuracy: 0.9785 - val_auc_4: 0.9955 - val_precision_4: 0.9785 - val_recall_4: 0.9785\n",
      "Epoch 9/100\n",
      "epoch_end | time:  13.04.2021 13:41:05\n",
      "1547/1547 - 1025s - loss: 0.0169 - accuracy: 0.9723 - auc_4: 0.9932 - precision_4: 0.9723 - recall_4: 0.9723 - val_loss: 0.0736 - val_accuracy: 0.9778 - val_auc_4: 0.9953 - val_precision_4: 0.9778 - val_recall_4: 0.9778\n",
      "Epoch 10/100\n",
      "epoch_end | time:  13.04.2021 13:57:28\n",
      "1547/1547 - 983s - loss: 0.0165 - accuracy: 0.9732 - auc_4: 0.9936 - precision_4: 0.9732 - recall_4: 0.9732 - val_loss: 0.1867 - val_accuracy: 0.9410 - val_auc_4: 0.9768 - val_precision_4: 0.9410 - val_recall_4: 0.9410\n",
      "Epoch 11/100\n",
      "epoch_end | time:  13.04.2021 14:13:53\n",
      "1547/1547 - 984s - loss: 0.0163 - accuracy: 0.9733 - auc_4: 0.9936 - precision_4: 0.9733 - recall_4: 0.9733 - val_loss: 0.1259 - val_accuracy: 0.9601 - val_auc_4: 0.9883 - val_precision_4: 0.9601 - val_recall_4: 0.9601\n",
      "Epoch 12/100\n",
      "epoch_end | time:  13.04.2021 14:30:15\n",
      "1547/1547 - 982s - loss: 0.0161 - accuracy: 0.9739 - auc_4: 0.9939 - precision_4: 0.9739 - recall_4: 0.9739 - val_loss: 0.0727 - val_accuracy: 0.9783 - val_auc_4: 0.9953 - val_precision_4: 0.9783 - val_recall_4: 0.9783\n",
      "Epoch 13/100\n",
      "epoch_end | time:  13.04.2021 14:48:37\n",
      "1547/1547 - 1100s - loss: 0.0161 - accuracy: 0.9737 - auc_4: 0.9939 - precision_4: 0.9737 - recall_4: 0.9737 - val_loss: 0.0603 - val_accuracy: 0.9813 - val_auc_4: 0.9966 - val_precision_4: 0.9813 - val_recall_4: 0.9813\n",
      "Epoch 14/100\n",
      "epoch_end | time:  13.04.2021 15:05:48\n",
      "1547/1547 - 1030s - loss: 0.0159 - accuracy: 0.9743 - auc_4: 0.9940 - precision_4: 0.9743 - recall_4: 0.9743 - val_loss: 0.1178 - val_accuracy: 0.9643 - val_auc_4: 0.9888 - val_precision_4: 0.9643 - val_recall_4: 0.9643\n",
      "Epoch 15/100\n",
      "epoch_end | time:  13.04.2021 15:25:09\n",
      "1547/1547 - 1161s - loss: 0.0156 - accuracy: 0.9748 - auc_4: 0.9942 - precision_4: 0.9748 - recall_4: 0.9748 - val_loss: 0.1168 - val_accuracy: 0.9649 - val_auc_4: 0.9895 - val_precision_4: 0.9649 - val_recall_4: 0.9649\n",
      "Epoch 16/100\n",
      "epoch_end | time:  13.04.2021 15:42:37\n",
      "1547/1547 - 1047s - loss: 0.0155 - accuracy: 0.9752 - auc_4: 0.9943 - precision_4: 0.9752 - recall_4: 0.9752 - val_loss: 0.1171 - val_accuracy: 0.9646 - val_auc_4: 0.9891 - val_precision_4: 0.9646 - val_recall_4: 0.9646\n",
      "Epoch 17/100\n",
      "epoch_end | time:  13.04.2021 16:00:40\n",
      "1547/1547 - 1083s - loss: 0.0154 - accuracy: 0.9749 - auc_4: 0.9943 - precision_4: 0.9749 - recall_4: 0.9749 - val_loss: 0.0881 - val_accuracy: 0.9710 - val_auc_4: 0.9940 - val_precision_4: 0.9710 - val_recall_4: 0.9710\n",
      "Epoch 18/100\n",
      "epoch_end | time:  13.04.2021 16:16:45\n",
      "1547/1547 - 964s - loss: 0.0152 - accuracy: 0.9753 - auc_4: 0.9945 - precision_4: 0.9753 - recall_4: 0.9753 - val_loss: 0.1577 - val_accuracy: 0.9488 - val_auc_4: 0.9831 - val_precision_4: 0.9488 - val_recall_4: 0.9488\n",
      "Epoch 19/100\n",
      "epoch_end | time:  13.04.2021 16:31:54\n",
      "1547/1547 - 909s - loss: 0.0152 - accuracy: 0.9754 - auc_4: 0.9946 - precision_4: 0.9754 - recall_4: 0.9754 - val_loss: 0.0782 - val_accuracy: 0.9775 - val_auc_4: 0.9943 - val_precision_4: 0.9775 - val_recall_4: 0.9775\n",
      "Epoch 20/100\n",
      "epoch_end | time:  13.04.2021 16:46:55\n",
      "1547/1547 - 900s - loss: 0.0151 - accuracy: 0.9758 - auc_4: 0.9946 - precision_4: 0.9758 - recall_4: 0.9758 - val_loss: 0.0618 - val_accuracy: 0.9812 - val_auc_4: 0.9963 - val_precision_4: 0.9812 - val_recall_4: 0.9812\n",
      "Epoch 21/100\n",
      "epoch_end | time:  13.04.2021 17:01:53\n",
      "1547/1547 - 898s - loss: 0.0149 - accuracy: 0.9760 - auc_4: 0.9947 - precision_4: 0.9760 - recall_4: 0.9760 - val_loss: 0.0593 - val_accuracy: 0.9821 - val_auc_4: 0.9969 - val_precision_4: 0.9821 - val_recall_4: 0.9821\n",
      "Epoch 22/100\n",
      "epoch_end | time:  13.04.2021 17:16:42\n",
      "1547/1547 - 888s - loss: 0.0148 - accuracy: 0.9760 - auc_4: 0.9948 - precision_4: 0.9760 - recall_4: 0.9760 - val_loss: 0.0578 - val_accuracy: 0.9830 - val_auc_4: 0.9968 - val_precision_4: 0.9830 - val_recall_4: 0.9830\n",
      "Epoch 23/100\n",
      "epoch_end | time:  13.04.2021 17:31:40\n",
      "1547/1547 - 897s - loss: 0.0147 - accuracy: 0.9764 - auc_4: 0.9949 - precision_4: 0.9764 - recall_4: 0.9764 - val_loss: 0.0812 - val_accuracy: 0.9747 - val_auc_4: 0.9946 - val_precision_4: 0.9747 - val_recall_4: 0.9747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100\n",
      "epoch_end | time:  13.04.2021 17:46:29\n",
      "1547/1547 - 888s - loss: 0.0146 - accuracy: 0.9765 - auc_4: 0.9949 - precision_4: 0.9765 - recall_4: 0.9765 - val_loss: 0.0915 - val_accuracy: 0.9711 - val_auc_4: 0.9935 - val_precision_4: 0.9711 - val_recall_4: 0.9711\n",
      "Epoch 25/100\n",
      "epoch_end | time:  13.04.2021 18:02:42\n",
      "1547/1547 - 973s - loss: 0.0145 - accuracy: 0.9767 - auc_4: 0.9949 - precision_4: 0.9767 - recall_4: 0.9767 - val_loss: 0.0660 - val_accuracy: 0.9808 - val_auc_4: 0.9960 - val_precision_4: 0.9808 - val_recall_4: 0.9808\n",
      "Epoch 26/100\n",
      "epoch_end | time:  13.04.2021 18:17:11\n",
      "1547/1547 - 868s - loss: 0.0146 - accuracy: 0.9764 - auc_4: 0.9949 - precision_4: 0.9764 - recall_4: 0.9764 - val_loss: 0.0574 - val_accuracy: 0.9821 - val_auc_4: 0.9968 - val_precision_4: 0.9821 - val_recall_4: 0.9821\n",
      "Epoch 27/100\n",
      "epoch_end | time:  13.04.2021 18:32:19\n",
      "1547/1547 - 907s - loss: 0.0144 - accuracy: 0.9768 - auc_4: 0.9951 - precision_4: 0.9768 - recall_4: 0.9768 - val_loss: 0.0648 - val_accuracy: 0.9795 - val_auc_4: 0.9962 - val_precision_4: 0.9795 - val_recall_4: 0.9795\n",
      "Epoch 28/100\n",
      "epoch_end | time:  13.04.2021 18:48:28\n",
      "1547/1547 - 967s - loss: 0.0144 - accuracy: 0.9770 - auc_4: 0.9951 - precision_4: 0.9770 - recall_4: 0.9770 - val_loss: 0.0753 - val_accuracy: 0.9768 - val_auc_4: 0.9952 - val_precision_4: 0.9768 - val_recall_4: 0.9768\n",
      "Epoch 29/100\n",
      "epoch_end | time:  13.04.2021 19:03:07\n",
      "1547/1547 - 879s - loss: 0.0143 - accuracy: 0.9773 - auc_4: 0.9952 - precision_4: 0.9773 - recall_4: 0.9773 - val_loss: 0.0627 - val_accuracy: 0.9807 - val_auc_4: 0.9966 - val_precision_4: 0.9807 - val_recall_4: 0.9807\n",
      "Epoch 30/100\n",
      "epoch_end | time:  13.04.2021 19:17:49\n",
      "1547/1547 - 881s - loss: 0.0142 - accuracy: 0.9772 - auc_4: 0.9952 - precision_4: 0.9772 - recall_4: 0.9772 - val_loss: 0.0797 - val_accuracy: 0.9762 - val_auc_4: 0.9944 - val_precision_4: 0.9762 - val_recall_4: 0.9762\n",
      "Epoch 31/100\n",
      "epoch_end | time:  13.04.2021 19:32:31\n",
      "1547/1547 - 882s - loss: 0.0141 - accuracy: 0.9776 - auc_4: 0.9954 - precision_4: 0.9776 - recall_4: 0.9776 - val_loss: 0.0606 - val_accuracy: 0.9814 - val_auc_4: 0.9966 - val_precision_4: 0.9814 - val_recall_4: 0.9814\n",
      "Epoch 32/100\n",
      "epoch_end | time:  13.04.2021 19:47:19\n",
      "1547/1547 - 887s - loss: 0.0140 - accuracy: 0.9773 - auc_4: 0.9954 - precision_4: 0.9773 - recall_4: 0.9773 - val_loss: 0.1378 - val_accuracy: 0.9540 - val_auc_4: 0.9867 - val_precision_4: 0.9540 - val_recall_4: 0.9540\n",
      "Epoch 33/100\n",
      "epoch_end | time:  13.04.2021 20:02:00\n",
      "1547/1547 - 880s - loss: 0.0141 - accuracy: 0.9775 - auc_4: 0.9953 - precision_4: 0.9775 - recall_4: 0.9775 - val_loss: 0.1303 - val_accuracy: 0.9604 - val_auc_4: 0.9874 - val_precision_4: 0.9604 - val_recall_4: 0.9604\n",
      "Epoch 34/100\n",
      "epoch_end | time:  13.04.2021 20:16:57\n",
      "1547/1547 - 896s - loss: 0.0139 - accuracy: 0.9778 - auc_4: 0.9954 - precision_4: 0.9778 - recall_4: 0.9778 - val_loss: 0.0991 - val_accuracy: 0.9684 - val_auc_4: 0.9927 - val_precision_4: 0.9684 - val_recall_4: 0.9684\n",
      "Epoch 35/100\n",
      "epoch_end | time:  13.04.2021 20:31:54\n",
      "1547/1547 - 896s - loss: 0.0140 - accuracy: 0.9773 - auc_4: 0.9955 - precision_4: 0.9773 - recall_4: 0.9773 - val_loss: 0.0647 - val_accuracy: 0.9811 - val_auc_4: 0.9961 - val_precision_4: 0.9811 - val_recall_4: 0.9811\n",
      "Epoch 36/100\n",
      "epoch_end | time:  13.04.2021 20:46:52\n",
      "1547/1547 - 897s - loss: 0.0138 - accuracy: 0.9777 - auc_4: 0.9954 - precision_4: 0.9777 - recall_4: 0.9777 - val_loss: 0.0843 - val_accuracy: 0.9746 - val_auc_4: 0.9939 - val_precision_4: 0.9746 - val_recall_4: 0.9746\n",
      "Epoch 37/100\n",
      "epoch_end | time:  13.04.2021 21:01:50\n",
      "1547/1547 - 897s - loss: 0.0138 - accuracy: 0.9777 - auc_4: 0.9955 - precision_4: 0.9777 - recall_4: 0.9777 - val_loss: 0.0516 - val_accuracy: 0.9846 - val_auc_4: 0.9977 - val_precision_4: 0.9846 - val_recall_4: 0.9846\n",
      "Epoch 38/100\n",
      "epoch_end | time:  13.04.2021 21:16:46\n",
      "1547/1547 - 896s - loss: 0.0137 - accuracy: 0.9780 - auc_4: 0.9955 - precision_4: 0.9780 - recall_4: 0.9780 - val_loss: 0.0919 - val_accuracy: 0.9727 - val_auc_4: 0.9928 - val_precision_4: 0.9727 - val_recall_4: 0.9727\n",
      "Epoch 39/100\n",
      "epoch_end | time:  13.04.2021 21:31:37\n",
      "1547/1547 - 890s - loss: 0.0137 - accuracy: 0.9780 - auc_4: 0.9955 - precision_4: 0.9780 - recall_4: 0.9780 - val_loss: 0.0640 - val_accuracy: 0.9809 - val_auc_4: 0.9961 - val_precision_4: 0.9809 - val_recall_4: 0.9809\n",
      "Epoch 40/100\n",
      "epoch_end | time:  13.04.2021 21:46:24\n",
      "1547/1547 - 887s - loss: 0.0137 - accuracy: 0.9780 - auc_4: 0.9956 - precision_4: 0.9780 - recall_4: 0.9780 - val_loss: 0.0870 - val_accuracy: 0.9735 - val_auc_4: 0.9938 - val_precision_4: 0.9735 - val_recall_4: 0.9735\n",
      "Epoch 41/100\n",
      "epoch_end | time:  13.04.2021 22:01:16\n",
      "1547/1547 - 891s - loss: 0.0137 - accuracy: 0.9781 - auc_4: 0.9955 - precision_4: 0.9781 - recall_4: 0.9781 - val_loss: 0.0803 - val_accuracy: 0.9760 - val_auc_4: 0.9943 - val_precision_4: 0.9760 - val_recall_4: 0.9760\n",
      "Epoch 42/100\n",
      "epoch_end | time:  13.04.2021 22:16:07\n",
      "1547/1547 - 890s - loss: 0.0136 - accuracy: 0.9782 - auc_4: 0.9956 - precision_4: 0.9782 - recall_4: 0.9782 - val_loss: 0.1263 - val_accuracy: 0.9612 - val_auc_4: 0.9883 - val_precision_4: 0.9612 - val_recall_4: 0.9612\n",
      "Epoch 43/100\n",
      "epoch_end | time:  13.04.2021 22:30:52\n",
      "1547/1547 - 885s - loss: 0.0137 - accuracy: 0.9780 - auc_4: 0.9956 - precision_4: 0.9780 - recall_4: 0.9780 - val_loss: 0.0845 - val_accuracy: 0.9735 - val_auc_4: 0.9944 - val_precision_4: 0.9735 - val_recall_4: 0.9735\n",
      "Epoch 44/100\n",
      "epoch_end | time:  13.04.2021 22:45:42\n",
      "1547/1547 - 889s - loss: 0.0135 - accuracy: 0.9783 - auc_4: 0.9956 - precision_4: 0.9783 - recall_4: 0.9783 - val_loss: 0.0968 - val_accuracy: 0.9708 - val_auc_4: 0.9925 - val_precision_4: 0.9708 - val_recall_4: 0.9708\n",
      "Epoch 45/100\n",
      "epoch_end | time:  13.04.2021 23:00:30\n",
      "1547/1547 - 887s - loss: 0.0136 - accuracy: 0.9782 - auc_4: 0.9957 - precision_4: 0.9782 - recall_4: 0.9782 - val_loss: 0.0675 - val_accuracy: 0.9801 - val_auc_4: 0.9961 - val_precision_4: 0.9801 - val_recall_4: 0.9801\n",
      "Epoch 46/100\n",
      "epoch_end | time:  13.04.2021 23:14:45\n",
      "1547/1547 - 854s - loss: 0.0135 - accuracy: 0.9783 - auc_4: 0.9957 - precision_4: 0.9783 - recall_4: 0.9783 - val_loss: 0.1201 - val_accuracy: 0.9633 - val_auc_4: 0.9890 - val_precision_4: 0.9633 - val_recall_4: 0.9633\n",
      "Epoch 47/100\n",
      "epoch_end | time:  13.04.2021 23:28:24\n",
      "1547/1547 - 818s - loss: 0.0135 - accuracy: 0.9782 - auc_4: 0.9957 - precision_4: 0.9782 - recall_4: 0.9782 - val_loss: 0.0745 - val_accuracy: 0.9781 - val_auc_4: 0.9951 - val_precision_4: 0.9781 - val_recall_4: 0.9781\n",
      "Epoch 48/100\n",
      "epoch_end | time:  13.04.2021 23:42:03\n",
      "1547/1547 - 819s - loss: 0.0135 - accuracy: 0.9782 - auc_4: 0.9956 - precision_4: 0.9782 - recall_4: 0.9782 - val_loss: 0.0739 - val_accuracy: 0.9779 - val_auc_4: 0.9951 - val_precision_4: 0.9779 - val_recall_4: 0.9779\n",
      "Epoch 49/100\n",
      "epoch_end | time:  13.04.2021 23:55:40\n",
      "1547/1547 - 817s - loss: 0.0133 - accuracy: 0.9787 - auc_4: 0.9958 - precision_4: 0.9787 - recall_4: 0.9787 - val_loss: 0.1084 - val_accuracy: 0.9612 - val_auc_4: 0.9919 - val_precision_4: 0.9612 - val_recall_4: 0.9612\n",
      "Epoch 50/100\n",
      "epoch_end | time:  14.04.2021 00:09:19\n",
      "1547/1547 - 818s - loss: 0.0135 - accuracy: 0.9782 - auc_4: 0.9957 - precision_4: 0.9782 - recall_4: 0.9782 - val_loss: 0.0958 - val_accuracy: 0.9714 - val_auc_4: 0.9925 - val_precision_4: 0.9714 - val_recall_4: 0.9714\n",
      "Epoch 51/100\n",
      "epoch_end | time:  14.04.2021 00:22:59\n",
      "1547/1547 - 819s - loss: 0.0134 - accuracy: 0.9781 - auc_4: 0.9957 - precision_4: 0.9781 - recall_4: 0.9781 - val_loss: 0.0866 - val_accuracy: 0.9743 - val_auc_4: 0.9936 - val_precision_4: 0.9743 - val_recall_4: 0.9743\n",
      "Epoch 52/100\n",
      "epoch_end | time:  14.04.2021 00:36:34\n",
      "1547/1547 - 815s - loss: 0.0132 - accuracy: 0.9785 - auc_4: 0.9959 - precision_4: 0.9785 - recall_4: 0.9785 - val_loss: 0.0458 - val_accuracy: 0.9857 - val_auc_4: 0.9979 - val_precision_4: 0.9857 - val_recall_4: 0.9857\n",
      "Epoch 53/100\n",
      "epoch_end | time:  14.04.2021 00:50:14\n",
      "1547/1547 - 819s - loss: 0.0132 - accuracy: 0.9787 - auc_4: 0.9959 - precision_4: 0.9787 - recall_4: 0.9787 - val_loss: 0.1197 - val_accuracy: 0.9632 - val_auc_4: 0.9891 - val_precision_4: 0.9632 - val_recall_4: 0.9632\n",
      "Epoch 54/100\n",
      "epoch_end | time:  14.04.2021 01:03:54\n",
      "1547/1547 - 819s - loss: 0.0132 - accuracy: 0.9786 - auc_4: 0.9958 - precision_4: 0.9786 - recall_4: 0.9786 - val_loss: 0.1285 - val_accuracy: 0.9595 - val_auc_4: 0.9880 - val_precision_4: 0.9595 - val_recall_4: 0.9595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "epoch_end | time:  14.04.2021 01:17:32\n",
      "1547/1547 - 818s - loss: 0.0133 - accuracy: 0.9786 - auc_4: 0.9958 - precision_4: 0.9786 - recall_4: 0.9786 - val_loss: 0.0982 - val_accuracy: 0.9692 - val_auc_4: 0.9924 - val_precision_4: 0.9692 - val_recall_4: 0.9692\n",
      "Epoch 56/100\n",
      "epoch_end | time:  14.04.2021 01:31:11\n",
      "1547/1547 - 819s - loss: 0.0132 - accuracy: 0.9788 - auc_4: 0.9958 - precision_4: 0.9788 - recall_4: 0.9788 - val_loss: 0.0644 - val_accuracy: 0.9802 - val_auc_4: 0.9961 - val_precision_4: 0.9802 - val_recall_4: 0.9802\n",
      "Epoch 57/100\n",
      "epoch_end | time:  14.04.2021 01:44:50\n",
      "1547/1547 - 818s - loss: 0.0132 - accuracy: 0.9789 - auc_4: 0.9958 - precision_4: 0.9789 - recall_4: 0.9789 - val_loss: 0.0896 - val_accuracy: 0.9720 - val_auc_4: 0.9936 - val_precision_4: 0.9720 - val_recall_4: 0.9720\n",
      "Epoch 58/100\n",
      "epoch_end | time:  14.04.2021 01:58:26\n",
      "1547/1547 - 815s - loss: 0.0132 - accuracy: 0.9787 - auc_4: 0.9958 - precision_4: 0.9787 - recall_4: 0.9787 - val_loss: 0.1020 - val_accuracy: 0.9697 - val_auc_4: 0.9914 - val_precision_4: 0.9697 - val_recall_4: 0.9697\n",
      "Epoch 59/100\n",
      "epoch_end | time:  14.04.2021 02:12:07\n",
      "1547/1547 - 821s - loss: 0.0130 - accuracy: 0.9789 - auc_4: 0.9959 - precision_4: 0.9789 - recall_4: 0.9789 - val_loss: 0.0928 - val_accuracy: 0.9719 - val_auc_4: 0.9928 - val_precision_4: 0.9719 - val_recall_4: 0.9719\n",
      "Epoch 60/100\n",
      "epoch_end | time:  14.04.2021 02:25:45\n",
      "1547/1547 - 818s - loss: 0.0131 - accuracy: 0.9788 - auc_4: 0.9960 - precision_4: 0.9788 - recall_4: 0.9788 - val_loss: 0.0929 - val_accuracy: 0.9724 - val_auc_4: 0.9929 - val_precision_4: 0.9724 - val_recall_4: 0.9724\n",
      "Epoch 61/100\n",
      "epoch_end | time:  14.04.2021 02:39:26\n",
      "1547/1547 - 820s - loss: 0.0130 - accuracy: 0.9790 - auc_4: 0.9959 - precision_4: 0.9790 - recall_4: 0.9790 - val_loss: 0.1148 - val_accuracy: 0.9634 - val_auc_4: 0.9901 - val_precision_4: 0.9634 - val_recall_4: 0.9634\n",
      "Epoch 62/100\n",
      "epoch_end | time:  14.04.2021 02:53:08\n",
      "1547/1547 - 821s - loss: 0.0131 - accuracy: 0.9786 - auc_4: 0.9959 - precision_4: 0.9786 - recall_4: 0.9786 - val_loss: 0.0815 - val_accuracy: 0.9753 - val_auc_4: 0.9942 - val_precision_4: 0.9753 - val_recall_4: 0.9753\n",
      "Epoch 63/100\n",
      "epoch_end | time:  14.04.2021 03:06:45\n",
      "1547/1547 - 816s - loss: 0.0130 - accuracy: 0.9788 - auc_4: 0.9960 - precision_4: 0.9788 - recall_4: 0.9788 - val_loss: 0.0886 - val_accuracy: 0.9744 - val_auc_4: 0.9931 - val_precision_4: 0.9744 - val_recall_4: 0.9744\n",
      "Epoch 64/100\n",
      "epoch_end | time:  14.04.2021 03:20:26\n",
      "1547/1547 - 821s - loss: 0.0129 - accuracy: 0.9791 - auc_4: 0.9960 - precision_4: 0.9791 - recall_4: 0.9791 - val_loss: 0.0698 - val_accuracy: 0.9788 - val_auc_4: 0.9959 - val_precision_4: 0.9788 - val_recall_4: 0.9788\n",
      "Epoch 65/100\n",
      "epoch_end | time:  14.04.2021 03:34:02\n",
      "1547/1547 - 815s - loss: 0.0129 - accuracy: 0.9792 - auc_4: 0.9960 - precision_4: 0.9792 - recall_4: 0.9792 - val_loss: 0.0743 - val_accuracy: 0.9769 - val_auc_4: 0.9952 - val_precision_4: 0.9769 - val_recall_4: 0.9769\n",
      "Epoch 66/100\n",
      "epoch_end | time:  14.04.2021 03:47:38\n",
      "1547/1547 - 815s - loss: 0.0130 - accuracy: 0.9789 - auc_4: 0.9959 - precision_4: 0.9789 - recall_4: 0.9789 - val_loss: 0.0800 - val_accuracy: 0.9749 - val_auc_4: 0.9946 - val_precision_4: 0.9749 - val_recall_4: 0.9749\n",
      "Epoch 67/100\n",
      "epoch_end | time:  14.04.2021 04:01:12\n",
      "1547/1547 - 814s - loss: 0.0129 - accuracy: 0.9792 - auc_4: 0.9960 - precision_4: 0.9792 - recall_4: 0.9792 - val_loss: 0.0624 - val_accuracy: 0.9818 - val_auc_4: 0.9966 - val_precision_4: 0.9818 - val_recall_4: 0.9818\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 163, 1) for input Tensor(\"input_5:0\", shape=(None, 163, 1), dtype=float32), but it was called on an input with incompatible shape (None, 128, 1).\n",
      "=========================================\n",
      "VALIDATION: APS: 0.4365929787632824 AUC_ROC: 0.963030652276284 GINI: 0.9260613045525681\n",
      "TEST: APS: 0.42340308661639314 AUC_ROC: 0.9594166673914652 GINI: 0.9188333347829305\n",
      "=========================================\n",
      "\n",
      "train_begin | time:  14.04.2021 04:01:46\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 163, 1) for input Tensor(\"input_6:0\", shape=(None, 163, 1), dtype=float32), but it was called on an input with incompatible shape (None, 128, 1).\n",
      "epoch_end | time:  14.04.2021 04:22:19\n",
      "1547/1547 - 1228s - loss: 0.0288 - accuracy: 0.9384 - auc_5: 0.9825 - precision_5: 0.9384 - recall_5: 0.9384 - val_loss: 0.0487 - val_accuracy: 0.9856 - val_auc_5: 0.9973 - val_precision_5: 0.9856 - val_recall_5: 0.9856\n",
      "Epoch 2/100\n",
      "epoch_end | time:  14.04.2021 04:42:40\n",
      "1547/1547 - 1220s - loss: 0.0191 - accuracy: 0.9659 - auc_5: 0.9915 - precision_5: 0.9659 - recall_5: 0.9659 - val_loss: 0.1435 - val_accuracy: 0.9546 - val_auc_5: 0.9855 - val_precision_5: 0.9546 - val_recall_5: 0.9546\n",
      "Epoch 3/100\n",
      "epoch_end | time:  14.04.2021 05:03:09\n",
      "1547/1547 - 1228s - loss: 0.0173 - accuracy: 0.9702 - auc_5: 0.9928 - precision_5: 0.9702 - recall_5: 0.9702 - val_loss: 0.1057 - val_accuracy: 0.9690 - val_auc_5: 0.9912 - val_precision_5: 0.9690 - val_recall_5: 0.9690\n",
      "Epoch 4/100\n",
      "epoch_end | time:  14.04.2021 05:23:35\n",
      "1547/1547 - 1225s - loss: 0.0160 - accuracy: 0.9733 - auc_5: 0.9938 - precision_5: 0.9733 - recall_5: 0.9733 - val_loss: 0.1634 - val_accuracy: 0.9483 - val_auc_5: 0.9822 - val_precision_5: 0.9483 - val_recall_5: 0.9483\n",
      "Epoch 5/100\n",
      "epoch_end | time:  14.04.2021 05:44:01\n",
      "1547/1547 - 1225s - loss: 0.0153 - accuracy: 0.9748 - auc_5: 0.9943 - precision_5: 0.9748 - recall_5: 0.9748 - val_loss: 0.0781 - val_accuracy: 0.9747 - val_auc_5: 0.9950 - val_precision_5: 0.9747 - val_recall_5: 0.9747\n",
      "Epoch 6/100\n",
      "epoch_end | time:  14.04.2021 06:04:26\n",
      "1547/1547 - 1224s - loss: 0.0148 - accuracy: 0.9758 - auc_5: 0.9946 - precision_5: 0.9758 - recall_5: 0.9758 - val_loss: 0.0867 - val_accuracy: 0.9742 - val_auc_5: 0.9938 - val_precision_5: 0.9742 - val_recall_5: 0.9742\n",
      "Epoch 7/100\n",
      "epoch_end | time:  14.04.2021 06:24:40\n",
      "1547/1547 - 1213s - loss: 0.0143 - accuracy: 0.9765 - auc_5: 0.9950 - precision_5: 0.9765 - recall_5: 0.9765 - val_loss: 0.0628 - val_accuracy: 0.9807 - val_auc_5: 0.9964 - val_precision_5: 0.9807 - val_recall_5: 0.9807\n",
      "Epoch 8/100\n",
      "epoch_end | time:  14.04.2021 06:44:50\n",
      "1547/1547 - 1209s - loss: 0.0141 - accuracy: 0.9766 - auc_5: 0.9951 - precision_5: 0.9766 - recall_5: 0.9766 - val_loss: 0.0401 - val_accuracy: 0.9871 - val_auc_5: 0.9983 - val_precision_5: 0.9871 - val_recall_5: 0.9871\n",
      "Epoch 9/100\n",
      "epoch_end | time:  14.04.2021 07:05:00\n",
      "1547/1547 - 1209s - loss: 0.0136 - accuracy: 0.9779 - auc_5: 0.9954 - precision_5: 0.9779 - recall_5: 0.9779 - val_loss: 0.0642 - val_accuracy: 0.9815 - val_auc_5: 0.9957 - val_precision_5: 0.9815 - val_recall_5: 0.9815\n",
      "Epoch 10/100\n",
      "epoch_end | time:  14.04.2021 07:25:09\n",
      "1547/1547 - 1208s - loss: 0.0135 - accuracy: 0.9781 - auc_5: 0.9955 - precision_5: 0.9781 - recall_5: 0.9781 - val_loss: 0.0797 - val_accuracy: 0.9759 - val_auc_5: 0.9944 - val_precision_5: 0.9759 - val_recall_5: 0.9759\n",
      "Epoch 11/100\n",
      "epoch_end | time:  14.04.2021 07:45:21\n",
      "1547/1547 - 1211s - loss: 0.0132 - accuracy: 0.9783 - auc_5: 0.9957 - precision_5: 0.9783 - recall_5: 0.9783 - val_loss: 0.1242 - val_accuracy: 0.9617 - val_auc_5: 0.9885 - val_precision_5: 0.9617 - val_recall_5: 0.9617\n",
      "Epoch 12/100\n",
      "epoch_end | time:  14.04.2021 08:05:30\n",
      "1547/1547 - 1208s - loss: 0.0128 - accuracy: 0.9790 - auc_5: 0.9959 - precision_5: 0.9790 - recall_5: 0.9790 - val_loss: 0.0587 - val_accuracy: 0.9820 - val_auc_5: 0.9969 - val_precision_5: 0.9820 - val_recall_5: 0.9820\n",
      "Epoch 13/100\n",
      "epoch_end | time:  14.04.2021 08:25:39\n",
      "1547/1547 - 1208s - loss: 0.0126 - accuracy: 0.9794 - auc_5: 0.9961 - precision_5: 0.9794 - recall_5: 0.9794 - val_loss: 0.0675 - val_accuracy: 0.9794 - val_auc_5: 0.9957 - val_precision_5: 0.9794 - val_recall_5: 0.9794\n",
      "Epoch 14/100\n",
      "epoch_end | time:  14.04.2021 08:45:50\n",
      "1547/1547 - 1209s - loss: 0.0125 - accuracy: 0.9794 - auc_5: 0.9961 - precision_5: 0.9794 - recall_5: 0.9794 - val_loss: 0.1259 - val_accuracy: 0.9630 - val_auc_5: 0.9881 - val_precision_5: 0.9630 - val_recall_5: 0.9630\n",
      "Epoch 15/100\n",
      "epoch_end | time:  14.04.2021 09:05:57\n",
      "1547/1547 - 1206s - loss: 0.0125 - accuracy: 0.9796 - auc_5: 0.9961 - precision_5: 0.9796 - recall_5: 0.9796 - val_loss: 0.0965 - val_accuracy: 0.9696 - val_auc_5: 0.9926 - val_precision_5: 0.9696 - val_recall_5: 0.9696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "epoch_end | time:  14.04.2021 09:26:05\n",
      "1547/1547 - 1208s - loss: 0.0122 - accuracy: 0.9800 - auc_5: 0.9962 - precision_5: 0.9800 - recall_5: 0.9800 - val_loss: 0.0882 - val_accuracy: 0.9733 - val_auc_5: 0.9934 - val_precision_5: 0.9733 - val_recall_5: 0.9733\n",
      "Epoch 17/100\n",
      "epoch_end | time:  14.04.2021 09:46:11\n",
      "1547/1547 - 1205s - loss: 0.0120 - accuracy: 0.9803 - auc_5: 0.9964 - precision_5: 0.9803 - recall_5: 0.9803 - val_loss: 0.0595 - val_accuracy: 0.9819 - val_auc_5: 0.9964 - val_precision_5: 0.9819 - val_recall_5: 0.9819\n",
      "Epoch 18/100\n",
      "epoch_end | time:  14.04.2021 10:06:36\n",
      "1547/1547 - 1223s - loss: 0.0119 - accuracy: 0.9803 - auc_5: 0.9965 - precision_5: 0.9803 - recall_5: 0.9803 - val_loss: 0.0610 - val_accuracy: 0.9818 - val_auc_5: 0.9966 - val_precision_5: 0.9818 - val_recall_5: 0.9818\n",
      "Epoch 19/100\n",
      "epoch_end | time:  14.04.2021 10:33:02\n",
      "1547/1547 - 1586s - loss: 0.0118 - accuracy: 0.9805 - auc_5: 0.9965 - precision_5: 0.9805 - recall_5: 0.9805 - val_loss: 0.0591 - val_accuracy: 0.9820 - val_auc_5: 0.9967 - val_precision_5: 0.9820 - val_recall_5: 0.9820\n",
      "Epoch 20/100\n",
      "epoch_end | time:  14.04.2021 10:55:36\n",
      "1547/1547 - 1353s - loss: 0.0116 - accuracy: 0.9804 - auc_5: 0.9966 - precision_5: 0.9804 - recall_5: 0.9804 - val_loss: 0.0606 - val_accuracy: 0.9821 - val_auc_5: 0.9965 - val_precision_5: 0.9821 - val_recall_5: 0.9821\n",
      "Epoch 21/100\n",
      "epoch_end | time:  14.04.2021 11:17:57\n",
      "1547/1547 - 1340s - loss: 0.0116 - accuracy: 0.9807 - auc_5: 0.9966 - precision_5: 0.9807 - recall_5: 0.9807 - val_loss: 0.1665 - val_accuracy: 0.9473 - val_auc_5: 0.9826 - val_precision_5: 0.9473 - val_recall_5: 0.9473\n",
      "Epoch 22/100\n",
      "epoch_end | time:  14.04.2021 11:40:25\n",
      "1547/1547 - 1347s - loss: 0.0115 - accuracy: 0.9808 - auc_5: 0.9966 - precision_5: 0.9808 - recall_5: 0.9808 - val_loss: 0.0826 - val_accuracy: 0.9747 - val_auc_5: 0.9946 - val_precision_5: 0.9747 - val_recall_5: 0.9747\n",
      "Epoch 23/100\n",
      "epoch_end | time:  14.04.2021 12:03:03\n",
      "1547/1547 - 1357s - loss: 0.0112 - accuracy: 0.9813 - auc_5: 0.9968 - precision_5: 0.9813 - recall_5: 0.9813 - val_loss: 0.1023 - val_accuracy: 0.9706 - val_auc_5: 0.9914 - val_precision_5: 0.9706 - val_recall_5: 0.9706\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 163, 1) for input Tensor(\"input_6:0\", shape=(None, 163, 1), dtype=float32), but it was called on an input with incompatible shape (None, 128, 1).\n",
      "=========================================\n",
      "VALIDATION: APS: 0.4485924023104777 AUC_ROC: 0.9671087016104283 GINI: 0.9342174032208566\n",
      "TEST: APS: 0.43033458140626457 AUC_ROC: 0.9647397915062433 GINI: 0.9294795830124867\n",
      "=========================================\n",
      "\n",
      "train_begin | time:  14.04.2021 12:03:43\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 163, 1) for input Tensor(\"input_7:0\", shape=(None, 163, 1), dtype=float32), but it was called on an input with incompatible shape (None, 128, 1).\n",
      "epoch_end | time:  14.04.2021 12:26:54\n",
      "1547/1547 - 1385s - loss: 0.0280 - accuracy: 0.9424 - auc_6: 0.9838 - precision_6: 0.9424 - recall_6: 0.9424 - val_loss: 0.1900 - val_accuracy: 0.9391 - val_auc_6: 0.9793 - val_precision_6: 0.9391 - val_recall_6: 0.9391\n",
      "Epoch 2/100\n",
      "epoch_end | time:  14.04.2021 12:49:36\n",
      "1547/1547 - 1361s - loss: 0.0186 - accuracy: 0.9688 - auc_6: 0.9917 - precision_6: 0.9688 - recall_6: 0.9688 - val_loss: 0.1503 - val_accuracy: 0.9543 - val_auc_6: 0.9830 - val_precision_6: 0.9543 - val_recall_6: 0.9543\n",
      "Epoch 3/100\n",
      "epoch_end | time:  14.04.2021 13:12:08\n",
      "1547/1547 - 1351s - loss: 0.0168 - accuracy: 0.9724 - auc_6: 0.9931 - precision_6: 0.9724 - recall_6: 0.9724 - val_loss: 0.1823 - val_accuracy: 0.9435 - val_auc_6: 0.9775 - val_precision_6: 0.9435 - val_recall_6: 0.9435\n",
      "Epoch 4/100\n",
      "epoch_end | time:  14.04.2021 13:34:52\n",
      "1547/1547 - 1362s - loss: 0.0159 - accuracy: 0.9743 - auc_6: 0.9938 - precision_6: 0.9743 - recall_6: 0.9743 - val_loss: 0.1768 - val_accuracy: 0.9446 - val_auc_6: 0.9791 - val_precision_6: 0.9446 - val_recall_6: 0.9446\n",
      "Epoch 5/100\n",
      "epoch_end | time:  14.04.2021 14:06:37\n",
      "1547/1547 - 1904s - loss: 0.0150 - accuracy: 0.9760 - auc_6: 0.9945 - precision_6: 0.9760 - recall_6: 0.9760 - val_loss: 0.1125 - val_accuracy: 0.9669 - val_auc_6: 0.9898 - val_precision_6: 0.9669 - val_recall_6: 0.9669\n",
      "Epoch 6/100\n",
      "epoch_end | time:  14.04.2021 14:39:21\n",
      "1547/1547 - 1963s - loss: 0.0145 - accuracy: 0.9770 - auc_6: 0.9948 - precision_6: 0.9770 - recall_6: 0.9770 - val_loss: 0.0460 - val_accuracy: 0.9863 - val_auc_6: 0.9980 - val_precision_6: 0.9863 - val_recall_6: 0.9863\n",
      "Epoch 7/100\n"
     ]
    }
   ],
   "source": [
    "# Гридсерч сетку настроить:\n",
    "# k = {5, 10}\n",
    "# initial_filters = {5, 10}, # количество фильтров лучше взять 5-10-20 (64 - из 2D)\n",
    "# block_sizes = [3, 3] - для Spider-6; [4, 4] - для Spider-8\n",
    "# conv_kernel_width = w, где for w in [5, 6] \n",
    "# bottleneck_size=2, лучше взять 2-3(общая формула Х = initial_filters + k * bottleneck_size (k={0,n}))\n",
    "# transition_pool_size=2,\n",
    "# transition_pool_stride=2, # здесь наверно лучше поставить страйд = 1 (2 - из 2D наверно)\n",
    "# theta=0.5, # это непонятный параметр для баттлнек сверток 1х1, мб настроить парочку из списка: {0.4, 0.5, 0.6, 1}\n",
    "# initial_conv_width=5,  # здесь лучше поставить 5 (7 - для 2D)\n",
    "# initial_stride=2, # здесь лучше 1 взять (2 - наверно из 2D)\n",
    "# initial_pool_width=3, # этот пулинг лучше 2 взять (3 наверно из 2D)\n",
    "# initial_pool_stride=2  # здесь наверно лучше поставить страйд = 1, а то размерность будет быстро уменьшаться\n",
    "\n",
    "\n",
    "n_features = 163\n",
    "\n",
    "for k_i in [5, 10]:\n",
    "    for theta_i in [0.5, 1]:\n",
    "        for w in [3, 5]:\n",
    "            model_dense = DenseNetCustom(input_shape = (163, 1),\n",
    "                                                 num_outputs=2,\n",
    "                                                 block_sizes= [3, 3],\n",
    "                                                 initial_filters=5,\n",
    "                                                 k=k_i, \n",
    "                                                 conv_kernel_width=5,\n",
    "                                                 bottleneck_size=2,\n",
    "                                                 transition_pool_stride=1,\n",
    "                                                 theta=theta_i,\n",
    "                                                 initial_conv_width=w,\n",
    "                                                 initial_stride=1,\n",
    "                                                 initial_pool_width=2,\n",
    "                                                 initial_pool_stride=2)\n",
    "\n",
    "            model_dense.compile(loss='categorical_crossentropy',\n",
    "                                        optimizer=tf.keras.optimizers.Adam(learning_rate=0.005),\n",
    "                                        metrics=['accuracy', tf.keras.metrics.AUC(),\n",
    "                                                 tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "            VERBOSE = 2 # формат вывода логов обучения\n",
    "            BATCH_SIZE = 512\n",
    "            NB_EPOCH = 100 # максимальное количество эпох, если не сработает EarlyStopping\n",
    "            class_weighting = {0:0.1 , 1:1} #{0:0.00163 , 1:1} можно подбирать как гипер.параметр.\n",
    "\n",
    "            history_logs = model_dense.fit_generator(generator=training_generator,\n",
    "                                                             validation_data= (X_2_2, Y_test_2),\n",
    "                                                             epochs=NB_EPOCH, verbose=VERBOSE,\n",
    "                                                             class_weight=class_weighting,\n",
    "                                                             callbacks=[_time, EarlyStopping(monitor='val_loss', patience=15)])\n",
    "\n",
    "            res_model_dense_3_3 = pd.DataFrame(history_logs.history, columns = history_logs.history.keys())\n",
    "            model_dense.save('model_dense_OpenData_c3c3' + '_k' + str(k_i) + '_t' + str(theta_i) + '_w' + str(w) + '.h5')\n",
    "            res_model_dense_3_3.to_csv('model_dense_OpenData_c3c3' + '_k' + str(k_i) + '_t' + str(theta_i) + '_w' + str(w) + '.csv')\n",
    "\n",
    "            predict_class_val = model_dense.predict(X_2_2)\n",
    "            APS = metrics.average_precision_score(y_test, predict_class_val[:,1])\n",
    "            AUC = metrics.roc_auc_score(y_test, predict_class_val[:,1])\n",
    "            GINI = 2*AUC - 1\n",
    "            print('=========================================')\n",
    "            print('VALIDATION:', 'APS:', APS, 'AUC_ROC:', AUC, 'GINI:', GINI)\n",
    "\n",
    "            predict_class_val = model_dense.predict(X_3_2)\n",
    "            APS = metrics.average_precision_score(y_val, predict_class_val[:,1])\n",
    "            AUC = metrics.roc_auc_score(y_val, predict_class_val[:,1])\n",
    "            GINI = 2*AUC - 1\n",
    "            print('TEST:', 'APS:', APS, 'AUC_ROC:', AUC, 'GINI:', GINI)\n",
    "            print('=========================================')\n",
    "            print('')\n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 5 t= 0.5 w= 3\n",
      "k= 5 t= 0.5 w= 5\n",
      "k= 5 t= 1 w= 3\n",
      "k= 5 t= 1 w= 5\n",
      "k= 10 t= 0.5 w= 3\n",
      "k= 10 t= 0.5 w= 5\n",
      "k= 10 t= 1 w= 3\n",
      "k= 10 t= 1 w= 5\n"
     ]
    }
   ],
   "source": [
    "for k_i in [5, 10]:\n",
    "    for theta_i in [0.5, 1]:\n",
    "        for w in [3, 5]:\n",
    "            print('k=', k_i, 't=', theta_i, 'w=', w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_begin | time:  05.04.2021 20:34:00\n",
      "Epoch 1/100\n",
      "epoch_end | time:  05.04.2021 21:32:47\n",
      "2945/2945 - 3521s - loss: 0.0090 - accuracy: 0.9700 - auc_20: 0.9952 - precision_20: 0.9700 - recall_20: 0.9700 - val_loss: 0.0597 - val_accuracy: 0.9789 - val_auc_20: 0.9978 - val_precision_20: 0.9789 - val_recall_20: 0.9789\n",
      "Epoch 2/100\n",
      "epoch_end | time:  05.04.2021 22:29:00\n",
      "2945/2945 - 3372s - loss: 0.0064 - accuracy: 0.9818 - auc_20: 0.9978 - precision_20: 0.9818 - recall_20: 0.9818 - val_loss: 0.1502 - val_accuracy: 0.9456 - val_auc_20: 0.9852 - val_precision_20: 0.9456 - val_recall_20: 0.9456\n",
      "Epoch 3/100\n",
      "epoch_end | time:  05.04.2021 23:23:57\n",
      "2945/2945 - 3296s - loss: 0.0059 - accuracy: 0.9838 - auc_20: 0.9981 - precision_20: 0.9838 - recall_20: 0.9838 - val_loss: 0.1819 - val_accuracy: 0.9327 - val_auc_20: 0.9790 - val_precision_20: 0.9327 - val_recall_20: 0.9327\n",
      "Epoch 4/100\n",
      "epoch_end | time:  06.04.2021 00:18:30\n",
      "2945/2945 - 3272s - loss: 0.0056 - accuracy: 0.9849 - auc_20: 0.9983 - precision_20: 0.9849 - recall_20: 0.9849 - val_loss: 0.0304 - val_accuracy: 0.9920 - val_auc_20: 0.9993 - val_precision_20: 0.9920 - val_recall_20: 0.9920\n",
      "Epoch 5/100\n",
      "epoch_end | time:  06.04.2021 01:13:00\n",
      "2945/2945 - 3269s - loss: 0.0053 - accuracy: 0.9859 - auc_20: 0.9985 - precision_20: 0.9859 - recall_20: 0.9859 - val_loss: 0.0692 - val_accuracy: 0.9781 - val_auc_20: 0.9965 - val_precision_20: 0.9781 - val_recall_20: 0.9781\n",
      "Epoch 6/100\n",
      "epoch_end | time:  06.04.2021 02:07:51\n",
      "2945/2945 - 3290s - loss: 0.0051 - accuracy: 0.9862 - auc_20: 0.9986 - precision_20: 0.9862 - recall_20: 0.9862 - val_loss: 0.1063 - val_accuracy: 0.9617 - val_auc_20: 0.9931 - val_precision_20: 0.9617 - val_recall_20: 0.9617\n",
      "Epoch 7/100\n",
      "epoch_end | time:  06.04.2021 03:02:32\n",
      "2945/2945 - 3280s - loss: 0.0049 - accuracy: 0.9866 - auc_20: 0.9987 - precision_20: 0.9866 - recall_20: 0.9866 - val_loss: 0.0887 - val_accuracy: 0.9689 - val_auc_20: 0.9950 - val_precision_20: 0.9689 - val_recall_20: 0.9689\n",
      "Epoch 8/100\n",
      "epoch_end | time:  06.04.2021 03:57:08\n",
      "2945/2945 - 3275s - loss: 0.0048 - accuracy: 0.9866 - auc_20: 0.9988 - precision_20: 0.9866 - recall_20: 0.9866 - val_loss: 0.0219 - val_accuracy: 0.9953 - val_auc_20: 0.9993 - val_precision_20: 0.9953 - val_recall_20: 0.9953\n",
      "Epoch 9/100\n",
      "epoch_end | time:  06.04.2021 04:51:38\n",
      "2945/2945 - 3269s - loss: 0.0046 - accuracy: 0.9870 - auc_20: 0.9988 - precision_20: 0.9870 - recall_20: 0.9870 - val_loss: 0.0227 - val_accuracy: 0.9942 - val_auc_20: 0.9994 - val_precision_20: 0.9942 - val_recall_20: 0.9942\n",
      "Epoch 10/100\n",
      "epoch_end | time:  06.04.2021 05:46:28\n",
      "2945/2945 - 3289s - loss: 0.0045 - accuracy: 0.9871 - auc_20: 0.9989 - precision_20: 0.9871 - recall_20: 0.9871 - val_loss: 0.0250 - val_accuracy: 0.9932 - val_auc_20: 0.9994 - val_precision_20: 0.9932 - val_recall_20: 0.9932\n",
      "Epoch 11/100\n",
      "epoch_end | time:  06.04.2021 06:41:25\n",
      "2945/2945 - 3296s - loss: 0.0044 - accuracy: 0.9875 - auc_20: 0.9989 - precision_20: 0.9875 - recall_20: 0.9875 - val_loss: 0.0624 - val_accuracy: 0.9809 - val_auc_20: 0.9980 - val_precision_20: 0.9809 - val_recall_20: 0.9809\n",
      "Epoch 12/100\n",
      "epoch_end | time:  06.04.2021 07:36:24\n",
      "2945/2945 - 3297s - loss: 0.0043 - accuracy: 0.9876 - auc_20: 0.9990 - precision_20: 0.9876 - recall_20: 0.9876 - val_loss: 0.0209 - val_accuracy: 0.9949 - val_auc_20: 0.9994 - val_precision_20: 0.9949 - val_recall_20: 0.9949\n",
      "Epoch 13/100\n",
      "epoch_end | time:  06.04.2021 08:31:27\n",
      "2945/2945 - 3302s - loss: 0.0043 - accuracy: 0.9875 - auc_20: 0.9990 - precision_20: 0.9875 - recall_20: 0.9875 - val_loss: 0.0350 - val_accuracy: 0.9902 - val_auc_20: 0.9991 - val_precision_20: 0.9902 - val_recall_20: 0.9902\n",
      "Epoch 14/100\n",
      "epoch_end | time:  06.04.2021 09:26:28\n",
      "2945/2945 - 3300s - loss: 0.0042 - accuracy: 0.9875 - auc_20: 0.9990 - precision_20: 0.9875 - recall_20: 0.9875 - val_loss: 0.0374 - val_accuracy: 0.9886 - val_auc_20: 0.9989 - val_precision_20: 0.9886 - val_recall_20: 0.9886\n",
      "Epoch 15/100\n",
      "epoch_end | time:  06.04.2021 10:21:34\n",
      "2945/2945 - 3305s - loss: 0.0042 - accuracy: 0.9879 - auc_20: 0.9990 - precision_20: 0.9879 - recall_20: 0.9879 - val_loss: 0.1645 - val_accuracy: 0.9399 - val_auc_20: 0.9831 - val_precision_20: 0.9399 - val_recall_20: 0.9399\n",
      "Epoch 16/100\n",
      "epoch_end | time:  06.04.2021 11:23:31\n",
      "2945/2945 - 3715s - loss: 0.0041 - accuracy: 0.9879 - auc_20: 0.9991 - precision_20: 0.9879 - recall_20: 0.9879 - val_loss: 0.0539 - val_accuracy: 0.9830 - val_auc_20: 0.9980 - val_precision_20: 0.9830 - val_recall_20: 0.9830\n",
      "Epoch 17/100\n",
      "epoch_end | time:  06.04.2021 12:26:37\n",
      "2945/2945 - 3784s - loss: 0.0041 - accuracy: 0.9881 - auc_20: 0.9991 - precision_20: 0.9881 - recall_20: 0.9881 - val_loss: 0.0178 - val_accuracy: 0.9959 - val_auc_20: 0.9992 - val_precision_20: 0.9959 - val_recall_20: 0.9959\n",
      "Epoch 18/100\n",
      "epoch_end | time:  06.04.2021 13:23:53\n",
      "2945/2945 - 3434s - loss: 0.0040 - accuracy: 0.9881 - auc_20: 0.9991 - precision_20: 0.9881 - recall_20: 0.9881 - val_loss: 0.0184 - val_accuracy: 0.9959 - val_auc_20: 0.9994 - val_precision_20: 0.9959 - val_recall_20: 0.9959\n",
      "Epoch 19/100\n",
      "epoch_end | time:  06.04.2021 14:21:27\n",
      "2945/2945 - 3453s - loss: 0.0040 - accuracy: 0.9882 - auc_20: 0.9991 - precision_20: 0.9882 - recall_20: 0.9882 - val_loss: 0.0208 - val_accuracy: 0.9946 - val_auc_20: 0.9992 - val_precision_20: 0.9946 - val_recall_20: 0.9946\n",
      "Epoch 20/100\n",
      "epoch_end | time:  06.04.2021 15:18:59\n",
      "2945/2945 - 3451s - loss: 0.0039 - accuracy: 0.9882 - auc_20: 0.9991 - precision_20: 0.9882 - recall_20: 0.9882 - val_loss: 0.0255 - val_accuracy: 0.9927 - val_auc_20: 0.9993 - val_precision_20: 0.9927 - val_recall_20: 0.9927\n",
      "Epoch 21/100\n",
      "epoch_end | time:  06.04.2021 16:15:31\n",
      "2945/2945 - 3390s - loss: 0.0039 - accuracy: 0.9883 - auc_20: 0.9991 - precision_20: 0.9883 - recall_20: 0.9883 - val_loss: 0.0258 - val_accuracy: 0.9933 - val_auc_20: 0.9993 - val_precision_20: 0.9933 - val_recall_20: 0.9933\n",
      "Epoch 22/100\n",
      "epoch_end | time:  06.04.2021 17:10:36\n",
      "2945/2945 - 3303s - loss: 0.0038 - accuracy: 0.9883 - auc_20: 0.9991 - precision_20: 0.9883 - recall_20: 0.9883 - val_loss: 0.0513 - val_accuracy: 0.9819 - val_auc_20: 0.9983 - val_precision_20: 0.9819 - val_recall_20: 0.9819\n",
      "Epoch 23/100\n",
      "epoch_end | time:  06.04.2021 18:08:31\n",
      "2945/2945 - 3475s - loss: 0.0037 - accuracy: 0.9886 - auc_20: 0.9992 - precision_20: 0.9886 - recall_20: 0.9886 - val_loss: 0.0393 - val_accuracy: 0.9878 - val_auc_20: 0.9989 - val_precision_20: 0.9878 - val_recall_20: 0.9878\n",
      "Epoch 24/100\n",
      "epoch_end | time:  06.04.2021 19:04:42\n",
      "2945/2945 - 3369s - loss: 0.0037 - accuracy: 0.9886 - auc_20: 0.9992 - precision_20: 0.9886 - recall_20: 0.9886 - val_loss: 0.0243 - val_accuracy: 0.9938 - val_auc_20: 0.9992 - val_precision_20: 0.9938 - val_recall_20: 0.9938\n",
      "Epoch 25/100\n",
      "epoch_end | time:  06.04.2021 20:00:46\n",
      "2945/2945 - 3363s - loss: 0.0037 - accuracy: 0.9886 - auc_20: 0.9992 - precision_20: 0.9886 - recall_20: 0.9886 - val_loss: 0.0326 - val_accuracy: 0.9898 - val_auc_20: 0.9991 - val_precision_20: 0.9898 - val_recall_20: 0.9898\n",
      "Epoch 26/100\n",
      "epoch_end | time:  06.04.2021 20:56:38\n",
      "2945/2945 - 3350s - loss: 0.0036 - accuracy: 0.9887 - auc_20: 0.9992 - precision_20: 0.9887 - recall_20: 0.9887 - val_loss: 0.0341 - val_accuracy: 0.9898 - val_auc_20: 0.9987 - val_precision_20: 0.9898 - val_recall_20: 0.9898\n",
      "Epoch 27/100\n",
      "epoch_end | time:  06.04.2021 21:51:55\n",
      "2945/2945 - 3317s - loss: 0.0036 - accuracy: 0.9887 - auc_20: 0.9992 - precision_20: 0.9887 - recall_20: 0.9887 - val_loss: 0.0559 - val_accuracy: 0.9794 - val_auc_20: 0.9980 - val_precision_20: 0.9794 - val_recall_20: 0.9794\n",
      "Epoch 28/100\n",
      "epoch_end | time:  06.04.2021 22:47:20\n",
      "2945/2945 - 3323s - loss: 0.0035 - accuracy: 0.9889 - auc_20: 0.9992 - precision_20: 0.9889 - recall_20: 0.9889 - val_loss: 0.0254 - val_accuracy: 0.9935 - val_auc_20: 0.9994 - val_precision_20: 0.9935 - val_recall_20: 0.9935\n",
      "Epoch 29/100\n",
      "epoch_end | time:  06.04.2021 23:42:49\n",
      "2945/2945 - 3328s - loss: 0.0035 - accuracy: 0.9890 - auc_20: 0.9992 - precision_20: 0.9890 - recall_20: 0.9890 - val_loss: 0.0406 - val_accuracy: 0.9877 - val_auc_20: 0.9984 - val_precision_20: 0.9877 - val_recall_20: 0.9877\n",
      "Epoch 30/100\n",
      "epoch_end | time:  07.04.2021 00:38:06\n",
      "2945/2945 - 3316s - loss: 0.0035 - accuracy: 0.9888 - auc_20: 0.9992 - precision_20: 0.9888 - recall_20: 0.9888 - val_loss: 0.0347 - val_accuracy: 0.9889 - val_auc_20: 0.9989 - val_precision_20: 0.9889 - val_recall_20: 0.9889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      "epoch_end | time:  07.04.2021 01:33:25\n",
      "2945/2945 - 3318s - loss: 0.0035 - accuracy: 0.9890 - auc_20: 0.9992 - precision_20: 0.9890 - recall_20: 0.9890 - val_loss: 0.0203 - val_accuracy: 0.9949 - val_auc_20: 0.9993 - val_precision_20: 0.9949 - val_recall_20: 0.9949\n",
      "Epoch 32/100\n",
      "epoch_end | time:  07.04.2021 02:28:48\n",
      "2945/2945 - 3322s - loss: 0.0034 - accuracy: 0.9892 - auc_20: 0.9992 - precision_20: 0.9892 - recall_20: 0.9892 - val_loss: 0.0333 - val_accuracy: 0.9907 - val_auc_20: 0.9991 - val_precision_20: 0.9907 - val_recall_20: 0.9907\n",
      "=========================================\n",
      "VALIDATION: APS: 0.05275438900597422 AUC_ROC: 0.92122279241821 GINI: 0.8424455848364201\n",
      "TEST: APS: 0.04582367976578686 AUC_ROC: 0.9230978249094874 GINI: 0.8461956498189749\n",
      "=========================================\n",
      "\n",
      "train_begin | time:  07.04.2021 02:30:21\n",
      "Epoch 1/100\n",
      "epoch_end | time:  07.04.2021 03:50:35\n",
      "2945/2945 - 4809s - loss: 0.0083 - accuracy: 0.9733 - auc_21: 0.9959 - precision_21: 0.9733 - recall_21: 0.9733 - val_loss: 0.0480 - val_accuracy: 0.9849 - val_auc_21: 0.9982 - val_precision_21: 0.9849 - val_recall_21: 0.9849\n",
      "Epoch 2/100\n",
      "epoch_end | time:  07.04.2021 05:10:44\n",
      "2945/2945 - 4807s - loss: 0.0058 - accuracy: 0.9845 - auc_21: 0.9981 - precision_21: 0.9845 - recall_21: 0.9845 - val_loss: 0.0510 - val_accuracy: 0.9847 - val_auc_21: 0.9985 - val_precision_21: 0.9847 - val_recall_21: 0.9847\n",
      "Epoch 3/100\n",
      "epoch_end | time:  07.04.2021 06:30:36\n",
      "2945/2945 - 4790s - loss: 0.0054 - accuracy: 0.9860 - auc_21: 0.9984 - precision_21: 0.9860 - recall_21: 0.9860 - val_loss: 0.0348 - val_accuracy: 0.9903 - val_auc_21: 0.9989 - val_precision_21: 0.9903 - val_recall_21: 0.9903\n",
      "Epoch 4/100\n",
      "epoch_end | time:  07.04.2021 07:50:39\n",
      "2945/2945 - 4801s - loss: 0.0051 - accuracy: 0.9868 - auc_21: 0.9986 - precision_21: 0.9868 - recall_21: 0.9868 - val_loss: 0.1304 - val_accuracy: 0.9541 - val_auc_21: 0.9897 - val_precision_21: 0.9541 - val_recall_21: 0.9541\n",
      "Epoch 5/100\n",
      "epoch_end | time:  07.04.2021 09:10:51\n",
      "2945/2945 - 4810s - loss: 0.0048 - accuracy: 0.9873 - auc_21: 0.9987 - precision_21: 0.9873 - recall_21: 0.9873 - val_loss: 0.0579 - val_accuracy: 0.9807 - val_auc_21: 0.9978 - val_precision_21: 0.9807 - val_recall_21: 0.9807\n",
      "Epoch 6/100\n",
      "epoch_end | time:  07.04.2021 10:33:06\n",
      "2945/2945 - 4933s - loss: 0.0045 - accuracy: 0.9877 - auc_21: 0.9988 - precision_21: 0.9877 - recall_21: 0.9877 - val_loss: 0.0319 - val_accuracy: 0.9910 - val_auc_21: 0.9992 - val_precision_21: 0.9910 - val_recall_21: 0.9910\n",
      "Epoch 7/100\n",
      "epoch_end | time:  07.04.2021 12:00:47\n",
      "2945/2945 - 5259s - loss: 0.0044 - accuracy: 0.9878 - auc_21: 0.9989 - precision_21: 0.9878 - recall_21: 0.9878 - val_loss: 0.0550 - val_accuracy: 0.9820 - val_auc_21: 0.9978 - val_precision_21: 0.9820 - val_recall_21: 0.9820\n",
      "Epoch 8/100\n",
      "epoch_end | time:  07.04.2021 13:28:46\n",
      "2945/2945 - 5278s - loss: 0.0043 - accuracy: 0.9881 - auc_21: 0.9990 - precision_21: 0.9881 - recall_21: 0.9881 - val_loss: 0.0335 - val_accuracy: 0.9902 - val_auc_21: 0.9991 - val_precision_21: 0.9902 - val_recall_21: 0.9902\n",
      "Epoch 9/100\n",
      "epoch_end | time:  07.04.2021 15:00:12\n",
      "2945/2945 - 5484s - loss: 0.0042 - accuracy: 0.9881 - auc_21: 0.9990 - precision_21: 0.9881 - recall_21: 0.9881 - val_loss: 0.0282 - val_accuracy: 0.9927 - val_auc_21: 0.9993 - val_precision_21: 0.9927 - val_recall_21: 0.9927\n",
      "Epoch 10/100\n",
      "epoch_end | time:  07.04.2021 16:34:43\n",
      "2945/2945 - 5669s - loss: 0.0041 - accuracy: 0.9884 - auc_21: 0.9991 - precision_21: 0.9884 - recall_21: 0.9884 - val_loss: 0.0902 - val_accuracy: 0.9670 - val_auc_21: 0.9948 - val_precision_21: 0.9670 - val_recall_21: 0.9670\n",
      "Epoch 11/100\n",
      "epoch_end | time:  07.04.2021 18:05:47\n",
      "2945/2945 - 5462s - loss: 0.0039 - accuracy: 0.9885 - auc_21: 0.9991 - precision_21: 0.9885 - recall_21: 0.9885 - val_loss: 0.0233 - val_accuracy: 0.9935 - val_auc_21: 0.9994 - val_precision_21: 0.9935 - val_recall_21: 0.9935\n",
      "Epoch 12/100\n",
      "epoch_end | time:  07.04.2021 19:39:32\n",
      "2945/2945 - 5623s - loss: 0.0038 - accuracy: 0.9887 - auc_21: 0.9991 - precision_21: 0.9887 - recall_21: 0.9887 - val_loss: 0.0306 - val_accuracy: 0.9918 - val_auc_21: 0.9992 - val_precision_21: 0.9918 - val_recall_21: 0.9918\n",
      "Epoch 13/100\n",
      "epoch_end | time:  07.04.2021 21:17:51\n",
      "2945/2945 - 5897s - loss: 0.0037 - accuracy: 0.9888 - auc_21: 0.9992 - precision_21: 0.9888 - recall_21: 0.9888 - val_loss: 0.0349 - val_accuracy: 0.9892 - val_auc_21: 0.9991 - val_precision_21: 0.9892 - val_recall_21: 0.9892\n",
      "Epoch 14/100\n",
      "epoch_end | time:  07.04.2021 22:43:10\n",
      "2945/2945 - 5117s - loss: 0.0037 - accuracy: 0.9891 - auc_21: 0.9992 - precision_21: 0.9891 - recall_21: 0.9891 - val_loss: 0.0309 - val_accuracy: 0.9907 - val_auc_21: 0.9989 - val_precision_21: 0.9907 - val_recall_21: 0.9907\n",
      "Epoch 15/100\n",
      "epoch_end | time:  08.04.2021 00:04:54\n",
      "2945/2945 - 4902s - loss: 0.0036 - accuracy: 0.9892 - auc_21: 0.9992 - precision_21: 0.9892 - recall_21: 0.9892 - val_loss: 0.0256 - val_accuracy: 0.9935 - val_auc_21: 0.9992 - val_precision_21: 0.9935 - val_recall_21: 0.9935\n",
      "Epoch 16/100\n",
      "epoch_end | time:  08.04.2021 01:26:29\n",
      "2945/2945 - 4893s - loss: 0.0035 - accuracy: 0.9893 - auc_21: 0.9992 - precision_21: 0.9893 - recall_21: 0.9893 - val_loss: 0.0393 - val_accuracy: 0.9866 - val_auc_21: 0.9988 - val_precision_21: 0.9866 - val_recall_21: 0.9866\n",
      "Epoch 17/100\n",
      "epoch_end | time:  08.04.2021 02:48:10\n",
      "2945/2945 - 4900s - loss: 0.0034 - accuracy: 0.9895 - auc_21: 0.9992 - precision_21: 0.9895 - recall_21: 0.9895 - val_loss: 0.0281 - val_accuracy: 0.9920 - val_auc_21: 0.9992 - val_precision_21: 0.9920 - val_recall_21: 0.9920\n",
      "Epoch 18/100\n",
      "epoch_end | time:  08.04.2021 04:09:31\n",
      "2945/2945 - 4880s - loss: 0.0034 - accuracy: 0.9894 - auc_21: 0.9992 - precision_21: 0.9894 - recall_21: 0.9894 - val_loss: 0.0205 - val_accuracy: 0.9948 - val_auc_21: 0.9993 - val_precision_21: 0.9948 - val_recall_21: 0.9948\n",
      "Epoch 19/100\n",
      "epoch_end | time:  08.04.2021 05:30:48\n",
      "2945/2945 - 4876s - loss: 0.0033 - accuracy: 0.9896 - auc_21: 0.9993 - precision_21: 0.9896 - recall_21: 0.9896 - val_loss: 0.0296 - val_accuracy: 0.9917 - val_auc_21: 0.9991 - val_precision_21: 0.9917 - val_recall_21: 0.9917\n",
      "Epoch 20/100\n",
      "epoch_end | time:  08.04.2021 06:51:49\n",
      "2945/2945 - 4859s - loss: 0.0032 - accuracy: 0.9896 - auc_21: 0.9993 - precision_21: 0.9896 - recall_21: 0.9896 - val_loss: 0.0419 - val_accuracy: 0.9859 - val_auc_21: 0.9984 - val_precision_21: 0.9859 - val_recall_21: 0.9859\n",
      "Epoch 21/100\n",
      "epoch_end | time:  08.04.2021 08:13:30\n",
      "2945/2945 - 4899s - loss: 0.0031 - accuracy: 0.9898 - auc_21: 0.9993 - precision_21: 0.9898 - recall_21: 0.9898 - val_loss: 0.0326 - val_accuracy: 0.9901 - val_auc_21: 0.9990 - val_precision_21: 0.9901 - val_recall_21: 0.9901\n",
      "Epoch 22/100\n",
      "epoch_end | time:  08.04.2021 09:33:52\n",
      "2945/2945 - 4821s - loss: 0.0031 - accuracy: 0.9899 - auc_21: 0.9993 - precision_21: 0.9899 - recall_21: 0.9899 - val_loss: 0.0217 - val_accuracy: 0.9941 - val_auc_21: 0.9992 - val_precision_21: 0.9941 - val_recall_21: 0.9941\n",
      "Epoch 23/100\n",
      "epoch_end | time:  08.04.2021 10:41:57\n",
      "2945/2945 - 4083s - loss: 0.0030 - accuracy: 0.9900 - auc_21: 0.9993 - precision_21: 0.9900 - recall_21: 0.9900 - val_loss: 0.0211 - val_accuracy: 0.9946 - val_auc_21: 0.9992 - val_precision_21: 0.9946 - val_recall_21: 0.9946\n",
      "Epoch 24/100\n",
      "epoch_end | time:  08.04.2021 11:50:12\n",
      "2945/2945 - 4093s - loss: 0.0029 - accuracy: 0.9901 - auc_21: 0.9993 - precision_21: 0.9901 - recall_21: 0.9901 - val_loss: 0.0199 - val_accuracy: 0.9951 - val_auc_21: 0.9992 - val_precision_21: 0.9951 - val_recall_21: 0.9951\n",
      "Epoch 25/100\n",
      "epoch_end | time:  08.04.2021 12:57:51\n",
      "2945/2945 - 4058s - loss: 0.0029 - accuracy: 0.9903 - auc_21: 0.9994 - precision_21: 0.9903 - recall_21: 0.9903 - val_loss: 0.0220 - val_accuracy: 0.9940 - val_auc_21: 0.9990 - val_precision_21: 0.9940 - val_recall_21: 0.9940\n",
      "Epoch 26/100\n",
      "epoch_end | time:  08.04.2021 14:16:00\n",
      "2945/2945 - 4687s - loss: 0.0028 - accuracy: 0.9904 - auc_21: 0.9994 - precision_21: 0.9904 - recall_21: 0.9904 - val_loss: 0.0233 - val_accuracy: 0.9929 - val_auc_21: 0.9992 - val_precision_21: 0.9929 - val_recall_21: 0.9929\n",
      "Epoch 27/100\n",
      "epoch_end | time:  08.04.2021 15:29:53\n",
      "2945/2945 - 4431s - loss: 0.0028 - accuracy: 0.9906 - auc_21: 0.9994 - precision_21: 0.9906 - recall_21: 0.9906 - val_loss: 0.0242 - val_accuracy: 0.9929 - val_auc_21: 0.9992 - val_precision_21: 0.9929 - val_recall_21: 0.9929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100\n",
      "epoch_end | time:  08.04.2021 16:36:14\n",
      "2945/2945 - 3980s - loss: 0.0027 - accuracy: 0.9906 - auc_21: 0.9994 - precision_21: 0.9906 - recall_21: 0.9906 - val_loss: 0.0238 - val_accuracy: 0.9933 - val_auc_21: 0.9992 - val_precision_21: 0.9933 - val_recall_21: 0.9933\n",
      "Epoch 29/100\n",
      "epoch_end | time:  08.04.2021 17:44:59\n",
      "2945/2945 - 4124s - loss: 0.0027 - accuracy: 0.9907 - auc_21: 0.9994 - precision_21: 0.9907 - recall_21: 0.9907 - val_loss: 0.0258 - val_accuracy: 0.9926 - val_auc_21: 0.9989 - val_precision_21: 0.9926 - val_recall_21: 0.9926\n",
      "Epoch 30/100\n",
      "epoch_end | time:  08.04.2021 19:06:37\n",
      "2945/2945 - 4896s - loss: 0.0026 - accuracy: 0.9908 - auc_21: 0.9994 - precision_21: 0.9908 - recall_21: 0.9908 - val_loss: 0.0198 - val_accuracy: 0.9949 - val_auc_21: 0.9990 - val_precision_21: 0.9949 - val_recall_21: 0.9949\n",
      "Epoch 31/100\n",
      "epoch_end | time:  08.04.2021 20:43:13\n",
      "2945/2945 - 5794s - loss: 0.0026 - accuracy: 0.9910 - auc_21: 0.9994 - precision_21: 0.9910 - recall_21: 0.9910 - val_loss: 0.0214 - val_accuracy: 0.9941 - val_auc_21: 0.9991 - val_precision_21: 0.9941 - val_recall_21: 0.9941\n",
      "Epoch 32/100\n",
      "epoch_end | time:  08.04.2021 21:58:31\n",
      "2945/2945 - 4517s - loss: 0.0025 - accuracy: 0.9909 - auc_21: 0.9994 - precision_21: 0.9909 - recall_21: 0.9909 - val_loss: 0.0193 - val_accuracy: 0.9951 - val_auc_21: 0.9991 - val_precision_21: 0.9951 - val_recall_21: 0.9951\n",
      "Epoch 33/100\n",
      "epoch_end | time:  08.04.2021 23:11:39\n",
      "2945/2945 - 4386s - loss: 0.0025 - accuracy: 0.9910 - auc_21: 0.9994 - precision_21: 0.9910 - recall_21: 0.9910 - val_loss: 0.0213 - val_accuracy: 0.9943 - val_auc_21: 0.9990 - val_precision_21: 0.9943 - val_recall_21: 0.9943\n",
      "Epoch 34/100\n",
      "epoch_end | time:  09.04.2021 00:18:07\n",
      "2945/2945 - 3987s - loss: 0.0024 - accuracy: 0.9912 - auc_21: 0.9994 - precision_21: 0.9912 - recall_21: 0.9912 - val_loss: 0.0208 - val_accuracy: 0.9946 - val_auc_21: 0.9989 - val_precision_21: 0.9946 - val_recall_21: 0.9946\n",
      "Epoch 35/100\n",
      "epoch_end | time:  09.04.2021 01:24:42\n",
      "2945/2945 - 3993s - loss: 0.0024 - accuracy: 0.9911 - auc_21: 0.9994 - precision_21: 0.9911 - recall_21: 0.9911 - val_loss: 0.0290 - val_accuracy: 0.9905 - val_auc_21: 0.9989 - val_precision_21: 0.9905 - val_recall_21: 0.9905\n",
      "Epoch 36/100\n",
      "epoch_end | time:  09.04.2021 02:31:16\n",
      "2945/2945 - 3993s - loss: 0.0023 - accuracy: 0.9914 - auc_21: 0.9994 - precision_21: 0.9914 - recall_21: 0.9914 - val_loss: 0.0197 - val_accuracy: 0.9952 - val_auc_21: 0.9989 - val_precision_21: 0.9952 - val_recall_21: 0.9952\n",
      "Epoch 37/100\n",
      "epoch_end | time:  09.04.2021 03:37:57\n",
      "2945/2945 - 4000s - loss: 0.0023 - accuracy: 0.9914 - auc_21: 0.9994 - precision_21: 0.9914 - recall_21: 0.9914 - val_loss: 0.0217 - val_accuracy: 0.9941 - val_auc_21: 0.9989 - val_precision_21: 0.9941 - val_recall_21: 0.9941\n",
      "Epoch 38/100\n",
      "epoch_end | time:  09.04.2021 04:44:44\n",
      "2945/2945 - 4005s - loss: 0.0023 - accuracy: 0.9915 - auc_21: 0.9995 - precision_21: 0.9915 - recall_21: 0.9915 - val_loss: 0.0224 - val_accuracy: 0.9939 - val_auc_21: 0.9989 - val_precision_21: 0.9939 - val_recall_21: 0.9939\n",
      "Epoch 39/100\n",
      "epoch_end | time:  09.04.2021 05:51:36\n",
      "2945/2945 - 4011s - loss: 0.0023 - accuracy: 0.9916 - auc_21: 0.9995 - precision_21: 0.9916 - recall_21: 0.9916 - val_loss: 0.0263 - val_accuracy: 0.9920 - val_auc_21: 0.9990 - val_precision_21: 0.9920 - val_recall_21: 0.9920\n",
      "Epoch 40/100\n",
      "epoch_end | time:  09.04.2021 06:58:27\n",
      "2945/2945 - 4009s - loss: 0.0022 - accuracy: 0.9917 - auc_21: 0.9995 - precision_21: 0.9917 - recall_21: 0.9917 - val_loss: 0.0209 - val_accuracy: 0.9947 - val_auc_21: 0.9989 - val_precision_21: 0.9947 - val_recall_21: 0.9947\n",
      "Epoch 41/100\n",
      "epoch_end | time:  09.04.2021 08:05:21\n",
      "2945/2945 - 4012s - loss: 0.0022 - accuracy: 0.9918 - auc_21: 0.9995 - precision_21: 0.9918 - recall_21: 0.9918 - val_loss: 0.0316 - val_accuracy: 0.9902 - val_auc_21: 0.9985 - val_precision_21: 0.9902 - val_recall_21: 0.9902\n",
      "Epoch 42/100\n",
      "epoch_end | time:  09.04.2021 09:12:17\n",
      "2945/2945 - 4015s - loss: 0.0021 - accuracy: 0.9920 - auc_21: 0.9995 - precision_21: 0.9920 - recall_21: 0.9920 - val_loss: 0.0203 - val_accuracy: 0.9958 - val_auc_21: 0.9985 - val_precision_21: 0.9958 - val_recall_21: 0.9958\n",
      "Epoch 43/100\n",
      "epoch_end | time:  09.04.2021 10:25:48\n",
      "2945/2945 - 4409s - loss: 0.0021 - accuracy: 0.9920 - auc_21: 0.9995 - precision_21: 0.9920 - recall_21: 0.9920 - val_loss: 0.0212 - val_accuracy: 0.9947 - val_auc_21: 0.9988 - val_precision_21: 0.9947 - val_recall_21: 0.9947\n",
      "Epoch 44/100\n",
      "epoch_end | time:  09.04.2021 11:51:05\n",
      "2945/2945 - 5116s - loss: 0.0020 - accuracy: 0.9922 - auc_21: 0.9995 - precision_21: 0.9922 - recall_21: 0.9922 - val_loss: 0.0339 - val_accuracy: 0.9892 - val_auc_21: 0.9987 - val_precision_21: 0.9892 - val_recall_21: 0.9892\n",
      "Epoch 45/100\n",
      "epoch_end | time:  09.04.2021 13:19:13\n",
      "2945/2945 - 5286s - loss: 0.0020 - accuracy: 0.9923 - auc_21: 0.9995 - precision_21: 0.9923 - recall_21: 0.9923 - val_loss: 0.0336 - val_accuracy: 0.9890 - val_auc_21: 0.9985 - val_precision_21: 0.9890 - val_recall_21: 0.9890\n",
      "Epoch 46/100\n",
      "epoch_end | time:  09.04.2021 14:46:00\n",
      "2945/2945 - 5205s - loss: 0.0020 - accuracy: 0.9922 - auc_21: 0.9995 - precision_21: 0.9922 - recall_21: 0.9922 - val_loss: 0.0228 - val_accuracy: 0.9935 - val_auc_21: 0.9990 - val_precision_21: 0.9935 - val_recall_21: 0.9935\n",
      "Epoch 47/100\n",
      "epoch_end | time:  09.04.2021 16:13:40\n",
      "2945/2945 - 5258s - loss: 0.0020 - accuracy: 0.9923 - auc_21: 0.9995 - precision_21: 0.9923 - recall_21: 0.9923 - val_loss: 0.0204 - val_accuracy: 0.9951 - val_auc_21: 0.9989 - val_precision_21: 0.9951 - val_recall_21: 0.9951\n",
      "=========================================\n",
      "VALIDATION: APS: 0.05704960188981729 AUC_ROC: 0.9145089726474515 GINI: 0.8290179452949029\n",
      "TEST: APS: 0.04967351612589977 AUC_ROC: 0.9068305988298595 GINI: 0.813661197659719\n",
      "=========================================\n",
      "\n",
      "train_begin | time:  09.04.2021 16:16:48\n",
      "Epoch 1/100\n",
      "epoch_end | time:  09.04.2021 17:46:25\n",
      "2945/2945 - 5370s - loss: 0.0084 - accuracy: 0.9735 - auc_22: 0.9958 - precision_22: 0.9735 - recall_22: 0.9735 - val_loss: 0.1639 - val_accuracy: 0.9429 - val_auc_22: 0.9837 - val_precision_22: 0.9429 - val_recall_22: 0.9429\n",
      "Epoch 2/100\n",
      "epoch_end | time:  09.04.2021 19:15:56\n",
      "2945/2945 - 5368s - loss: 0.0061 - accuracy: 0.9838 - auc_22: 0.9980 - precision_22: 0.9838 - recall_22: 0.9838 - val_loss: 0.0861 - val_accuracy: 0.9699 - val_auc_22: 0.9948 - val_precision_22: 0.9699 - val_recall_22: 0.9699\n",
      "Epoch 3/100\n",
      "epoch_end | time:  09.04.2021 20:45:04\n",
      "2945/2945 - 5346s - loss: 0.0055 - accuracy: 0.9858 - auc_22: 0.9984 - precision_22: 0.9858 - recall_22: 0.9858 - val_loss: 0.0240 - val_accuracy: 0.9949 - val_auc_22: 0.9994 - val_precision_22: 0.9949 - val_recall_22: 0.9949\n",
      "Epoch 4/100\n",
      "epoch_end | time:  09.04.2021 22:07:32\n",
      "2945/2945 - 4947s - loss: 0.0051 - accuracy: 0.9864 - auc_22: 0.9986 - precision_22: 0.9864 - recall_22: 0.9864 - val_loss: 0.0282 - val_accuracy: 0.9936 - val_auc_22: 0.9994 - val_precision_22: 0.9936 - val_recall_22: 0.9936\n",
      "Epoch 5/100\n",
      "epoch_end | time:  09.04.2021 23:16:00\n",
      "2945/2945 - 4106s - loss: 0.0049 - accuracy: 0.9869 - auc_22: 0.9987 - precision_22: 0.9869 - recall_22: 0.9869 - val_loss: 0.0202 - val_accuracy: 0.9953 - val_auc_22: 0.9995 - val_precision_22: 0.9953 - val_recall_22: 0.9953\n",
      "Epoch 6/100\n",
      "epoch_end | time:  10.04.2021 00:24:27\n",
      "2945/2945 - 4106s - loss: 0.0047 - accuracy: 0.9875 - auc_22: 0.9988 - precision_22: 0.9875 - recall_22: 0.9875 - val_loss: 0.0309 - val_accuracy: 0.9910 - val_auc_22: 0.9992 - val_precision_22: 0.9910 - val_recall_22: 0.9910\n",
      "Epoch 7/100\n",
      "epoch_end | time:  10.04.2021 01:32:51\n",
      "2945/2945 - 4102s - loss: 0.0045 - accuracy: 0.9877 - auc_22: 0.9989 - precision_22: 0.9877 - recall_22: 0.9877 - val_loss: 0.0255 - val_accuracy: 0.9939 - val_auc_22: 0.9994 - val_precision_22: 0.9939 - val_recall_22: 0.9939\n",
      "Epoch 8/100\n",
      "epoch_end | time:  10.04.2021 02:41:23\n",
      "2945/2945 - 4111s - loss: 0.0044 - accuracy: 0.9880 - auc_22: 0.9989 - precision_22: 0.9880 - recall_22: 0.9880 - val_loss: 0.0371 - val_accuracy: 0.9885 - val_auc_22: 0.9989 - val_precision_22: 0.9885 - val_recall_22: 0.9885\n",
      "Epoch 9/100\n",
      "epoch_end | time:  10.04.2021 03:49:50\n",
      "2945/2945 - 4106s - loss: 0.0043 - accuracy: 0.9881 - auc_22: 0.9990 - precision_22: 0.9881 - recall_22: 0.9881 - val_loss: 0.0259 - val_accuracy: 0.9931 - val_auc_22: 0.9992 - val_precision_22: 0.9931 - val_recall_22: 0.9931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100\n",
      "epoch_end | time:  10.04.2021 04:58:24\n",
      "2945/2945 - 4112s - loss: 0.0042 - accuracy: 0.9882 - auc_22: 0.9990 - precision_22: 0.9882 - recall_22: 0.9882 - val_loss: 0.0295 - val_accuracy: 0.9918 - val_auc_22: 0.9991 - val_precision_22: 0.9918 - val_recall_22: 0.9918\n",
      "Epoch 11/100\n",
      "epoch_end | time:  10.04.2021 06:07:06\n",
      "2945/2945 - 4120s - loss: 0.0040 - accuracy: 0.9885 - auc_22: 0.9990 - precision_22: 0.9885 - recall_22: 0.9885 - val_loss: 0.0204 - val_accuracy: 0.9949 - val_auc_22: 0.9992 - val_precision_22: 0.9949 - val_recall_22: 0.9949\n",
      "Epoch 12/100\n",
      "epoch_end | time:  10.04.2021 07:15:47\n",
      "2945/2945 - 4120s - loss: 0.0039 - accuracy: 0.9886 - auc_22: 0.9991 - precision_22: 0.9886 - recall_22: 0.9886 - val_loss: 0.0221 - val_accuracy: 0.9943 - val_auc_22: 0.9993 - val_precision_22: 0.9943 - val_recall_22: 0.9943\n",
      "Epoch 13/100\n",
      "epoch_end | time:  10.04.2021 08:22:43\n",
      "2945/2945 - 4015s - loss: 0.0039 - accuracy: 0.9888 - auc_22: 0.9991 - precision_22: 0.9888 - recall_22: 0.9888 - val_loss: 0.0647 - val_accuracy: 0.9798 - val_auc_22: 0.9976 - val_precision_22: 0.9798 - val_recall_22: 0.9798\n",
      "Epoch 14/100\n",
      "epoch_end | time:  10.04.2021 09:44:15\n",
      "2945/2945 - 4890s - loss: 0.0037 - accuracy: 0.9889 - auc_22: 0.9991 - precision_22: 0.9889 - recall_22: 0.9889 - val_loss: 0.0479 - val_accuracy: 0.9843 - val_auc_22: 0.9984 - val_precision_22: 0.9843 - val_recall_22: 0.9843\n",
      "Epoch 15/100\n",
      "epoch_end | time:  10.04.2021 11:11:32\n",
      "2945/2945 - 5236s - loss: 0.0036 - accuracy: 0.9892 - auc_22: 0.9992 - precision_22: 0.9892 - recall_22: 0.9892 - val_loss: 0.0282 - val_accuracy: 0.9919 - val_auc_22: 0.9992 - val_precision_22: 0.9919 - val_recall_22: 0.9919\n",
      "Epoch 16/100\n",
      "epoch_end | time:  10.04.2021 12:36:53\n",
      "2945/2945 - 5119s - loss: 0.0036 - accuracy: 0.9892 - auc_22: 0.9992 - precision_22: 0.9892 - recall_22: 0.9892 - val_loss: 0.0167 - val_accuracy: 0.9965 - val_auc_22: 0.9992 - val_precision_22: 0.9965 - val_recall_22: 0.9965\n",
      "Epoch 17/100\n",
      "epoch_end | time:  10.04.2021 13:59:57\n",
      "2945/2945 - 4982s - loss: 0.0035 - accuracy: 0.9892 - auc_22: 0.9992 - precision_22: 0.9892 - recall_22: 0.9892 - val_loss: 0.0249 - val_accuracy: 0.9933 - val_auc_22: 0.9992 - val_precision_22: 0.9933 - val_recall_22: 0.9933\n",
      "Epoch 18/100\n",
      "epoch_end | time:  10.04.2021 15:16:19\n",
      "2945/2945 - 4581s - loss: 0.0034 - accuracy: 0.9895 - auc_22: 0.9992 - precision_22: 0.9895 - recall_22: 0.9895 - val_loss: 0.0309 - val_accuracy: 0.9910 - val_auc_22: 0.9991 - val_precision_22: 0.9910 - val_recall_22: 0.9910\n",
      "Epoch 19/100\n",
      "epoch_end | time:  10.04.2021 16:32:34\n",
      "2945/2945 - 4574s - loss: 0.0033 - accuracy: 0.9896 - auc_22: 0.9992 - precision_22: 0.9896 - recall_22: 0.9896 - val_loss: 0.0189 - val_accuracy: 0.9956 - val_auc_22: 0.9991 - val_precision_22: 0.9956 - val_recall_22: 0.9956\n",
      "Epoch 20/100\n",
      "epoch_end | time:  10.04.2021 17:49:03\n",
      "2945/2945 - 4587s - loss: 0.0033 - accuracy: 0.9897 - auc_22: 0.9993 - precision_22: 0.9897 - recall_22: 0.9897 - val_loss: 0.0223 - val_accuracy: 0.9941 - val_auc_22: 0.9992 - val_precision_22: 0.9941 - val_recall_22: 0.9941\n",
      "Epoch 21/100\n",
      "epoch_end | time:  10.04.2021 19:05:58\n",
      "2945/2945 - 4613s - loss: 0.0032 - accuracy: 0.9898 - auc_22: 0.9993 - precision_22: 0.9898 - recall_22: 0.9898 - val_loss: 0.0677 - val_accuracy: 0.9760 - val_auc_22: 0.9969 - val_precision_22: 0.9760 - val_recall_22: 0.9760\n",
      "Epoch 22/100\n",
      "epoch_end | time:  10.04.2021 20:25:32\n",
      "2945/2945 - 4773s - loss: 0.0032 - accuracy: 0.9897 - auc_22: 0.9993 - precision_22: 0.9897 - recall_22: 0.9897 - val_loss: 0.0240 - val_accuracy: 0.9933 - val_auc_22: 0.9992 - val_precision_22: 0.9933 - val_recall_22: 0.9933\n",
      "Epoch 23/100\n",
      "epoch_end | time:  10.04.2021 21:42:35\n",
      "2945/2945 - 4622s - loss: 0.0031 - accuracy: 0.9900 - auc_22: 0.9993 - precision_22: 0.9900 - recall_22: 0.9900 - val_loss: 0.0254 - val_accuracy: 0.9924 - val_auc_22: 0.9992 - val_precision_22: 0.9924 - val_recall_22: 0.9924\n",
      "Epoch 24/100\n",
      "epoch_end | time:  10.04.2021 23:00:06\n",
      "2945/2945 - 4649s - loss: 0.0030 - accuracy: 0.9901 - auc_22: 0.9993 - precision_22: 0.9901 - recall_22: 0.9901 - val_loss: 0.0193 - val_accuracy: 0.9951 - val_auc_22: 0.9991 - val_precision_22: 0.9951 - val_recall_22: 0.9951\n",
      "Epoch 25/100\n",
      "epoch_end | time:  11.04.2021 00:15:13\n",
      "2945/2945 - 4505s - loss: 0.0029 - accuracy: 0.9902 - auc_22: 0.9993 - precision_22: 0.9902 - recall_22: 0.9902 - val_loss: 0.0831 - val_accuracy: 0.9712 - val_auc_22: 0.9948 - val_precision_22: 0.9712 - val_recall_22: 0.9712\n",
      "Epoch 26/100\n",
      "epoch_end | time:  11.04.2021 01:27:06\n",
      "2945/2945 - 4312s - loss: 0.0029 - accuracy: 0.9904 - auc_22: 0.9993 - precision_22: 0.9904 - recall_22: 0.9904 - val_loss: 0.0254 - val_accuracy: 0.9929 - val_auc_22: 0.9991 - val_precision_22: 0.9929 - val_recall_22: 0.9929\n",
      "Epoch 27/100\n",
      "epoch_end | time:  11.04.2021 02:38:19\n",
      "2945/2945 - 4271s - loss: 0.0029 - accuracy: 0.9904 - auc_22: 0.9994 - precision_22: 0.9904 - recall_22: 0.9904 - val_loss: 0.0195 - val_accuracy: 0.9951 - val_auc_22: 0.9992 - val_precision_22: 0.9951 - val_recall_22: 0.9951\n",
      "Epoch 28/100\n",
      "epoch_end | time:  11.04.2021 03:51:25\n",
      "2945/2945 - 4385s - loss: 0.0028 - accuracy: 0.9905 - auc_22: 0.9994 - precision_22: 0.9905 - recall_22: 0.9905 - val_loss: 0.0212 - val_accuracy: 0.9943 - val_auc_22: 0.9992 - val_precision_22: 0.9943 - val_recall_22: 0.9943\n",
      "Epoch 29/100\n",
      "epoch_end | time:  11.04.2021 05:05:32\n",
      "2945/2945 - 4445s - loss: 0.0028 - accuracy: 0.9905 - auc_22: 0.9993 - precision_22: 0.9905 - recall_22: 0.9905 - val_loss: 0.0303 - val_accuracy: 0.9905 - val_auc_22: 0.9990 - val_precision_22: 0.9905 - val_recall_22: 0.9905\n",
      "Epoch 30/100\n",
      "epoch_end | time:  11.04.2021 06:20:26\n",
      "2945/2945 - 4493s - loss: 0.0027 - accuracy: 0.9908 - auc_22: 0.9994 - precision_22: 0.9908 - recall_22: 0.9908 - val_loss: 0.0245 - val_accuracy: 0.9930 - val_auc_22: 0.9991 - val_precision_22: 0.9930 - val_recall_22: 0.9930\n",
      "Epoch 31/100\n",
      "epoch_end | time:  11.04.2021 07:35:58\n",
      "2945/2945 - 4531s - loss: 0.0027 - accuracy: 0.9908 - auc_22: 0.9994 - precision_22: 0.9908 - recall_22: 0.9908 - val_loss: 0.0210 - val_accuracy: 0.9947 - val_auc_22: 0.9990 - val_precision_22: 0.9947 - val_recall_22: 0.9947\n",
      "=========================================\n",
      "VALIDATION: APS: 0.048437035671872394 AUC_ROC: 0.9134292156505273 GINI: 0.8268584313010545\n",
      "TEST: APS: 0.0485551572956364 AUC_ROC: 0.8965298697861515 GINI: 0.7930597395723029\n",
      "=========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### Дополнительный ГридСерч\n",
    "\n",
    "# Гридсерч сетку настроить:\n",
    "# k = {5, 10}\n",
    "# initial_filters = {5, 10}, # количество фильтров лучше взять 5-10-20 (64 - из 2D)\n",
    "# block_sizes = [3, 3] - для Spider-6; [4, 4] - для Spider-8\n",
    "# conv_kernel_width = w, где for w in [5, 6] \n",
    "# bottleneck_size=2, лучше взять 2-3(общая формула Х = initial_filters + k * bottleneck_size (k={0,n}))\n",
    "# transition_pool_size=2,\n",
    "# transition_pool_stride=2, # здесь лучше поставить страйд = 1 (2 - из 2D)\n",
    "# theta=0.5, # это параметр для баттлнек сверток 1х1, мб настроить парочку из списка: {0.4, 0.5, 0.6, 1}\n",
    "# initial_conv_width=5,  # здесь лучше поставить 5 (7 - для 2D)\n",
    "# initial_stride=2, # здесь лучше 1 взять (2 - из 2D)\n",
    "# initial_pool_width=3, # этот пулинг лучше 2 взять (3 - из 2D)\n",
    "# initial_pool_stride=2  # здесь лучше поставить страйд = 1, а то размерность будет быстро уменьшаться\n",
    "\n",
    "\n",
    "n_features = 163\n",
    "\n",
    "\n",
    "\n",
    "for k_i in [10, 15]:\n",
    "    for theta_i in [0.5]:\n",
    "        for w in [5, 7]:\n",
    "            if ((k_i != 10) or (theta_i != 0.5) or (w != 5)):\n",
    "                if True: #((k_i != 10) or (theta_i != 1) or (w != 3)):\n",
    "                    model_dense = DenseNetCustom(input_shape = (163, 1),\n",
    "                                                 num_outputs=2,\n",
    "                                                 block_sizes= [3, 3],\n",
    "                                                 initial_filters=5,\n",
    "                                                 k=k_i, \n",
    "                                                 conv_kernel_width=5,\n",
    "                                                 bottleneck_size=2,\n",
    "                                                 transition_pool_stride=1,\n",
    "                                                 theta=theta_i,\n",
    "                                                 initial_conv_width=w,\n",
    "                                                 initial_stride=1,\n",
    "                                                 initial_pool_width=2,\n",
    "                                                 initial_pool_stride=2)\n",
    "\n",
    "                    model_dense.compile(loss='categorical_crossentropy',\n",
    "                                        optimizer=tf.keras.optimizers.Adam(learning_rate=0.005),\n",
    "                                        metrics=['accuracy', tf.keras.metrics.AUC(),\n",
    "                                                 tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "                    VERBOSE = 2 # формат вывода логов обучения\n",
    "                    BATCH_SIZE = 512\n",
    "                    NB_EPOCH = 100 # максимальное количество эпох, если не сработает EarlyStopping\n",
    "                    class_weighting = {0:0.05 , 1:1} #{0:0.00163 , 1:1} можно подбирать как гипер.параметр.\n",
    "\n",
    "                    history_logs = model_dense.fit_generator(generator=training_generator,\n",
    "                                                             validation_data= (X_2_2, Y_test_2),\n",
    "                                                             epochs=NB_EPOCH, verbose=VERBOSE,\n",
    "                                                             class_weight=class_weighting,\n",
    "                                                             callbacks=[_time, EarlyStopping(monitor='val_loss', patience=15)])\n",
    "\n",
    "                    res_model_dense_3_3 = pd.DataFrame(history_logs.history, columns = history_logs.history.keys())\n",
    "                    model_dense.save('model_dense_c3c3' + '_k' + str(k_i) + '_t' + str(theta_i) + '_w' + str(w) + '.h5')\n",
    "                    res_model_dense_3_3.to_csv('model_dense_c3c3' + '_k' + str(k_i) + '_t' + str(theta_i) + '_w' + str(w) + '.csv')\n",
    "\n",
    "                    predict_class_val = model_dense.predict(X_2_2)\n",
    "                    APS = metrics.average_precision_score(y_test, predict_class_val[:,1])\n",
    "                    AUC = metrics.roc_auc_score(y_test, predict_class_val[:,1])\n",
    "                    GINI = 2*AUC - 1\n",
    "                    print('=========================================')\n",
    "                    print('VALIDATION:', 'APS:', APS, 'AUC_ROC:', AUC, 'GINI:', GINI)\n",
    "\n",
    "                    predict_class_val = model_dense.predict(X_3_2)\n",
    "                    APS = metrics.average_precision_score(y_val, predict_class_val[:,1])\n",
    "                    AUC = metrics.roc_auc_score(y_val, predict_class_val[:,1])\n",
    "                    GINI = 2*AUC - 1\n",
    "                    print('TEST:', 'APS:', APS, 'AUC_ROC:', AUC, 'GINI:', GINI)\n",
    "                    print('=========================================')\n",
    "                    print('')\n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
