{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing, GridSearch and Training SpiderNet-8 on Open Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import math\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.pyplot import cm\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import collections\n",
    "from collections import OrderedDict, Counter\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import normaltest, kstest, ttest_ind, ttest_rel, mannwhitneyu, wilcoxon, levene, bartlett\n",
    "from scipy.stats import chi2_contingency, fisher_exact, mode, pearsonr, f_oneway, kruskal, spearmanr\n",
    "\n",
    "from rfpimp import *\n",
    "\n",
    "from datetime import datetime\n",
    "import re\n",
    "from seaborn import heatmap\n",
    "import random\n",
    "import statsmodels.distributions.empirical_distribution as edf\n",
    "from scipy.interpolate import interp1d\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from functools import reduce\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n",
    "\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, log_loss, recall_score\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler, PowerTransformer\n",
    "\n",
    "from sklearn.utils import check_consistent_length, column_or_1d, assert_all_finite\n",
    "from sklearn.utils.extmath import stable_cumsum\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import re\n",
    "import gc\n",
    "\n",
    "import os\n",
    "\n",
    "#from sklearn.externals import joblib\n",
    "import joblib\n",
    "\n",
    "from importlib import reload\n",
    "import Filter_and_Grid_Search\n",
    "Filter_and_Grid_Search = reload(Filter_and_Grid_Search)\n",
    "from Filter_and_Grid_Search import stratified_split\n",
    "from Filter_and_Grid_Search import attributes_list, attributes_list_new\n",
    "from Filter_and_Grid_Search import get_s_stat, get_PSI_stat, get_stats_by_month, get_stats, stable_unstable\n",
    "from Filter_and_Grid_Search import stable_unstable_by_month_divide, union_datas, individual_hists_all \n",
    "from Filter_and_Grid_Search import paired_time_hists_by_month, statistics_with_target\n",
    "from Filter_and_Grid_Search import receive_correlations, find_doubles_corr\n",
    "from Filter_and_Grid_Search import statistics_with_target, attributes_list, attributes_list_new, make_standard\n",
    "from Filter_and_Grid_Search import data_preprocessing_train, data_preprocessing_test\n",
    "from Filter_and_Grid_Search import receive_correlations, find_doubles_corr\n",
    "from Filter_and_Grid_Search import stratified_split, two_forests, turn_variables_with_values\n",
    "from Filter_and_Grid_Search import find_meta_params, calculate_vif#, find_meta_params_mem\n",
    "from Filter_and_Grid_Search import plot_meta_2d, data_preprocessing, find_ouliers_iqr\n",
    "from Filter_and_Grid_Search import train_model_receive_stats, simple_b_score_risk\n",
    "from Filter_and_Grid_Search import max_prof_corve, by_month_gini, check_attribute_list_cases\n",
    "\n",
    "from Filter_and_Grid_Search import to_zip, br_correction, br_stat\n",
    "\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import pathlib\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/Share/01 -Risk Desc Science/AntiFraud/Chinese_data/Datasets/\n",
      "D:/Share/safanasev/Python-notebook/AF_ML_chinese/\n"
     ]
    }
   ],
   "source": [
    "PATH_DATA = 'D:/Share/01 -Risk Desc Science/AntiFraud/Chinese_data/Datasets/'\n",
    "PATH = 'D:/Share/safanasev/Python-notebook/AF_ML_chinese/'\n",
    "print(PATH_DATA)\n",
    "print(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/Share/asmirnova5/Python-notebook/AF_ML_chinese/Data Sets\n",
      "D:/Share/asmirnova5/Python-notebook/AF_ML_chinese/Documentation\n",
      "D:/Share/asmirnova5/Python-notebook/AF_ML_chinese/Graphs\n",
      "D:/Share/asmirnova5/Python-notebook/AF_ML_chinese/Modeling\n",
      "D:/Share/asmirnova5/Python-notebook/AF_ML_chinese/SandBox\n",
      "D:/Share/asmirnova5/Python-notebook/AF_ML_chinese/Selection\n",
      "D:/Share/asmirnova5/Python-notebook/AF_ML_chinese/Statistics\n",
      "D:/Share/asmirnova5/Python-notebook/AF_ML_chinese/Selection/csv_from_python\n",
      "D:/Share/asmirnova5/Python-notebook/AF_ML_chinese/Selection/excel\n",
      "D:/Share/asmirnova5/Python-notebook/AF_ML_chinese/Selection/python\n"
     ]
    }
   ],
   "source": [
    "for DIR in ['Data Sets', 'Documentation', 'Graphs', 'Modeling', 'SandBox', 'Selection', 'Statistics']:\n",
    "    PATH_DIR = PATH + DIR\n",
    "    print(PATH_DIR)\n",
    "    pathlib.Path(PATH_DIR).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "for DIR in ['csv_from_python', 'excel', 'python']:\n",
    "    PATH_DIR = PATH + 'Selection/' + DIR\n",
    "    print(PATH_DIR)\n",
    "    pathlib.Path(PATH_DIR).mkdir(parents=True, exist_ok=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'binary'\n",
    "missing_strings = 'MISSING'\n",
    "p_value = 0.05\n",
    "target_dict = {'good': 0, 'bad': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'BAD_FLAG'\n",
    "index_month = 'MONTH_YEAR'\n",
    "list_of_vars_for_strat = ['MONTH_YEAR']\n",
    "sort_by_var = 'APPPOSID'\n",
    "\n",
    "necessary_fields = [target, index_month, sort_by_var]\n",
    "\n",
    "COL_DEL = ['Unnamed: 0', 'PERIOD_7', 'LOSS_90P'] \n",
    "COL_DEL = [x.upper() for x in COL_DEL]\n",
    "COL_TRG = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UNNAMED: 0', 'PERIOD_7', 'LOSS_90P']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COL_DEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BAD_FLAG', 'MONTH_YEAR', 'APPPOSID']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "necessary_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start of selection¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (Input, Activation, Dense, Flatten, Dropout)\n",
    "from tensorflow.keras.layers import (Conv1D, MaxPooling1D, AveragePooling1D)\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import ReLU, Concatenate, GlobalAveragePooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, Callback, LearningRateScheduler\n",
    "#from keras.callbacks import EarlyStopping, Callback\n",
    "\n",
    "# объявляем класс метрик\n",
    "\n",
    "class E_time(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        tm = datetime.strftime(datetime.now(), \"%d.%m.%Y %H:%M:%S\")\n",
    "        print ('train_begin', '| time: ' , tm)\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        tm = datetime.strftime(datetime.now(), \"%d.%m.%Y %H:%M:%S\")\n",
    "        print ('epoch_end', '| time: ' , tm)\n",
    "    \n",
    "        return\n",
    "\n",
    "_time = E_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#если alpha не задано, то не делаем br_correction\n",
    "\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self,  dataset, x_col, y_col,  batch_size=256, num_classes=2, alpha = 0.1, random_state = 42, \n",
    "                 shuffle=True, class_w = None):\n",
    "        self.batch_size = batch_size\n",
    "        self.dataset = dataset\n",
    "        self.x_col = x_col\n",
    "        self.y_col = y_col\n",
    "        self.indices = self.dataset.index.tolist()\n",
    "        self.num_classes = num_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.alpha = alpha\n",
    "        self.random_state = random_state\n",
    "        self.class_w = class_w\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.indices) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        index = self.index[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch = [self.indices[k] for k in index]\n",
    "        \n",
    "        data_tmp = self.dataset.loc[batch]\n",
    "        data_tmp_b = data_tmp[data_tmp[self.y_col] == 1]\n",
    "        data_tmp_b_all = self.dataset[self.dataset[self.y_col] == 1]\n",
    "        X_tmp = data_tmp.head(0)\n",
    "        \n",
    "        \n",
    "        #print(data_tmp_b.shape[0], data_tmp.shape[0], data_tmp_b_all.shape[0])\n",
    "        if (self.alpha is None) and (self.class_w is None):\n",
    "            X = data_tmp[self.x_col] #.reshape(-1)\n",
    "            y = data_tmp[self.y_col] \n",
    "            \n",
    "        elif (self.alpha is None) and self.class_w > 0:\n",
    "            k = (self.class_w*self.batch_size)/(1-self.class_w)\n",
    "            k = k - data_tmp_b.shape[0]\n",
    "            if int(k) < 1:\n",
    "                k = k+1\n",
    "            ix2 = np.random.RandomState(self.random_state + int(k)).choice(data_tmp_b_all.shape[0], int(k))\n",
    "            X_tmp = data_tmp_b_all.iloc[ix2]\n",
    "            data_tmp = data_tmp.append(X_tmp, ignore_index=True)\n",
    "            X = data_tmp[self.x_col] #.reshape(-1)\n",
    "            y = data_tmp[self.y_col]\n",
    "            #print(data_tmp_b.shape[0], data_tmp.shape[0],  data_tmp_b.shape[0]/(data_tmp.shape[0] - X_tmp.shape[0]), np.mean(y)) \n",
    "            \n",
    "            \n",
    "            \n",
    "        else:\n",
    "            if data_tmp_b.shape[0] > 0:\n",
    "                k=(self.alpha*self.batch_size/data_tmp_b.shape[0] -1 )/(1-self.alpha)\n",
    "                for i in range(0,int(k)):\n",
    "                    X_tmp = X_tmp.append(data_tmp_b, ignore_index=True)\n",
    "            else:\n",
    "                k = (self.alpha*self.batch_size)/(1-self.alpha)\n",
    "                ix2 = np.random.RandomState(self.random_state + int(k)).choice(data_tmp_b_all.shape[0], int(k))\n",
    "                X_tmp = data_tmp_b_all.iloc[ix2]\n",
    "                data_tmp_b = X_tmp\n",
    "\n",
    "    #         print('Добавим дробное число строк')    \n",
    "            k_fraction = k - int(k)\n",
    "            n_samples = int(round(data_tmp_b.shape[0]*k_fraction))\n",
    "    #         print(k_fraction, n_samples)\n",
    "\n",
    "            ix = np.random.RandomState(self.random_state).choice(data_tmp_b.shape[0], n_samples)\n",
    "            data_add_fraction = data_tmp_b.iloc[ix]\n",
    "            X_tmp.append(data_add_fraction, ignore_index=True)\n",
    "\n",
    "            data_tmp = data_tmp.append(X_tmp, ignore_index=True)\n",
    "\n",
    "\n",
    "            X = data_tmp[self.x_col] #.reshape(-1)\n",
    "            y = data_tmp[self.y_col]   \n",
    "        #print(sum(self.dataset.loc[batch][self.y_col])/len(index), np.mean(y))\n",
    "        \n",
    "        if self.num_classes > 1:\n",
    "            y = np_utils.to_categorical( y, self.num_classes)\n",
    "            \n",
    "        ####for tf 2.3.0, [np.array(X)], np.array(y)\n",
    "\n",
    "        #return [np.array(X).reshape(X.shape[0], X.shape[1], 1)], np.array(y)\n",
    "        return [np.array(X)], np.array(y)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.index = np.arange(len(self.indices))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'D:/Share/safanasev/Python-notebook/AF_ML_v2_2014/'\n",
    "#загружаем данные для 163 переменных\n",
    "\n",
    "train_for = pd.read_csv(PATH + 'train_163_prep.csv')\n",
    "valid_for = pd.read_csv(PATH + 'valid_163_prep.csv')\n",
    "test_for = pd.read_csv(PATH + 'test_163_prep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_for[target]\n",
    "#y_test = valid_for[target]\n",
    "#y_val = test_for[target]\n",
    "\n",
    "y_test = test_for[target]\n",
    "y_val = valid_for[target]\n",
    "\n",
    "train_for.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "valid_for.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "test_for.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "col = train_for.columns.to_list()\n",
    "col.remove(target)\n",
    "\n",
    "\n",
    "X_1_2 = train_for[col]\n",
    "X_2_2 = valid_for[col]\n",
    "X_3_2 = test_for[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1507599, 163), (1507599, 164), 1507599)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#проверка корректности\n",
    "X_1_2.shape, train_for.shape, len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col = X_2_2.columns\n",
    "y_col = 'BAD_FLAG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#проверка корректности, должно быть везде True\n",
    "print(X_2_2.shape[0] == valid_for.shape[0])\n",
    "print(X_2_2.shape[1] == valid_for.shape[1] - 1)\n",
    "print(len(y_val) == valid_for.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#если alpha не задано, то не делаем br_correction\n",
    "#новая версия, исправлены индексы\n",
    "\n",
    "class DataGenerator_new(tf.keras.utils.Sequence):\n",
    "    def __init__(self,  dataset, x_col, y_col,  batch_size=256, num_classes=2, alpha = 0.1, random_state = 42, \n",
    "                 shuffle=True, class_w = None):\n",
    "        self.batch_size = batch_size\n",
    "        self.dataset = dataset\n",
    "        self.x_col = x_col\n",
    "        self.y_col = y_col\n",
    "        self.indices = self.dataset.index.tolist()\n",
    "        self.num_classes = num_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.alpha = alpha\n",
    "        self.random_state = random_state\n",
    "        self.class_w = class_w\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.indices) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch = [self.indices[k] for k in indexes]\n",
    "        \n",
    "        data_tmp = self.dataset.loc[batch]\n",
    "        data_tmp_b = data_tmp[data_tmp[self.y_col] == 1]\n",
    "        data_tmp_b_all = self.dataset[self.dataset[self.y_col] == 1]\n",
    "        X_tmp = data_tmp.head(0)\n",
    "        \n",
    "        \n",
    "        #print(data_tmp_b.shape[0], data_tmp.shape[0], data_tmp_b_all.shape[0])\n",
    "        if (self.alpha is None) and (self.class_w is None):\n",
    "            X = data_tmp[self.x_col] #.reshape(-1)\n",
    "            y = data_tmp[self.y_col] \n",
    "            \n",
    "        elif (self.alpha is None) and self.class_w > 0:\n",
    "            k = (self.class_w*self.batch_size)/(1-self.class_w)\n",
    "            k = k - data_tmp_b.shape[0]\n",
    "            if int(k) < 1:\n",
    "                k = k+1\n",
    "            ix2 = np.random.RandomState(self.random_state + int(k)).choice(data_tmp_b_all.shape[0], int(k))\n",
    "            X_tmp = data_tmp_b_all.iloc[ix2]\n",
    "            data_tmp = data_tmp.append(X_tmp, ignore_index=True)\n",
    "            X = data_tmp[self.x_col] #.reshape(-1)\n",
    "            y = data_tmp[self.y_col]\n",
    "            #print(data_tmp_b.shape[0], data_tmp.shape[0],  data_tmp_b.shape[0]/(data_tmp.shape[0] - X_tmp.shape[0]), np.mean(y)) \n",
    "            \n",
    "            \n",
    "            \n",
    "        else:\n",
    "            if data_tmp_b.shape[0] > 0:\n",
    "                k=(self.alpha*self.batch_size/data_tmp_b.shape[0] -1 )/(1-self.alpha)\n",
    "                for i in range(0,int(k)):\n",
    "                    X_tmp = X_tmp.append(data_tmp_b, ignore_index=True)\n",
    "            else:\n",
    "                k = (self.alpha*self.batch_size)/(1-self.alpha)\n",
    "                ix2 = np.random.RandomState(self.random_state + int(k)).choice(data_tmp_b_all.shape[0], int(k))\n",
    "                X_tmp = data_tmp_b_all.iloc[ix2]\n",
    "                data_tmp_b = X_tmp\n",
    "\n",
    "    #         print('Добавим дробное число строк')    \n",
    "            k_fraction = k - int(k)\n",
    "            n_samples = int(round(data_tmp_b.shape[0]*k_fraction))\n",
    "    #         print(k_fraction, n_samples)\n",
    "\n",
    "            ix = np.random.RandomState(self.random_state).choice(data_tmp_b.shape[0], n_samples)\n",
    "            data_add_fraction = data_tmp_b.iloc[ix]\n",
    "            X_tmp.append(data_add_fraction, ignore_index=True)\n",
    "\n",
    "            data_tmp = data_tmp.append(X_tmp, ignore_index=True)\n",
    "\n",
    "\n",
    "            X = data_tmp[self.x_col] #.reshape(-1)\n",
    "            y = data_tmp[self.y_col]   \n",
    "        #print(sum(self.dataset.loc[batch][self.y_col])/len(index), np.mean(y))\n",
    "        \n",
    "        if self.num_classes > 1:\n",
    "            y = np_utils.to_categorical( y, self.num_classes)\n",
    "            \n",
    "        ####for tf 2.3.0, [np.array(X)], np.array(y)\n",
    "\n",
    "        return [np.array(X).reshape(X.shape[0], X.shape[1], 1)], np.array(y)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.indices))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = DataGenerator(train_for, x_col, y_col, batch_size=512, alpha = None, class_w = 0.05 )\n",
    "#validation_generator = DataGenerator(valid_for, x_col, y_col, batch_size=valid_for.shape[0], alpha = None, class_w = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_2 = np_utils.to_categorical( y_val, 2) # преобразовываем в 2 класса "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((185400, 163), (185400, 2))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2_2.shape, Y_test_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 29\n",
    "\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.set_random_seed(seed_value)\n",
    "\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "# for later versions:\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, valid_data):\n",
    "        super(Metrics, self).__init__()\n",
    "        self.validation_data = valid_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        val_predict = self.model.predict(self.validation_data[0])[:, 1]\n",
    "        val_targ = self.validation_data[1]\n",
    "        \n",
    "        if len(val_targ.shape) == 2: #and val_targ.shape[1] != 1:\n",
    "            val_targ = val_targ[:,1]\n",
    "\n",
    "        _val_aps = metrics.average_precision_score(val_targ, val_predict)\n",
    "        #_val_recall = metrics.recall_score(val_targ, val_predict)\n",
    "        _val_a = metrics.roc_auc_score(val_targ, val_predict)\n",
    "\n",
    "        logs['val_aps'] = _val_aps\n",
    "        logs['val_a'] = _val_a\n",
    "        print(\" — val_aps:  %f — val_a: %f\" % (_val_aps, _val_a))\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:\\\\Program Files (x86)\\\\Graphviz2.38\\\\bin\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_aug = DataGenerator(aug_for, x_col, y_col, batch_size=512, alpha = None, class_w = 0.05 )\n",
    "training_generator = DataGenerator(train_for, x_col, y_col, batch_size=512, alpha = None, class_w = 0.05 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning_rate=0.005\n",
    "initial_learning_rate = 0.005\n",
    "\n",
    "def lr_step_decay(epoch, lr):\n",
    "    drop_rate = 0.1\n",
    "    epochs_drop = 20.0\n",
    "    \n",
    "    return initial_learning_rate * math.pow(drop_rate, math.floor(epoch/epochs_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import optuna\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "from optuna.trial import TrialState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRID SEARCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SpiderNet-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool(min_pool, n_pool, padding_pool, str_pool, y ):\n",
    "    if y.shape[1] < (min_pool):\n",
    "        \n",
    "        return MaxPooling1D(pool_size = n_pool, padding=padding_pool, strides=1)(y)\n",
    "    else:\n",
    "        return MaxPooling1D(pool_size = n_pool, padding=padding_pool, strides=str_pool)(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spider_model_8block(l2_conv = None, reg = 1E-5 , reg_dense = 1E-5,\n",
    "                 _bias = True,  n_features = 163, n_pool = 2, n_kernel = 5, n_filters = 5, n_strides = 1,\n",
    "                 classes = 2, hidden = 64 , drop_out = 0.25, drop_out_conv = 0.001, drop_out_rate = 4 ,\n",
    "                 padding_pool = 'valid' ,\n",
    "                gl_pool_max = False,\n",
    "                       min_pool = 12, str_pool = None):\n",
    "    \n",
    "    if reg == None:\n",
    "        l2_batch_gamma = None \n",
    "        l2_batch_betta = None\n",
    "    else:\n",
    "        l2_batch_gamma = l2(reg)\n",
    "        l2_batch_betta =l2(reg)\n",
    "    \n",
    "    if reg_dense == None:\n",
    "        kernel_regularizer = None\n",
    "    else:\n",
    "        kernel_regularizer = l2(reg)   \n",
    "    \n",
    "    \n",
    "    x = Input(shape=(  n_features, 1))\n",
    "    n = -2 # для 6 - n = 0, для 8 = -2\n",
    "    y = Conv1D(filters=n_filters, kernel_size=n_kernel, strides=n_strides, padding='same', \n",
    "           use_bias=_bias, kernel_regularizer=l2_conv)(x) \n",
    "\n",
    "    y = BatchNormalization(gamma_regularizer=l2_batch_gamma ,beta_regularizer=l2_batch_betta)(y)\n",
    "    y = ReLU()(y)\n",
    "#y = Dropout(rate=drop_rate)(y)\n",
    "\n",
    "    y = max_pool(min_pool, n_pool, padding_pool, str_pool, y) ##\n",
    "    shortcut1_2 = max_pool(min_pool, n_pool, padding_pool, str_pool, y)## поправить\n",
    "    shortcut1_3 = max_pool(min_pool, n_pool, padding_pool, str_pool, shortcut1_2)##\n",
    "    shortcut1_4 = max_pool(min_pool, n_pool, padding_pool, str_pool, shortcut1_3)##\n",
    "    \n",
    "    shortcut1_5 = max_pool(min_pool, n_pool, padding_pool, str_pool, shortcut1_4)\n",
    "    shortcut1_6 = max_pool(min_pool, n_pool, padding_pool, str_pool, shortcut1_5) #*\n",
    "    shortcut1_7 = max_pool(min_pool, n_pool, padding_pool, str_pool, shortcut1_6) #*\n",
    "\n",
    "    # второй spider-block\n",
    "    y = Conv1D(filters=n_filters*2, kernel_size=n_kernel, strides=n_strides, padding='same',\n",
    "              use_bias=_bias, kernel_regularizer=l2_conv)(y) \n",
    "    y = BatchNormalization(gamma_regularizer=l2_batch_gamma ,beta_regularizer=l2_batch_betta)(y)\n",
    "    y = ReLU()(y)\n",
    "\n",
    "    y = max_pool(min_pool, n_pool, padding_pool, str_pool, y) ##\n",
    "    shortcut2_3 = max_pool(min_pool, n_pool, padding_pool, str_pool, y)##\n",
    "    shortcut2_4 = max_pool(min_pool, n_pool, padding_pool, str_pool, shortcut2_3)##\n",
    "    \n",
    "    shortcut2_5 = max_pool(min_pool, n_pool, padding_pool, str_pool, shortcut2_4)\n",
    "    shortcut2_6 = max_pool(min_pool, n_pool, padding_pool, str_pool, shortcut2_5)\n",
    "    shortcut2_7 = max_pool(min_pool, n_pool, padding_pool, str_pool, shortcut2_6)\n",
    "\n",
    "\n",
    "    y= Concatenate(axis=-1)([shortcut1_2, y])\n",
    "    n = n+1\n",
    "\n",
    "    # третий spider-block\n",
    "    y = Conv1D(filters=n_filters*(3 + 1), kernel_size=n_kernel, strides=n_strides, padding='same',\n",
    "              use_bias=_bias, kernel_regularizer=l2_conv)(y) \n",
    "    y = BatchNormalization(gamma_regularizer=l2_batch_gamma ,beta_regularizer=l2_batch_betta)(y)\n",
    "    y = ReLU()(y)\n",
    "\n",
    "    y = max_pool(min_pool, n_pool, padding_pool, str_pool, y) ##\n",
    "    shortcut3_4 = max_pool(min_pool, n_pool, padding_pool, str_pool, y)##\n",
    "    \n",
    "    shortcut3_5 = max_pool(min_pool, n_pool, padding_pool, str_pool, shortcut3_4)##\n",
    "    shortcut3_6 = max_pool(min_pool, n_pool, padding_pool, str_pool, shortcut3_5)##\n",
    "    shortcut3_7 = max_pool(min_pool, n_pool, padding_pool, str_pool, shortcut3_6)##\n",
    "\n",
    "    y= Concatenate(axis=-1)([shortcut2_3, shortcut1_3, y])\n",
    "    \n",
    "    n = n+1\n",
    "    # четвертый spider-block\n",
    "    y = Conv1D(filters=n_filters*(4 + 1), kernel_size=n_kernel, strides=n_strides, padding='same',\n",
    "              use_bias=_bias, kernel_regularizer=l2_conv)(y) \n",
    "    y = BatchNormalization(gamma_regularizer=l2_batch_gamma ,beta_regularizer=l2_batch_betta)(y)\n",
    "    y = ReLU()(y)\n",
    "\n",
    "    y = max_pool(min_pool, n_pool, padding_pool, str_pool, y) ##\n",
    "    shortcut4_5 = max_pool(min_pool, n_pool, padding_pool, str_pool, y)##\n",
    "    shortcut4_6 = max_pool(min_pool, n_pool, padding_pool, str_pool, shortcut4_5)##\n",
    "    shortcut4_7 = max_pool(min_pool, n_pool, padding_pool, str_pool, shortcut4_6)##\n",
    "\n",
    "    y= Concatenate(axis=-1)([shortcut3_4, shortcut2_4, shortcut1_4, y])\n",
    "    n = n+1\n",
    "    y = Dropout(drop_out_conv*(n**drop_out_rate))(y)\n",
    "    print(n, drop_out_conv*(n**drop_out_rate))\n",
    "\n",
    "    # пятый spider-block\n",
    "    y = Conv1D(filters=n_filters*(5 + 1), kernel_size=n_kernel, strides=n_strides, padding='same',\n",
    "              use_bias=_bias, kernel_regularizer=l2_conv)(y) \n",
    "    y = BatchNormalization(gamma_regularizer=l2_batch_gamma ,beta_regularizer=l2_batch_betta)(y)\n",
    "    y = ReLU()(y)\n",
    "\n",
    "    y = max_pool(min_pool, n_pool, padding_pool, str_pool, y) ##\n",
    "    shortcut5_6 = max_pool(min_pool, n_pool, padding_pool, str_pool, y)\n",
    "    shortcut5_7 = max_pool(min_pool, n_pool, padding_pool, str_pool, shortcut5_6)    \n",
    "    \n",
    "    \n",
    "    y= Concatenate(axis=-1)([shortcut4_5, shortcut3_5, shortcut2_5, shortcut1_5, y])\n",
    "    n = n+1\n",
    "    y = Dropout(drop_out_conv*(n**drop_out_rate))(y)\n",
    "    print(n, drop_out_conv*(n**drop_out_rate))\n",
    "\n",
    "    # шестой spider-block\n",
    "    y = Conv1D(filters=n_filters*(6 + 1), kernel_size=n_kernel, strides=n_strides, padding='same',\n",
    "              use_bias=_bias, kernel_regularizer=l2_conv)(y) \n",
    "    y = BatchNormalization(gamma_regularizer=l2_batch_gamma ,beta_regularizer=l2_batch_betta)(y)\n",
    "    y = ReLU()(y)\n",
    "    \n",
    "    y = max_pool(min_pool, n_pool, padding_pool, str_pool, y) ##\n",
    "    shortcut6_7 = max_pool(min_pool, n_pool, padding_pool, str_pool, y)\n",
    "    \n",
    "    y= Concatenate(axis=-1)([shortcut5_6, shortcut4_6, shortcut3_6, shortcut2_6, shortcut1_6, y])\n",
    "    n = n+1\n",
    "    y = Dropout(drop_out_conv*(n**drop_out_rate))(y)\n",
    "    print(n, drop_out_conv*(n**drop_out_rate))\n",
    "    \n",
    "    \n",
    "    # седьмой блок\n",
    "    y = Conv1D(filters=n_filters*(7 + 1), kernel_size=n_kernel, strides=n_strides, padding='same',\n",
    "              use_bias=_bias, kernel_regularizer=l2_conv)(y) \n",
    "    y = BatchNormalization(gamma_regularizer=l2_batch_gamma ,beta_regularizer=l2_batch_betta)(y)\n",
    "    y = ReLU()(y)\n",
    "    \n",
    "    y = max_pool(min_pool, n_pool, padding_pool, str_pool, y) ##\n",
    "    \n",
    "    y= Concatenate(axis=-1)([shortcut6_7, shortcut5_7, shortcut4_7, shortcut3_7, shortcut2_7, shortcut1_7, y])\n",
    "    n = n+1\n",
    "    y = Dropout(drop_out_conv*(n**drop_out_rate))(y)\n",
    "    print(n, drop_out_conv*(n**drop_out_rate))\n",
    "    \n",
    "     # восьмой блок\n",
    "    y = Conv1D(filters=n_filters*(8 + 1), kernel_size=n_kernel, strides=n_strides, padding='same',\n",
    "              use_bias=_bias, kernel_regularizer=l2_conv)(y) \n",
    "    y = BatchNormalization(gamma_regularizer=l2_batch_gamma ,beta_regularizer=l2_batch_betta)(y)\n",
    "    y = ReLU()(y)\n",
    "    \n",
    "    y = max_pool(min_pool, n_pool, padding_pool, str_pool, y) ##\n",
    "    \n",
    "    if gl_pool_max:\n",
    "        z = GlobalMaxPooling1D()(y)\n",
    "        \n",
    "    else:\n",
    "        z = GlobalAveragePooling1D()(y)\n",
    "    #z = Flatten()(y) #сглаживание, пример использования - https://stackoverflow.com/questions/43237124/what-is-the-role-of-flatten-in-keras\n",
    "    z = Dense(hidden, activation='relu', kernel_regularizer = kernel_regularizer)(z)\n",
    "    z = Dropout(drop_out)(z)\n",
    "    z = Dense(hidden, activation='relu', kernel_regularizer = kernel_regularizer)(z)\n",
    "    z = Dropout(drop_out)(z)\n",
    "    predictions = Dense(classes, activation='softmax')(z)\n",
    "\n",
    "    #model = Sequential()\n",
    "    model_15 = Model(inputs=x, outputs=predictions)\n",
    "    \n",
    "    return model_15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl_p = [False] #0\n",
    "l2_batch = [ 0.0002] #1\n",
    "n_ker = [5, 7] #2\n",
    "n_fil = [ 5, 15] #3\n",
    "d_hidden = [60, 100] #4\n",
    "drop_out = [0.25] #5\n",
    "drop_out_conv = [0.001] #6\n",
    "reg_dense = [ 0.0002] #7\n",
    "min_pool = [ 15] #7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = (False, 0.0002, 7, 5, 64, 0.25, 0.001, 0.0002, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = itertools.product(gl_p, l2_batch, n_ker, n_fil, d_hidden, drop_out, drop_out_conv, reg_dense, min_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (False, 0.0002, 5, 5, 60, 0.25, 0.001, 0.0002, 15)\n",
      "1 (False, 0.0002, 5, 5, 100, 0.25, 0.001, 0.0002, 15)\n",
      "2 (False, 0.0002, 5, 15, 60, 0.25, 0.001, 0.0002, 15)\n",
      "3 (False, 0.0002, 5, 15, 100, 0.25, 0.001, 0.0002, 15)\n",
      "4 (False, 0.0002, 7, 5, 60, 0.25, 0.001, 0.0002, 15)\n",
      "5 (False, 0.0002, 7, 5, 100, 0.25, 0.001, 0.0002, 15)\n",
      "6 (False, 0.0002, 7, 15, 60, 0.25, 0.001, 0.0002, 15)\n",
      "7 (False, 0.0002, 7, 15, 100, 0.25, 0.001, 0.0002, 15)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for p in param:\n",
    "    print(i, p)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(False, 0.0002, 5, 15, 100, 0.25, 0.001, 0.0002, 15)\n",
    "163 (185400, 163) (False, 0.0002, 7, 15, 100, 0.25, 0.001, 0.0002, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = (  (False, 0.0002, 5, 5, 64, 0.25, 0.001, 0.0002, 15) #internal spider6 best\n",
    "         , (False, 0.0002, 3, 10, 100, 0.25, 0.001, 0.0002, 15) #internal cnn best\n",
    "         \n",
    ", (False, 0.0002, 7, 15, 100, 0.25, 0.001, 0.0002, 15) ##\n",
    "        , (False, 0.0002, 7, 15, 60, 0.25, 0.001, 0.0002, 15)\n",
    "        , (False, 0.0002, 7, 5, 100, 0.25, 0.001, 0.0002, 15)\n",
    "        , (False, 0.0002, 7, 5, 60, 0.25, 0.001, 0.0002, 15)\n",
    "        , (False, 0.0002, 5, 15, 100, 0.25, 0.001, 0.0002, 15)) ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = ((False, 0.0002, 7, 5, 64, 0.25, 0.001, 0.0002, 20) ,\n",
    "        (False, 0.0002, 7, 15, 64, 0.25, 0.001, 0.0002, 20) ,\n",
    "        (False, 0.0002, 7, 5, 32, 0.25, 0.001, 0.0002, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_shape = X_2_2.shape[1]\n",
    "inp_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================================================\n",
      "163 (185400, 163) (False, 0.0002, 7, 5, 64, 0.25, 0.001, 0.0002, 20)\n",
      "1 0.001\n",
      "2 0.016\n",
      "3 0.081\n",
      "4 0.256\n",
      "WARNING:tensorflow:From <ipython-input-44-4ff59fd00bba>:32: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "train_begin | time:  14.05.2021 11:23:00\n",
      "Epoch 1/150\n",
      "epoch_end | time:  14.05.2021 11:44:56\n",
      " — val_aps:  0.045093 — val_a: 0.920695\n",
      "2945/2945 - 1345s - loss: 0.0144 - accuracy: 0.9782 - auc: 0.9952 - precision: 0.9782 - recall: 0.9782 - val_loss: 0.2667 - val_accuracy: 0.9474 - val_auc: 0.9708 - val_precision: 0.9474 - val_recall: 0.9474\n",
      "Epoch 2/150\n",
      "epoch_end | time:  14.05.2021 12:06:51\n",
      " — val_aps:  0.030027 — val_a: 0.863341\n",
      "2945/2945 - 1317s - loss: 0.0070 - accuracy: 0.9873 - auc: 0.9978 - precision: 0.9873 - recall: 0.9873 - val_loss: 1.0949 - val_accuracy: 0.6947 - val_auc: 0.7138 - val_precision: 0.6947 - val_recall: 0.6947\n",
      "Epoch 3/150\n",
      "epoch_end | time:  14.05.2021 12:30:16\n",
      " — val_aps:  0.045203 — val_a: 0.926760\n",
      "2945/2945 - 1402s - loss: 0.0063 - accuracy: 0.9876 - auc: 0.9982 - precision: 0.9876 - recall: 0.9876 - val_loss: 0.0670 - val_accuracy: 0.9844 - val_auc: 0.9967 - val_precision: 0.9844 - val_recall: 0.9844\n",
      "Epoch 4/150\n",
      "epoch_end | time:  14.05.2021 12:54:55\n",
      " — val_aps:  0.049562 — val_a: 0.931504\n",
      "2945/2945 - 1481s - loss: 0.0059 - accuracy: 0.9885 - auc: 0.9985 - precision: 0.9885 - recall: 0.9885 - val_loss: 0.0504 - val_accuracy: 0.9852 - val_auc: 0.9979 - val_precision: 0.9852 - val_recall: 0.9852\n",
      "Epoch 5/150\n",
      "epoch_end | time:  14.05.2021 13:18:10\n",
      " — val_aps:  0.063766 — val_a: 0.935393\n",
      "2945/2945 - 1400s - loss: 0.0057 - accuracy: 0.9887 - auc: 0.9986 - precision: 0.9887 - recall: 0.9887 - val_loss: 0.0319 - val_accuracy: 0.9901 - val_auc: 0.9987 - val_precision: 0.9901 - val_recall: 0.9901\n",
      "Epoch 6/150\n",
      "epoch_end | time:  14.05.2021 13:42:15\n",
      " — val_aps:  0.062922 — val_a: 0.940791\n",
      "2945/2945 - 1447s - loss: 0.0054 - accuracy: 0.9886 - auc: 0.9988 - precision: 0.9886 - recall: 0.9886 - val_loss: 0.0291 - val_accuracy: 0.9945 - val_auc: 0.9996 - val_precision: 0.9945 - val_recall: 0.9945\n",
      "Epoch 7/150\n",
      "epoch_end | time:  14.05.2021 14:07:49\n",
      " — val_aps:  0.062061 — val_a: 0.941557\n",
      "2945/2945 - 1562s - loss: 0.0052 - accuracy: 0.9890 - auc: 0.9989 - precision: 0.9890 - recall: 0.9890 - val_loss: 0.0234 - val_accuracy: 0.9943 - val_auc: 0.9993 - val_precision: 0.9943 - val_recall: 0.9943\n",
      "Epoch 8/150\n",
      "epoch_end | time:  14.05.2021 14:33:09\n",
      " — val_aps:  0.059933 — val_a: 0.936135\n",
      "2945/2945 - 1486s - loss: 0.0052 - accuracy: 0.9889 - auc: 0.9989 - precision: 0.9889 - recall: 0.9889 - val_loss: 0.0532 - val_accuracy: 0.9863 - val_auc: 0.9976 - val_precision: 0.9863 - val_recall: 0.9863\n",
      "Epoch 9/150\n",
      "epoch_end | time:  14.05.2021 14:56:28\n",
      " — val_aps:  0.045495 — val_a: 0.928557\n",
      "2945/2945 - 1409s - loss: 0.0050 - accuracy: 0.9888 - auc: 0.9989 - precision: 0.9888 - recall: 0.9888 - val_loss: 0.0315 - val_accuracy: 0.9937 - val_auc: 0.9994 - val_precision: 0.9937 - val_recall: 0.9937\n",
      "Epoch 10/150\n",
      "epoch_end | time:  14.05.2021 15:23:35\n",
      " — val_aps:  0.067824 — val_a: 0.939034\n",
      "2945/2945 - 1656s - loss: 0.0049 - accuracy: 0.9890 - auc: 0.9989 - precision: 0.9890 - recall: 0.9890 - val_loss: 0.0291 - val_accuracy: 0.9923 - val_auc: 0.9992 - val_precision: 0.9923 - val_recall: 0.9923\n",
      "Epoch 11/150\n",
      "epoch_end | time:  14.05.2021 15:52:21\n",
      " — val_aps:  0.060814 — val_a: 0.934686\n",
      "2945/2945 - 1722s - loss: 0.0048 - accuracy: 0.9892 - auc: 0.9990 - precision: 0.9892 - recall: 0.9892 - val_loss: 0.0311 - val_accuracy: 0.9911 - val_auc: 0.9987 - val_precision: 0.9911 - val_recall: 0.9911\n",
      "Epoch 12/150\n",
      "epoch_end | time:  14.05.2021 16:23:21\n",
      " — val_aps:  0.063962 — val_a: 0.943159\n",
      "2945/2945 - 1868s - loss: 0.0047 - accuracy: 0.9893 - auc: 0.9990 - precision: 0.9893 - recall: 0.9893 - val_loss: 0.0222 - val_accuracy: 0.9958 - val_auc: 0.9994 - val_precision: 0.9958 - val_recall: 0.9958\n",
      "Epoch 13/150\n",
      "epoch_end | time:  14.05.2021 16:51:49\n",
      " — val_aps:  0.058978 — val_a: 0.935860\n",
      "2945/2945 - 1693s - loss: 0.0045 - accuracy: 0.9894 - auc: 0.9991 - precision: 0.9894 - recall: 0.9894 - val_loss: 0.0403 - val_accuracy: 0.9897 - val_auc: 0.9990 - val_precision: 0.9897 - val_recall: 0.9897\n",
      "Epoch 14/150\n",
      "epoch_end | time:  14.05.2021 17:20:07\n",
      " — val_aps:  0.065440 — val_a: 0.929256\n",
      "2945/2945 - 1688s - loss: 0.0045 - accuracy: 0.9894 - auc: 0.9991 - precision: 0.9894 - recall: 0.9894 - val_loss: 0.0219 - val_accuracy: 0.9945 - val_auc: 0.9990 - val_precision: 0.9945 - val_recall: 0.9945\n",
      "Epoch 15/150\n",
      "epoch_end | time:  14.05.2021 17:45:55\n",
      " — val_aps:  0.069353 — val_a: 0.920801\n",
      "2945/2945 - 1542s - loss: 0.0044 - accuracy: 0.9891 - auc: 0.9991 - precision: 0.9891 - recall: 0.9891 - val_loss: 0.0486 - val_accuracy: 0.9828 - val_auc: 0.9977 - val_precision: 0.9828 - val_recall: 0.9828\n",
      "Epoch 16/150\n",
      "epoch_end | time:  14.05.2021 18:12:14\n",
      " — val_aps:  0.080369 — val_a: 0.914385\n",
      "2945/2945 - 1584s - loss: 0.0044 - accuracy: 0.9896 - auc: 0.9991 - precision: 0.9896 - recall: 0.9896 - val_loss: 0.0188 - val_accuracy: 0.9967 - val_auc: 0.9982 - val_precision: 0.9967 - val_recall: 0.9967\n",
      "Epoch 17/150\n",
      "epoch_end | time:  14.05.2021 18:38:28\n",
      " — val_aps:  0.054413 — val_a: 0.926670\n",
      "2945/2945 - 1570s - loss: 0.0043 - accuracy: 0.9894 - auc: 0.9991 - precision: 0.9894 - recall: 0.9894 - val_loss: 0.0406 - val_accuracy: 0.9868 - val_auc: 0.9981 - val_precision: 0.9868 - val_recall: 0.9868\n",
      "Epoch 18/150\n",
      "epoch_end | time:  14.05.2021 19:02:55\n",
      " — val_aps:  0.078095 — val_a: 0.931672\n",
      "2945/2945 - 1462s - loss: 0.0042 - accuracy: 0.9895 - auc: 0.9991 - precision: 0.9895 - recall: 0.9895 - val_loss: 0.0217 - val_accuracy: 0.9938 - val_auc: 0.9987 - val_precision: 0.9938 - val_recall: 0.9938\n",
      "Epoch 19/150\n",
      "epoch_end | time:  14.05.2021 19:27:37\n",
      " — val_aps:  0.055762 — val_a: 0.928981\n",
      "2945/2945 - 1483s - loss: 0.0042 - accuracy: 0.9897 - auc: 0.9992 - precision: 0.9897 - recall: 0.9897 - val_loss: 0.0491 - val_accuracy: 0.9812 - val_auc: 0.9980 - val_precision: 0.9812 - val_recall: 0.9812\n",
      "Epoch 20/150\n",
      "epoch_end | time:  14.05.2021 19:52:21\n",
      " — val_aps:  0.062079 — val_a: 0.917462\n",
      "2945/2945 - 1476s - loss: 0.0040 - accuracy: 0.9901 - auc: 0.9992 - precision: 0.9901 - recall: 0.9901 - val_loss: 0.0446 - val_accuracy: 0.9924 - val_auc: 0.9993 - val_precision: 0.9924 - val_recall: 0.9924\n",
      "Epoch 21/150\n",
      "epoch_end | time:  14.05.2021 20:16:48\n",
      " — val_aps:  0.063994 — val_a: 0.926466\n",
      "2945/2945 - 1474s - loss: 0.0041 - accuracy: 0.9897 - auc: 0.9992 - precision: 0.9897 - recall: 0.9897 - val_loss: 0.0236 - val_accuracy: 0.9937 - val_auc: 0.9989 - val_precision: 0.9937 - val_recall: 0.9937\n",
      "Epoch 22/150\n",
      "epoch_end | time:  14.05.2021 20:41:17\n",
      " — val_aps:  0.067233 — val_a: 0.927330\n",
      "2945/2945 - 1469s - loss: 0.0040 - accuracy: 0.9901 - auc: 0.9992 - precision: 0.9901 - recall: 0.9901 - val_loss: 0.0271 - val_accuracy: 0.9961 - val_auc: 0.9995 - val_precision: 0.9961 - val_recall: 0.9961\n",
      "Epoch 23/150\n",
      "epoch_end | time:  14.05.2021 21:05:58\n",
      " — val_aps:  0.071138 — val_a: 0.927922\n",
      "2945/2945 - 1478s - loss: 0.0039 - accuracy: 0.9897 - auc: 0.9992 - precision: 0.9897 - recall: 0.9897 - val_loss: 0.0280 - val_accuracy: 0.9915 - val_auc: 0.9990 - val_precision: 0.9915 - val_recall: 0.9915\n",
      "Epoch 24/150\n",
      "epoch_end | time:  14.05.2021 21:30:34\n",
      " — val_aps:  0.073211 — val_a: 0.931643\n",
      "2945/2945 - 1472s - loss: 0.0039 - accuracy: 0.9901 - auc: 0.9992 - precision: 0.9901 - recall: 0.9901 - val_loss: 0.0217 - val_accuracy: 0.9945 - val_auc: 0.9989 - val_precision: 0.9945 - val_recall: 0.9945\n",
      "Epoch 25/150\n",
      "epoch_end | time:  14.05.2021 21:54:50\n",
      " — val_aps:  0.067257 — val_a: 0.925800\n",
      "2945/2945 - 1458s - loss: 0.0039 - accuracy: 0.9900 - auc: 0.9992 - precision: 0.9900 - recall: 0.9900 - val_loss: 0.0372 - val_accuracy: 0.9880 - val_auc: 0.9988 - val_precision: 0.9880 - val_recall: 0.9880\n",
      "Epoch 26/150\n",
      "epoch_end | time:  14.05.2021 22:19:47\n",
      " — val_aps:  0.065388 — val_a: 0.929072\n",
      "2945/2945 - 1494s - loss: 0.0038 - accuracy: 0.9903 - auc: 0.9993 - precision: 0.9903 - recall: 0.9903 - val_loss: 0.0289 - val_accuracy: 0.9895 - val_auc: 0.9987 - val_precision: 0.9895 - val_recall: 0.9895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/150\n",
      "epoch_end | time:  14.05.2021 22:43:49\n",
      " — val_aps:  0.049221 — val_a: 0.922554\n",
      "2945/2945 - 1436s - loss: 0.0038 - accuracy: 0.9903 - auc: 0.9992 - precision: 0.9903 - recall: 0.9903 - val_loss: 0.0800 - val_accuracy: 0.9769 - val_auc: 0.9947 - val_precision: 0.9769 - val_recall: 0.9769\n",
      "Epoch 28/150\n",
      "epoch_end | time:  14.05.2021 23:08:16\n",
      " — val_aps:  0.049662 — val_a: 0.911226\n",
      "2945/2945 - 1479s - loss: 0.0038 - accuracy: 0.9904 - auc: 0.9992 - precision: 0.9904 - recall: 0.9904 - val_loss: 0.1256 - val_accuracy: 0.9607 - val_auc: 0.9898 - val_precision: 0.9607 - val_recall: 0.9607\n",
      "Epoch 29/150\n",
      "epoch_end | time:  14.05.2021 23:33:29\n",
      " — val_aps:  0.055740 — val_a: 0.924194\n",
      "2945/2945 - 1507s - loss: 0.0037 - accuracy: 0.9906 - auc: 0.9993 - precision: 0.9906 - recall: 0.9906 - val_loss: 0.0566 - val_accuracy: 0.9737 - val_auc: 0.9974 - val_precision: 0.9737 - val_recall: 0.9737\n",
      "Epoch 30/150\n",
      "epoch_end | time:  14.05.2021 23:57:51\n",
      " — val_aps:  0.067841 — val_a: 0.917448\n",
      "2945/2945 - 1462s - loss: 0.0038 - accuracy: 0.9902 - auc: 0.9992 - precision: 0.9902 - recall: 0.9902 - val_loss: 0.0522 - val_accuracy: 0.9782 - val_auc: 0.9977 - val_precision: 0.9782 - val_recall: 0.9782\n",
      "Epoch 31/150\n",
      "epoch_end | time:  15.05.2021 00:22:36\n",
      " — val_aps:  0.066479 — val_a: 0.920998\n",
      "2945/2945 - 1484s - loss: 0.0037 - accuracy: 0.9906 - auc: 0.9993 - precision: 0.9906 - recall: 0.9906 - val_loss: 0.0367 - val_accuracy: 0.9865 - val_auc: 0.9986 - val_precision: 0.9865 - val_recall: 0.9865\n",
      "Epoch 32/150\n",
      "epoch_end | time:  15.05.2021 00:47:06\n",
      " — val_aps:  0.064096 — val_a: 0.915610\n",
      "2945/2945 - 1471s - loss: 0.0036 - accuracy: 0.9905 - auc: 0.9993 - precision: 0.9905 - recall: 0.9905 - val_loss: 0.0216 - val_accuracy: 0.9966 - val_auc: 0.9981 - val_precision: 0.9966 - val_recall: 0.9966\n",
      "Epoch 33/150\n",
      "epoch_end | time:  15.05.2021 01:11:46\n",
      " — val_aps:  0.050994 — val_a: 0.909396\n",
      "2945/2945 - 1478s - loss: 0.0037 - accuracy: 0.9907 - auc: 0.9993 - precision: 0.9907 - recall: 0.9907 - val_loss: 0.0519 - val_accuracy: 0.9822 - val_auc: 0.9975 - val_precision: 0.9822 - val_recall: 0.9822\n",
      "Epoch 34/150\n",
      "epoch_end | time:  15.05.2021 01:36:43\n",
      " — val_aps:  0.064317 — val_a: 0.917150\n",
      "2945/2945 - 1499s - loss: 0.0036 - accuracy: 0.9905 - auc: 0.9993 - precision: 0.9905 - recall: 0.9905 - val_loss: 0.0217 - val_accuracy: 0.9957 - val_auc: 0.9990 - val_precision: 0.9957 - val_recall: 0.9957\n",
      "Epoch 35/150\n",
      "epoch_end | time:  15.05.2021 02:02:02\n",
      " — val_aps:  0.063549 — val_a: 0.922409\n",
      "2945/2945 - 1518s - loss: 0.0036 - accuracy: 0.9907 - auc: 0.9993 - precision: 0.9907 - recall: 0.9907 - val_loss: 0.0265 - val_accuracy: 0.9925 - val_auc: 0.9985 - val_precision: 0.9925 - val_recall: 0.9925\n",
      "Epoch 36/150\n",
      "epoch_end | time:  15.05.2021 02:27:03\n",
      " — val_aps:  0.070147 — val_a: 0.912565\n",
      "2945/2945 - 1502s - loss: 0.0035 - accuracy: 0.9906 - auc: 0.9993 - precision: 0.9906 - recall: 0.9906 - val_loss: 0.0240 - val_accuracy: 0.9942 - val_auc: 0.9986 - val_precision: 0.9942 - val_recall: 0.9942\n",
      "model_spider8_internal_grid_20_7_5_64_0.0002_200515_2 valid_for_train:  0.8251300936843902 0.07014745856378353 | test:  0.8448725437966713 0.06797556658189371\n",
      "=====================================================================================================\n",
      "163 (185400, 163) (False, 0.0002, 7, 15, 64, 0.25, 0.001, 0.0002, 20)\n",
      "1 0.001\n",
      "2 0.016\n",
      "3 0.081\n",
      "4 0.256\n",
      "train_begin | time:  15.05.2021 02:30:19\n",
      "Epoch 1/150\n",
      "epoch_end | time:  15.05.2021 04:46:59\n",
      " — val_aps:  0.054825 — val_a: 0.935004\n",
      "2945/2945 - 8305s - loss: 0.0188 - accuracy: 0.9747 - auc_1: 0.9951 - precision_1: 0.9747 - recall_1: 0.9747 - val_loss: 0.1175 - val_accuracy: 0.9622 - val_auc_1: 0.9909 - val_precision_1: 0.9622 - val_recall_1: 0.9622\n",
      "Epoch 2/150\n",
      "epoch_end | time:  15.05.2021 07:02:01\n",
      " — val_aps:  0.084973 — val_a: 0.942728\n",
      "2945/2945 - 8102s - loss: 0.0066 - accuracy: 0.9878 - auc_1: 0.9981 - precision_1: 0.9878 - recall_1: 0.9878 - val_loss: 0.0176 - val_accuracy: 0.9968 - val_auc_1: 0.9991 - val_precision_1: 0.9968 - val_recall_1: 0.9968\n",
      "Epoch 3/150\n",
      "epoch_end | time:  15.05.2021 09:14:05\n",
      " — val_aps:  0.063697 — val_a: 0.942090\n",
      "2945/2945 - 7919s - loss: 0.0060 - accuracy: 0.9884 - auc_1: 0.9984 - precision_1: 0.9884 - recall_1: 0.9884 - val_loss: 0.0558 - val_accuracy: 0.9855 - val_auc_1: 0.9981 - val_precision_1: 0.9855 - val_recall_1: 0.9855\n",
      "Epoch 4/150\n",
      "epoch_end | time:  15.05.2021 11:10:14\n",
      " — val_aps:  0.059302 — val_a: 0.937267\n",
      "2945/2945 - 6932s - loss: 0.0056 - accuracy: 0.9881 - auc_1: 0.9987 - precision_1: 0.9881 - recall_1: 0.9881 - val_loss: 0.0899 - val_accuracy: 0.9697 - val_auc_1: 0.9943 - val_precision_1: 0.9697 - val_recall_1: 0.9697\n",
      "Epoch 5/150\n",
      "epoch_end | time:  15.05.2021 12:54:02\n",
      " — val_aps:  0.066677 — val_a: 0.943118\n",
      "2945/2945 - 6223s - loss: 0.0053 - accuracy: 0.9887 - auc_1: 0.9989 - precision_1: 0.9887 - recall_1: 0.9887 - val_loss: 0.0252 - val_accuracy: 0.9956 - val_auc_1: 0.9996 - val_precision_1: 0.9956 - val_recall_1: 0.9956\n",
      "Epoch 6/150\n",
      "epoch_end | time:  15.05.2021 14:38:23\n",
      " — val_aps:  0.097234 — val_a: 0.940676\n",
      "2945/2945 - 6257s - loss: 0.0050 - accuracy: 0.9889 - auc_1: 0.9990 - precision_1: 0.9889 - recall_1: 0.9889 - val_loss: 0.0205 - val_accuracy: 0.9961 - val_auc_1: 0.9994 - val_precision_1: 0.9961 - val_recall_1: 0.9961\n",
      "Epoch 7/150\n",
      "epoch_end | time:  15.05.2021 16:22:35\n",
      " — val_aps:  0.089744 — val_a: 0.933559\n",
      "2945/2945 - 6252s - loss: 0.0048 - accuracy: 0.9888 - auc_1: 0.9990 - precision_1: 0.9888 - recall_1: 0.9888 - val_loss: 0.0415 - val_accuracy: 0.9919 - val_auc_1: 0.9993 - val_precision_1: 0.9919 - val_recall_1: 0.9919\n",
      "Epoch 8/150\n",
      "epoch_end | time:  15.05.2021 18:04:27\n",
      " — val_aps:  0.078552 — val_a: 0.936034\n",
      "2945/2945 - 6110s - loss: 0.0046 - accuracy: 0.9890 - auc_1: 0.9991 - precision_1: 0.9890 - recall_1: 0.9890 - val_loss: 0.0221 - val_accuracy: 0.9940 - val_auc_1: 0.9991 - val_precision_1: 0.9940 - val_recall_1: 0.9940\n",
      "Epoch 9/150\n",
      "epoch_end | time:  15.05.2021 19:45:54\n",
      " — val_aps:  0.063056 — val_a: 0.943567\n",
      "2945/2945 - 6084s - loss: 0.0045 - accuracy: 0.9894 - auc_1: 0.9991 - precision_1: 0.9894 - recall_1: 0.9894 - val_loss: 0.0318 - val_accuracy: 0.9896 - val_auc_1: 0.9991 - val_precision_1: 0.9896 - val_recall_1: 0.9896\n",
      "Epoch 10/150\n",
      "epoch_end | time:  15.05.2021 21:27:00\n",
      " — val_aps:  0.068505 — val_a: 0.919353\n",
      "2945/2945 - 6065s - loss: 0.0044 - accuracy: 0.9896 - auc_1: 0.9992 - precision_1: 0.9896 - recall_1: 0.9896 - val_loss: 0.0212 - val_accuracy: 0.9967 - val_auc_1: 0.9978 - val_precision_1: 0.9967 - val_recall_1: 0.9967\n",
      "Epoch 11/150\n",
      "epoch_end | time:  15.05.2021 23:07:48\n",
      " — val_aps:  0.070662 — val_a: 0.936277\n",
      "2945/2945 - 6048s - loss: 0.0042 - accuracy: 0.9896 - auc_1: 0.9992 - precision_1: 0.9896 - recall_1: 0.9896 - val_loss: 0.0176 - val_accuracy: 0.9964 - val_auc_1: 0.9991 - val_precision_1: 0.9964 - val_recall_1: 0.9964\n",
      "Epoch 12/150\n",
      "epoch_end | time:  16.05.2021 00:49:50\n",
      " — val_aps:  0.065349 — val_a: 0.930463\n",
      "2945/2945 - 6127s - loss: 0.0042 - accuracy: 0.9896 - auc_1: 0.9992 - precision_1: 0.9896 - recall_1: 0.9896 - val_loss: 0.1757 - val_accuracy: 0.9289 - val_auc_1: 0.9813 - val_precision_1: 0.9289 - val_recall_1: 0.9289\n",
      "Epoch 13/150\n",
      "epoch_end | time:  16.05.2021 02:32:54\n",
      " — val_aps:  0.064499 — val_a: 0.931218\n",
      "2945/2945 - 6173s - loss: 0.0040 - accuracy: 0.9898 - auc_1: 0.9992 - precision_1: 0.9898 - recall_1: 0.9898 - val_loss: 0.0732 - val_accuracy: 0.9785 - val_auc_1: 0.9978 - val_precision_1: 0.9785 - val_recall_1: 0.9785\n",
      "Epoch 14/150\n",
      "epoch_end | time:  16.05.2021 04:15:54\n",
      " — val_aps:  0.079353 — val_a: 0.939240\n",
      "2945/2945 - 6178s - loss: 0.0040 - accuracy: 0.9896 - auc_1: 0.9992 - precision_1: 0.9896 - recall_1: 0.9896 - val_loss: 0.0171 - val_accuracy: 0.9968 - val_auc_1: 0.9991 - val_precision_1: 0.9968 - val_recall_1: 0.9968\n",
      "Epoch 15/150\n",
      "epoch_end | time:  16.05.2021 05:59:03\n",
      " — val_aps:  0.068273 — val_a: 0.931659\n",
      "2945/2945 - 6187s - loss: 0.0039 - accuracy: 0.9900 - auc_1: 0.9993 - precision_1: 0.9900 - recall_1: 0.9900 - val_loss: 0.0251 - val_accuracy: 0.9938 - val_auc_1: 0.9984 - val_precision_1: 0.9938 - val_recall_1: 0.9938\n",
      "Epoch 16/150\n",
      "epoch_end | time:  16.05.2021 07:40:13\n",
      " — val_aps:  0.033532 — val_a: 0.897373\n",
      "2945/2945 - 6068s - loss: 0.0038 - accuracy: 0.9902 - auc_1: 0.9993 - precision_1: 0.9902 - recall_1: 0.9902 - val_loss: 0.4071 - val_accuracy: 0.8981 - val_auc_1: 0.9542 - val_precision_1: 0.8981 - val_recall_1: 0.8981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/150\n",
      "epoch_end | time:  16.05.2021 09:21:30\n",
      " — val_aps:  0.059671 — val_a: 0.939372\n",
      "2945/2945 - 6074s - loss: 0.0036 - accuracy: 0.9907 - auc_1: 0.9993 - precision_1: 0.9907 - recall_1: 0.9907 - val_loss: 0.0474 - val_accuracy: 0.9851 - val_auc_1: 0.9980 - val_precision_1: 0.9851 - val_recall_1: 0.9851\n",
      "Epoch 18/150\n",
      "epoch_end | time:  16.05.2021 11:02:12\n",
      " — val_aps:  0.067503 — val_a: 0.932378\n",
      "2945/2945 - 6041s - loss: 0.0036 - accuracy: 0.9905 - auc_1: 0.9993 - precision_1: 0.9905 - recall_1: 0.9905 - val_loss: 0.0405 - val_accuracy: 0.9823 - val_auc_1: 0.9986 - val_precision_1: 0.9823 - val_recall_1: 0.9823\n",
      "Epoch 19/150\n",
      "epoch_end | time:  16.05.2021 12:43:33\n",
      " — val_aps:  0.059075 — val_a: 0.939470\n",
      "2945/2945 - 6079s - loss: 0.0035 - accuracy: 0.9908 - auc_1: 0.9994 - precision_1: 0.9908 - recall_1: 0.9908 - val_loss: 0.0355 - val_accuracy: 0.9884 - val_auc_1: 0.9986 - val_precision_1: 0.9884 - val_recall_1: 0.9884\n",
      "Epoch 20/150\n",
      "epoch_end | time:  16.05.2021 14:24:28\n",
      " — val_aps:  0.062673 — val_a: 0.929305\n",
      "2945/2945 - 6053s - loss: 0.0034 - accuracy: 0.9907 - auc_1: 0.9994 - precision_1: 0.9907 - recall_1: 0.9907 - val_loss: 0.0428 - val_accuracy: 0.9844 - val_auc_1: 0.9981 - val_precision_1: 0.9844 - val_recall_1: 0.9844\n",
      "Epoch 21/150\n",
      "epoch_end | time:  16.05.2021 16:05:32\n",
      " — val_aps:  0.077710 — val_a: 0.918651\n",
      "2945/2945 - 6060s - loss: 0.0033 - accuracy: 0.9908 - auc_1: 0.9994 - precision_1: 0.9908 - recall_1: 0.9908 - val_loss: 0.0297 - val_accuracy: 0.9927 - val_auc_1: 0.9993 - val_precision_1: 0.9927 - val_recall_1: 0.9927\n",
      "Epoch 22/150\n",
      "epoch_end | time:  16.05.2021 17:46:43\n",
      " — val_aps:  0.029081 — val_a: 0.892768\n",
      "2945/2945 - 6078s - loss: 0.0034 - accuracy: 0.9911 - auc_1: 0.9994 - precision_1: 0.9911 - recall_1: 0.9911 - val_loss: 0.1740 - val_accuracy: 0.9413 - val_auc_1: 0.9810 - val_precision_1: 0.9413 - val_recall_1: 0.9413\n",
      "Epoch 23/150\n",
      "epoch_end | time:  16.05.2021 19:28:56\n",
      " — val_aps:  0.056244 — val_a: 0.922088\n",
      "2945/2945 - 6131s - loss: 0.0033 - accuracy: 0.9914 - auc_1: 0.9994 - precision_1: 0.9914 - recall_1: 0.9914 - val_loss: 0.0224 - val_accuracy: 0.9955 - val_auc_1: 0.9985 - val_precision_1: 0.9955 - val_recall_1: 0.9955\n",
      "Epoch 24/150\n",
      "epoch_end | time:  16.05.2021 21:11:07\n",
      " — val_aps:  0.057329 — val_a: 0.897923\n",
      "2945/2945 - 6129s - loss: 0.0032 - accuracy: 0.9915 - auc_1: 0.9994 - precision_1: 0.9915 - recall_1: 0.9915 - val_loss: 0.0267 - val_accuracy: 0.9947 - val_auc_1: 0.9981 - val_precision_1: 0.9947 - val_recall_1: 0.9947\n",
      "Epoch 25/150\n",
      "epoch_end | time:  16.05.2021 22:53:17\n",
      " — val_aps:  0.039752 — val_a: 0.901739\n",
      "2945/2945 - 6127s - loss: 0.0033 - accuracy: 0.9912 - auc_1: 0.9994 - precision_1: 0.9912 - recall_1: 0.9912 - val_loss: 0.0807 - val_accuracy: 0.9750 - val_auc_1: 0.9950 - val_precision_1: 0.9750 - val_recall_1: 0.9750\n",
      "Epoch 26/150\n",
      "epoch_end | time:  17.05.2021 00:36:20\n",
      " — val_aps:  0.072773 — val_a: 0.922317\n",
      "2945/2945 - 6180s - loss: 0.0032 - accuracy: 0.9919 - auc_1: 0.9994 - precision_1: 0.9919 - recall_1: 0.9919 - val_loss: 0.2651 - val_accuracy: 0.8907 - val_auc_1: 0.9585 - val_precision_1: 0.8907 - val_recall_1: 0.8907\n",
      "Epoch 27/150\n",
      "epoch_end | time:  17.05.2021 02:20:35\n",
      " — val_aps:  0.064606 — val_a: 0.895932\n",
      "2945/2945 - 6259s - loss: 0.0032 - accuracy: 0.9919 - auc_1: 0.9994 - precision_1: 0.9919 - recall_1: 0.9919 - val_loss: 0.0246 - val_accuracy: 0.9950 - val_auc_1: 0.9981 - val_precision_1: 0.9950 - val_recall_1: 0.9950\n",
      "Epoch 28/150\n",
      "epoch_end | time:  17.05.2021 04:04:54\n",
      " — val_aps:  0.057956 — val_a: 0.873515\n",
      "2945/2945 - 6257s - loss: 0.0031 - accuracy: 0.9921 - auc_1: 0.9994 - precision_1: 0.9921 - recall_1: 0.9921 - val_loss: 0.0312 - val_accuracy: 0.9966 - val_auc_1: 0.9973 - val_precision_1: 0.9966 - val_recall_1: 0.9966\n",
      "Epoch 29/150\n",
      "epoch_end | time:  17.05.2021 05:49:14\n",
      " — val_aps:  0.043325 — val_a: 0.894377\n",
      "2945/2945 - 6257s - loss: 0.0030 - accuracy: 0.9921 - auc_1: 0.9995 - precision_1: 0.9921 - recall_1: 0.9921 - val_loss: 0.0359 - val_accuracy: 0.9916 - val_auc_1: 0.9975 - val_precision_1: 0.9916 - val_recall_1: 0.9916\n",
      "Epoch 30/150\n",
      "epoch_end | time:  17.05.2021 07:33:37\n",
      " — val_aps:  0.038227 — val_a: 0.899201\n",
      "2945/2945 - 6262s - loss: 0.0030 - accuracy: 0.9924 - auc_1: 0.9995 - precision_1: 0.9924 - recall_1: 0.9924 - val_loss: 0.1959 - val_accuracy: 0.9225 - val_auc_1: 0.9812 - val_precision_1: 0.9225 - val_recall_1: 0.9225\n",
      "Epoch 31/150\n",
      "epoch_end | time:  17.05.2021 09:17:58\n",
      " — val_aps:  0.062448 — val_a: 0.895990\n",
      "2945/2945 - 6258s - loss: 0.0029 - accuracy: 0.9925 - auc_1: 0.9995 - precision_1: 0.9925 - recall_1: 0.9925 - val_loss: 0.0260 - val_accuracy: 0.9958 - val_auc_1: 0.9978 - val_precision_1: 0.9958 - val_recall_1: 0.9958\n",
      "Epoch 32/150\n",
      "epoch_end | time:  17.05.2021 11:00:47\n",
      " — val_aps:  0.052821 — val_a: 0.921919\n",
      "2945/2945 - 6158s - loss: 0.0029 - accuracy: 0.9927 - auc_1: 0.9994 - precision_1: 0.9927 - recall_1: 0.9927 - val_loss: 0.0406 - val_accuracy: 0.9903 - val_auc_1: 0.9972 - val_precision_1: 0.9903 - val_recall_1: 0.9903\n",
      "Epoch 33/150\n",
      "epoch_end | time:  17.05.2021 12:43:29\n",
      " — val_aps:  0.056484 — val_a: 0.915947\n",
      "2945/2945 - 6157s - loss: 0.0029 - accuracy: 0.9929 - auc_1: 0.9995 - precision_1: 0.9929 - recall_1: 0.9929 - val_loss: 0.0336 - val_accuracy: 0.9902 - val_auc_1: 0.9982 - val_precision_1: 0.9902 - val_recall_1: 0.9902\n",
      "Epoch 34/150\n",
      "epoch_end | time:  17.05.2021 14:28:35\n",
      " — val_aps:  0.059512 — val_a: 0.892767\n",
      "2945/2945 - 6315s - loss: 0.0029 - accuracy: 0.9926 - auc_1: 0.9995 - precision_1: 0.9926 - recall_1: 0.9926 - val_loss: 0.0302 - val_accuracy: 0.9962 - val_auc_1: 0.9975 - val_precision_1: 0.9962 - val_recall_1: 0.9962\n",
      "model_spider8_internal_grid_20_7_15_64_0.0002_200517_14 valid_for_train:  0.7855346502861105 0.05951212572382848 | test:  0.7622188052192906 0.05667819906319128\n",
      "=====================================================================================================\n",
      "163 (185400, 163) (False, 0.0002, 7, 5, 32, 0.25, 0.001, 0.0002, 20)\n",
      "1 0.001\n",
      "2 0.016\n",
      "3 0.081\n",
      "4 0.256\n",
      "train_begin | time:  17.05.2021 14:32:52\n",
      "Epoch 1/150\n",
      "epoch_end | time:  17.05.2021 14:52:58\n",
      " — val_aps:  0.051766 — val_a: 0.917563\n",
      "2945/2945 - 1245s - loss: 0.0150 - accuracy: 0.9758 - auc_2: 0.9942 - precision_2: 0.9758 - recall_2: 0.9758 - val_loss: 0.0542 - val_accuracy: 0.9892 - val_auc_2: 0.9975 - val_precision_2: 0.9892 - val_recall_2: 0.9892\n",
      "Epoch 2/150\n",
      "epoch_end | time:  17.05.2021 15:16:09\n",
      " — val_aps:  0.039938 — val_a: 0.925791\n",
      "2945/2945 - 1396s - loss: 0.0071 - accuracy: 0.9874 - auc_2: 0.9978 - precision_2: 0.9874 - recall_2: 0.9874 - val_loss: 0.2316 - val_accuracy: 0.9282 - val_auc_2: 0.9691 - val_precision_2: 0.9282 - val_recall_2: 0.9282\n",
      "Epoch 3/150\n",
      "epoch_end | time:  17.05.2021 15:40:18\n",
      " — val_aps:  0.057773 — val_a: 0.930945\n",
      "2945/2945 - 1443s - loss: 0.0064 - accuracy: 0.9878 - auc_2: 0.9983 - precision_2: 0.9878 - recall_2: 0.9878 - val_loss: 0.0219 - val_accuracy: 0.9960 - val_auc_2: 0.9994 - val_precision_2: 0.9960 - val_recall_2: 0.9960\n",
      "Epoch 4/150\n",
      "epoch_end | time:  17.05.2021 16:03:01\n",
      " — val_aps:  0.047083 — val_a: 0.917508\n",
      "2945/2945 - 1374s - loss: 0.0059 - accuracy: 0.9883 - auc_2: 0.9986 - precision_2: 0.9883 - recall_2: 0.9883 - val_loss: 0.1967 - val_accuracy: 0.9465 - val_auc_2: 0.9784 - val_precision_2: 0.9465 - val_recall_2: 0.9465\n",
      "Epoch 5/150\n",
      "epoch_end | time:  17.05.2021 16:29:43\n",
      " — val_aps:  0.058754 — val_a: 0.935484\n",
      "2945/2945 - 1618s - loss: 0.0057 - accuracy: 0.9890 - auc_2: 0.9987 - precision_2: 0.9890 - recall_2: 0.9890 - val_loss: 0.0772 - val_accuracy: 0.9757 - val_auc_2: 0.9970 - val_precision_2: 0.9757 - val_recall_2: 0.9757\n",
      "Epoch 6/150\n",
      "epoch_end | time:  17.05.2021 16:53:24\n",
      " — val_aps:  0.073663 — val_a: 0.939135\n",
      "2945/2945 - 1397s - loss: 0.0055 - accuracy: 0.9887 - auc_2: 0.9988 - precision_2: 0.9887 - recall_2: 0.9887 - val_loss: 0.0360 - val_accuracy: 0.9867 - val_auc_2: 0.9989 - val_precision_2: 0.9867 - val_recall_2: 0.9867\n",
      "Epoch 7/150\n",
      "epoch_end | time:  17.05.2021 17:17:43\n",
      " — val_aps:  0.066772 — val_a: 0.926238\n",
      "2945/2945 - 1474s - loss: 0.0053 - accuracy: 0.9885 - auc_2: 0.9989 - precision_2: 0.9885 - recall_2: 0.9885 - val_loss: 0.0186 - val_accuracy: 0.9965 - val_auc_2: 0.9985 - val_precision_2: 0.9965 - val_recall_2: 0.9965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/150\n",
      "epoch_end | time:  17.05.2021 17:43:22\n",
      " — val_aps:  0.063308 — val_a: 0.917641\n",
      "2945/2945 - 1524s - loss: 0.0052 - accuracy: 0.9885 - auc_2: 0.9989 - precision_2: 0.9885 - recall_2: 0.9885 - val_loss: 0.0331 - val_accuracy: 0.9875 - val_auc_2: 0.9990 - val_precision_2: 0.9875 - val_recall_2: 0.9875\n",
      "Epoch 9/150\n",
      "epoch_end | time:  17.05.2021 18:06:49\n",
      " — val_aps:  0.035320 — val_a: 0.906066\n",
      "2945/2945 - 1429s - loss: 0.0050 - accuracy: 0.9888 - auc_2: 0.9990 - precision_2: 0.9888 - recall_2: 0.9888 - val_loss: 0.1275 - val_accuracy: 0.9620 - val_auc_2: 0.9892 - val_precision_2: 0.9620 - val_recall_2: 0.9620\n",
      "Epoch 10/150\n",
      "epoch_end | time:  17.05.2021 18:32:31\n",
      " — val_aps:  0.068661 — val_a: 0.933709\n",
      "2945/2945 - 1527s - loss: 0.0049 - accuracy: 0.9890 - auc_2: 0.9990 - precision_2: 0.9890 - recall_2: 0.9890 - val_loss: 0.0557 - val_accuracy: 0.9873 - val_auc_2: 0.9988 - val_precision_2: 0.9873 - val_recall_2: 0.9873\n",
      "Epoch 11/150\n",
      "epoch_end | time:  17.05.2021 18:56:48\n",
      " — val_aps:  0.049133 — val_a: 0.908862\n",
      "2945/2945 - 1441s - loss: 0.0048 - accuracy: 0.9887 - auc_2: 0.9990 - precision_2: 0.9887 - recall_2: 0.9887 - val_loss: 0.0548 - val_accuracy: 0.9822 - val_auc_2: 0.9979 - val_precision_2: 0.9822 - val_recall_2: 0.9822\n",
      "Epoch 12/150\n",
      "epoch_end | time:  17.05.2021 19:18:22\n",
      " — val_aps:  0.067821 — val_a: 0.871521\n",
      "2945/2945 - 1290s - loss: 0.0047 - accuracy: 0.9885 - auc_2: 0.9990 - precision_2: 0.9885 - recall_2: 0.9885 - val_loss: 0.0234 - val_accuracy: 0.9950 - val_auc_2: 0.9981 - val_precision_2: 0.9950 - val_recall_2: 0.9950\n",
      "Epoch 13/150\n",
      "epoch_end | time:  17.05.2021 19:39:26\n",
      " — val_aps:  0.062957 — val_a: 0.929235\n",
      "2945/2945 - 1261s - loss: 0.0046 - accuracy: 0.9891 - auc_2: 0.9990 - precision_2: 0.9891 - recall_2: 0.9891 - val_loss: 0.0226 - val_accuracy: 0.9954 - val_auc_2: 0.9992 - val_precision_2: 0.9954 - val_recall_2: 0.9954\n",
      "Epoch 14/150\n",
      "epoch_end | time:  17.05.2021 20:00:06\n",
      " — val_aps:  0.062987 — val_a: 0.928461\n",
      "2945/2945 - 1239s - loss: 0.0045 - accuracy: 0.9891 - auc_2: 0.9991 - precision_2: 0.9891 - recall_2: 0.9891 - val_loss: 0.0587 - val_accuracy: 0.9720 - val_auc_2: 0.9976 - val_precision_2: 0.9720 - val_recall_2: 0.9720\n",
      "Epoch 15/150\n",
      "epoch_end | time:  17.05.2021 20:20:37\n",
      " — val_aps:  0.062154 — val_a: 0.937621\n",
      "2945/2945 - 1230s - loss: 0.0044 - accuracy: 0.9892 - auc_2: 0.9991 - precision_2: 0.9892 - recall_2: 0.9892 - val_loss: 0.0478 - val_accuracy: 0.9829 - val_auc_2: 0.9981 - val_precision_2: 0.9829 - val_recall_2: 0.9829\n",
      "Epoch 16/150\n",
      "epoch_end | time:  17.05.2021 20:40:46\n",
      " — val_aps:  0.065474 — val_a: 0.920644\n",
      "2945/2945 - 1208s - loss: 0.0043 - accuracy: 0.9891 - auc_2: 0.9992 - precision_2: 0.9891 - recall_2: 0.9891 - val_loss: 0.0296 - val_accuracy: 0.9924 - val_auc_2: 0.9980 - val_precision_2: 0.9924 - val_recall_2: 0.9924\n",
      "Epoch 17/150\n",
      "epoch_end | time:  17.05.2021 21:00:37\n",
      " — val_aps:  0.081853 — val_a: 0.919343\n",
      "2945/2945 - 1190s - loss: 0.0043 - accuracy: 0.9893 - auc_2: 0.9992 - precision_2: 0.9893 - recall_2: 0.9893 - val_loss: 0.0198 - val_accuracy: 0.9964 - val_auc_2: 0.9982 - val_precision_2: 0.9964 - val_recall_2: 0.9964\n",
      "Epoch 18/150\n",
      "epoch_end | time:  17.05.2021 21:20:41\n",
      " — val_aps:  0.081651 — val_a: 0.920625\n",
      "2945/2945 - 1204s - loss: 0.0043 - accuracy: 0.9889 - auc_2: 0.9992 - precision_2: 0.9889 - recall_2: 0.9889 - val_loss: 0.0209 - val_accuracy: 0.9949 - val_auc_2: 0.9986 - val_precision_2: 0.9949 - val_recall_2: 0.9949\n",
      "Epoch 19/150\n",
      "epoch_end | time:  17.05.2021 21:40:50\n",
      " — val_aps:  0.050266 — val_a: 0.918724\n",
      "2945/2945 - 1208s - loss: 0.0042 - accuracy: 0.9895 - auc_2: 0.9992 - precision_2: 0.9895 - recall_2: 0.9895 - val_loss: 0.2820 - val_accuracy: 0.8572 - val_auc_2: 0.9503 - val_precision_2: 0.8572 - val_recall_2: 0.8572\n",
      "Epoch 20/150\n",
      "epoch_end | time:  17.05.2021 22:00:34\n",
      " — val_aps:  0.042757 — val_a: 0.887515\n",
      "2945/2945 - 1184s - loss: 0.0041 - accuracy: 0.9894 - auc_2: 0.9992 - precision_2: 0.9894 - recall_2: 0.9894 - val_loss: 0.0467 - val_accuracy: 0.9833 - val_auc_2: 0.9977 - val_precision_2: 0.9833 - val_recall_2: 0.9833\n",
      "Epoch 21/150\n",
      "epoch_end | time:  17.05.2021 22:19:41\n",
      " — val_aps:  0.064565 — val_a: 0.924161\n",
      "2945/2945 - 1145s - loss: 0.0040 - accuracy: 0.9894 - auc_2: 0.9992 - precision_2: 0.9894 - recall_2: 0.9894 - val_loss: 0.0295 - val_accuracy: 0.9915 - val_auc_2: 0.9986 - val_precision_2: 0.9915 - val_recall_2: 0.9915\n",
      "Epoch 22/150\n",
      "epoch_end | time:  17.05.2021 22:38:46\n",
      " — val_aps:  0.069015 — val_a: 0.923409\n",
      "2945/2945 - 1143s - loss: 0.0040 - accuracy: 0.9891 - auc_2: 0.9992 - precision_2: 0.9891 - recall_2: 0.9891 - val_loss: 0.0579 - val_accuracy: 0.9829 - val_auc_2: 0.9971 - val_precision_2: 0.9829 - val_recall_2: 0.9829\n",
      "Epoch 23/150\n",
      "epoch_end | time:  17.05.2021 22:57:50\n",
      " — val_aps:  0.068152 — val_a: 0.898758\n",
      "2945/2945 - 1144s - loss: 0.0040 - accuracy: 0.9897 - auc_2: 0.9993 - precision_2: 0.9897 - recall_2: 0.9897 - val_loss: 0.0219 - val_accuracy: 0.9957 - val_auc_2: 0.9984 - val_precision_2: 0.9957 - val_recall_2: 0.9957\n",
      "Epoch 24/150\n",
      "epoch_end | time:  17.05.2021 23:16:33\n",
      " — val_aps:  0.053286 — val_a: 0.915795\n",
      "2945/2945 - 1122s - loss: 0.0039 - accuracy: 0.9898 - auc_2: 0.9993 - precision_2: 0.9898 - recall_2: 0.9898 - val_loss: 0.0681 - val_accuracy: 0.9767 - val_auc_2: 0.9973 - val_precision_2: 0.9767 - val_recall_2: 0.9767\n",
      "Epoch 25/150\n",
      "epoch_end | time:  17.05.2021 23:35:31\n",
      " — val_aps:  0.049718 — val_a: 0.902421\n",
      "2945/2945 - 1137s - loss: 0.0039 - accuracy: 0.9892 - auc_2: 0.9993 - precision_2: 0.9892 - recall_2: 0.9892 - val_loss: 0.0541 - val_accuracy: 0.9834 - val_auc_2: 0.9978 - val_precision_2: 0.9834 - val_recall_2: 0.9834\n",
      "Epoch 26/150\n",
      "epoch_end | time:  17.05.2021 23:54:19\n",
      " — val_aps:  0.070268 — val_a: 0.932699\n",
      "2945/2945 - 1128s - loss: 0.0038 - accuracy: 0.9896 - auc_2: 0.9993 - precision_2: 0.9896 - recall_2: 0.9896 - val_loss: 0.0394 - val_accuracy: 0.9855 - val_auc_2: 0.9989 - val_precision_2: 0.9855 - val_recall_2: 0.9855\n",
      "Epoch 27/150\n",
      "epoch_end | time:  18.05.2021 00:13:25\n",
      " — val_aps:  0.057551 — val_a: 0.919938\n",
      "2945/2945 - 1146s - loss: 0.0037 - accuracy: 0.9897 - auc_2: 0.9993 - precision_2: 0.9897 - recall_2: 0.9897 - val_loss: 0.0383 - val_accuracy: 0.9859 - val_auc_2: 0.9982 - val_precision_2: 0.9859 - val_recall_2: 0.9859\n",
      "model_spider8_internal_grid_20_7_5_32_0.0002_200518_0 valid_for_train:  0.8398753039008697 0.05755105987561758 | test:  0.8520207271846991 0.05456088105948585\n"
     ]
    }
   ],
   "source": [
    "VERBOSE = 2\n",
    "BATCH_SIZE = 512\n",
    "NB_EPOCH = 150\n",
    "class_weighting = {0:0.05 , 1:1}\n",
    "\n",
    "result_all_8 = pd.DataFrame()\n",
    "result_all_8['name_model'] = None\n",
    "result_all_8['params'] = None\n",
    "result_all_8['val_GINI'] = None\n",
    "result_all_8['val_APS'] = None\n",
    "result_all_8['test_GINI'] = None\n",
    "result_all_8['test_APS'] = None\n",
    "j = 0\n",
    "\n",
    "for p in param:\n",
    "    print('=====================================================================================================')\n",
    "    print(inp_shape, X_2_2.shape, p)\n",
    "    \n",
    "    model_grid = spider_model_8block(reg = p[1], reg_dense = p[7], n_features = inp_shape, n_pool = 2, n_kernel = p[2], \n",
    "                              n_filters = p[3], n_strides = 1, classes = 2, \n",
    "                              hidden = p[4] , drop_out = p[5], drop_out_conv = p[6], drop_out_rate = 4 ,\n",
    "                 padding_pool = 'valid' , gl_pool_max = p[0], min_pool = p[8], str_pool = None)\n",
    "    \n",
    "    model_grid.compile(loss='categorical_crossentropy', \n",
    "                 optimizer=tf.keras.optimizers.Adam(learning_rate=0.003),\n",
    "              metrics=['accuracy', tf.keras.metrics.AUC(), tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "    \n",
    "    history_XX = model_grid.fit_generator(generator=training_generator,  #training_aug,\n",
    "                    validation_data= (X_2_2, Y_test_2) , #Y_test_2 = np_utils.to_categorical( y_val, 2) \n",
    "                                     epochs=NB_EPOCH, verbose=VERBOSE, class_weight=class_weighting,\n",
    "                                     callbacks=[_time , EarlyStopping(monitor='val_loss', patience=20),\n",
    "                                               Metrics(valid_data=(X_2_2, Y_test_2))])\n",
    "    \n",
    "    res_model_ = pd.DataFrame(history_XX.history, columns = history_XX.history.keys())\n",
    "    dd = str(200000 + datetime.now().month*100 + datetime.now().day) + '_' + str(datetime.now().hour)\n",
    "    name_m = 'model_spider8_internal_grid_' + str(p[8]) + '_' + str(p[2]) + '_' + str(p[3]) + '_' + str(p[4]) + '_' + str(p[7]) + '_' + str(dd)\n",
    "    \n",
    "    model_grid.save( name_m + '.h5')\n",
    "    res_model_.to_csv(name_m + '.csv')\n",
    "    \n",
    "    predict_class_val = model_grid.predict(X_2_2)\n",
    "    APS = metrics.average_precision_score(y_val, predict_class_val[:,1])\n",
    "    GINI = 2*(metrics.roc_auc_score(y_val , predict_class_val[:,1])) - 1\n",
    "\n",
    "    predict_class_test = model_grid.predict(X_3_2)\n",
    "    APS_t = metrics.average_precision_score(y_test, predict_class_test[:,1])\n",
    "    GINI_t = 2*(metrics.roc_auc_score(y_test, predict_class_test[:,1])) - 1\n",
    "    \n",
    "    result_all_8.at[j , 'name_model'] = name_m\n",
    "    result_all_8.at[j ,'params'] = str(p)\n",
    "    result_all_8.at[j ,'val_GINI'] = GINI\n",
    "    result_all_8.at[j ,'val_APS'] = APS\n",
    "    result_all_8.at[j ,'test_GINI'] = GINI_t\n",
    "    result_all_8.at[j ,'test_APS'] = APS_t\n",
    "    \n",
    "    result_all_8.to_csv('internal_grid_result_all_8_202105_14.csv')\n",
    "    j += 1\n",
    "    print(name_m, 'valid_for_train: ', GINI, APS, '| test: ', GINI_t, APS_t) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
