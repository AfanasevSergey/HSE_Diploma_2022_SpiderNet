{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training CNN-3, CNN-6 and CNN-8 on Private Data without B/W-tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import math\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.pyplot import cm\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import collections\n",
    "from collections import OrderedDict, Counter\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import normaltest, kstest, ttest_ind, ttest_rel, mannwhitneyu, wilcoxon, levene, bartlett\n",
    "from scipy.stats import chi2_contingency, fisher_exact, mode, pearsonr, f_oneway, kruskal, spearmanr\n",
    "\n",
    "from rfpimp import *\n",
    "\n",
    "from datetime import datetime\n",
    "import re\n",
    "from seaborn import heatmap\n",
    "import random\n",
    "import statsmodels.distributions.empirical_distribution as edf\n",
    "from scipy.interpolate import interp1d\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from functools import reduce\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n",
    "\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, log_loss, recall_score\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler, PowerTransformer\n",
    "\n",
    "from sklearn.utils import check_consistent_length, column_or_1d, assert_all_finite\n",
    "from sklearn.utils.extmath import stable_cumsum\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import re\n",
    "import gc\n",
    "\n",
    "import os\n",
    "\n",
    "#from sklearn.externals import joblib\n",
    "import joblib\n",
    "\n",
    "from importlib import reload\n",
    "import Filter_and_Grid_Search\n",
    "Filter_and_Grid_Search = reload(Filter_and_Grid_Search)\n",
    "from Filter_and_Grid_Search import stratified_split\n",
    "from Filter_and_Grid_Search import attributes_list, attributes_list_new\n",
    "from Filter_and_Grid_Search import get_s_stat, get_PSI_stat, get_stats_by_month, get_stats, stable_unstable\n",
    "from Filter_and_Grid_Search import stable_unstable_by_month_divide, union_datas, individual_hists_all \n",
    "from Filter_and_Grid_Search import paired_time_hists_by_month, statistics_with_target\n",
    "from Filter_and_Grid_Search import receive_correlations, find_doubles_corr\n",
    "from Filter_and_Grid_Search import statistics_with_target, attributes_list, attributes_list_new, make_standard\n",
    "from Filter_and_Grid_Search import data_preprocessing_train, data_preprocessing_test\n",
    "from Filter_and_Grid_Search import receive_correlations, find_doubles_corr\n",
    "from Filter_and_Grid_Search import stratified_split, two_forests, turn_variables_with_values\n",
    "from Filter_and_Grid_Search import find_meta_params, calculate_vif#, find_meta_params_mem\n",
    "from Filter_and_Grid_Search import plot_meta_2d, data_preprocessing, find_ouliers_iqr\n",
    "from Filter_and_Grid_Search import train_model_receive_stats, simple_b_score_risk\n",
    "from Filter_and_Grid_Search import max_prof_corve, by_month_gini, check_attribute_list_cases\n",
    "\n",
    "from Filter_and_Grid_Search import to_zip, br_correction, br_stat\n",
    "\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import pathlib\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/Share/01 -Risk Desc Science/AntiFraud/Data Sets/\n",
      "D:/Share/safanasev/Python-notebook/AF_ML_v2_2014/\n"
     ]
    }
   ],
   "source": [
    "PATH_DATA = 'D:/Share/01 -Risk Desc Science/AntiFraud/Data Sets/'\n",
    "PATH = 'D:/Share/safanasev/Python-notebook/AF_ML_v2_2014/'\n",
    "print(PATH_DATA)\n",
    "print(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 29\n",
    "\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.set_random_seed(seed_value)\n",
    "\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "# for later versions:\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Activation, Dense, Flatten, Dropout)\n",
    "from tensorflow.keras.layers import (Conv1D, MaxPooling1D, AveragePooling1D)\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import ReLU, Concatenate, GlobalAveragePooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6806930242532557001\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 5163500694205374332\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 2692889278196551721\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#если alpha не задано, то не делаем br_correction\n",
    "\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self,  dataset, x_col, y_col,  batch_size=256, num_classes=2, alpha = 0.1, random_state = 42, \n",
    "                 shuffle=True, class_w = None):\n",
    "        self.batch_size = batch_size\n",
    "        self.dataset = dataset\n",
    "        self.x_col = x_col\n",
    "        self.y_col = y_col\n",
    "        self.indices = self.dataset.index.tolist()\n",
    "        self.num_classes = num_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.alpha = alpha\n",
    "        self.random_state = random_state\n",
    "        self.class_w = class_w\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.indices) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        index = self.index[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch = [self.indices[k] for k in index]\n",
    "        \n",
    "        data_tmp = self.dataset.loc[batch]\n",
    "        data_tmp_b = data_tmp[data_tmp[self.y_col] == 1]\n",
    "        data_tmp_b_all = self.dataset[self.dataset[self.y_col] == 1]\n",
    "        X_tmp = data_tmp.head(0)\n",
    "        \n",
    "        \n",
    "        #print(data_tmp_b.shape[0], data_tmp.shape[0], data_tmp_b_all.shape[0])\n",
    "        if (self.alpha is None) and (self.class_w is None):\n",
    "            X = data_tmp[self.x_col] #.reshape(-1)\n",
    "            y = data_tmp[self.y_col] \n",
    "            \n",
    "        elif (self.alpha is None) and self.class_w > 0:\n",
    "            k = (self.class_w*self.batch_size)/(1-self.class_w)\n",
    "            k = k - data_tmp_b.shape[0]\n",
    "            if int(k) < 1:\n",
    "                k = k+1\n",
    "            ix2 = np.random.RandomState(self.random_state + int(k)).choice(data_tmp_b_all.shape[0], int(k))\n",
    "            X_tmp = data_tmp_b_all.iloc[ix2]\n",
    "            data_tmp = data_tmp.append(X_tmp, ignore_index=True)\n",
    "            X = data_tmp[self.x_col] #.reshape(-1)\n",
    "            y = data_tmp[self.y_col]\n",
    "            #print(data_tmp_b.shape[0], data_tmp.shape[0],  data_tmp_b.shape[0]/(data_tmp.shape[0] - X_tmp.shape[0]), np.mean(y)) \n",
    "            \n",
    "            \n",
    "            \n",
    "        else:\n",
    "            if data_tmp_b.shape[0] > 0:\n",
    "                k=(self.alpha*self.batch_size/data_tmp_b.shape[0] -1 )/(1-self.alpha)\n",
    "                for i in range(0,int(k)):\n",
    "                    X_tmp = X_tmp.append(data_tmp_b, ignore_index=True)\n",
    "            else:\n",
    "                k = (self.alpha*self.batch_size)/(1-self.alpha)\n",
    "                ix2 = np.random.RandomState(self.random_state + int(k)).choice(data_tmp_b_all.shape[0], int(k))\n",
    "                X_tmp = data_tmp_b_all.iloc[ix2]\n",
    "                data_tmp_b = X_tmp\n",
    "\n",
    "    #         print('Добавим дробное число строк')    \n",
    "            k_fraction = k - int(k)\n",
    "            n_samples = int(round(data_tmp_b.shape[0]*k_fraction))\n",
    "    #         print(k_fraction, n_samples)\n",
    "\n",
    "            ix = np.random.RandomState(self.random_state).choice(data_tmp_b.shape[0], n_samples)\n",
    "            data_add_fraction = data_tmp_b.iloc[ix]\n",
    "            X_tmp.append(data_add_fraction, ignore_index=True)\n",
    "\n",
    "            data_tmp = data_tmp.append(X_tmp, ignore_index=True)\n",
    "\n",
    "\n",
    "            X = data_tmp[self.x_col] #.reshape(-1)\n",
    "            y = data_tmp[self.y_col]   \n",
    "        #print(sum(self.dataset.loc[batch][self.y_col])/len(index), np.mean(y))\n",
    "        \n",
    "        if self.num_classes > 1:\n",
    "            y = np_utils.to_categorical( y, self.num_classes)\n",
    "            \n",
    "        ####for tf 2.3.0, [np.array(X)], np.array(y)\n",
    "\n",
    "        #return [np.array(X).reshape(X.shape[0], X.shape[1], 1)], np.array(y)\n",
    "        return [np.array(X)], np.array(y)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.index = np.arange(len(self.indices))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
    "\n",
    "# объявляем класс метрик\n",
    "\n",
    "class E_time(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        tm = datetime.strftime(datetime.now(), \"%d.%m.%Y %H:%M:%S\")\n",
    "        print ('train_begin', '| time: ' , tm)\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        tm = datetime.strftime(datetime.now(), \"%d.%m.%Y %H:%M:%S\")\n",
    "        print ('epoch_end', '| time: ' , tm)\n",
    "    \n",
    "        return\n",
    "\n",
    "_time = E_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, valid_data):\n",
    "        super(Metrics, self).__init__()\n",
    "        self.validation_data = valid_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        val_predict = self.model.predict(self.validation_data[0])[:, 1]\n",
    "        val_targ = self.validation_data[1]\n",
    "        \n",
    "        if len(val_targ.shape) == 2: #and val_targ.shape[1] != 1:\n",
    "            val_targ = val_targ[:,1]\n",
    "\n",
    "        _val_aps = metrics.average_precision_score(val_targ, val_predict)\n",
    "        #_val_recall = metrics.recall_score(val_targ, val_predict)\n",
    "        _val_a = metrics.roc_auc_score(val_targ, val_predict)\n",
    "\n",
    "        logs['val_aps'] = _val_aps\n",
    "        logs['val_a'] = _val_a\n",
    "        print(\" — val_aps:  %f — val_a: %f\" % (_val_aps, _val_a))\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading preprocessed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_for = pd.read_csv(PATH + 'train_163_prep.csv')\n",
    "valid_for = pd.read_csv(PATH + 'valid_163_prep.csv')\n",
    "test_for = pd.read_csv(PATH + 'test_163_prep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_for[target]\n",
    "y_test = valid_for[target]\n",
    "y_val = test_for[target]\n",
    "\n",
    "train_for.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "valid_for.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "test_for.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "col = train_for.columns.to_list()\n",
    "col.remove(target)\n",
    "\n",
    "\n",
    "X_1_2 = train_for[col]\n",
    "X_2_2 = valid_for[col]\n",
    "X_3_2 = test_for[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['COUNT_CONT_30', 'W_TEST_AGE_6_60D', 'W_TEST_AGE_ALL5_7D',\n",
       "       'B_TEST_PASP_D_3_7D', 'B_TEST_PASP_D_3_14D', 'B_TEST_PASP_D_3_30D',\n",
       "       'B_TEST_PASP_D_3_60D', 'B_TEST_PASP_D_10_7D', 'B_TEST_PASP_D_10_30D',\n",
       "       'B_TEST_PASP_D_ALL5_30D',\n",
       "       ...\n",
       "       'DIVISION_Южный', 'AVG_FUND_TT_7_bin', 'AVG_FUND_TT_14_bin',\n",
       "       'STD_SUM_TT_14_bin', 'AVG_FUND_TT_30_bin', 'STD_SUM_TT_30_bin',\n",
       "       'STD_SUM_TT_60_bin', 'RULE_1_TRE3_SHARE_7_bin',\n",
       "       'RULE_1_TRE3_SHARE_14_bin', 'COUNT_CONT_FIO7_7_bin'],\n",
       "      dtype='object', length=163)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col = X_2_2.columns\n",
    "y_col = 'BAD_FLAG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = DataGenerator(train_for, x_col, y_col, batch_size=512, alpha = None, class_w = 0.05 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_2 = np_utils.to_categorical( y_test, 2) # преобразовываем в 2 класса "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_test = []\n",
    "w_test = []\n",
    "del_all = []\n",
    "\n",
    "for i in X_2_2.columns:\n",
    "    if i.find('W_TEST') >= 0:\n",
    "        w_test.append(i)\n",
    "        del_all.append(i)\n",
    "    if i.find('B_TEST') >= 0:\n",
    "        b_test.append(i)\n",
    "        del_all.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = train_for.columns.to_list()\n",
    "col.remove(target)\n",
    "\n",
    "col_2 = [i for i in col if i not in del_all]\n",
    "\n",
    "\n",
    "X_1_2 = train_for[col_2]\n",
    "X_2_2 = valid_for[col_2]\n",
    "X_3_2 = test_for[col_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1507599, 164)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_for.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_3 = col_2 + [target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_for = train_for[col_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_col = pd.DataFrame()\n",
    "pd_col['var_wo_btest'] = col_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_wo_btest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COUNT_CONT_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AVG_SUM_TT_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AVG_FUND_TT_7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AVG_SUM_TT_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STD_SUM_TT_14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>STD_SUM_TT_60_bin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>RULE_1_TRE3_SHARE_7_bin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>RULE_1_TRE3_SHARE_14_bin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>COUNT_CONT_FIO7_7_bin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>BAD_FLAG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 var_wo_btest\n",
       "0               COUNT_CONT_30\n",
       "1                AVG_SUM_TT_7\n",
       "2               AVG_FUND_TT_7\n",
       "3               AVG_SUM_TT_14\n",
       "4               STD_SUM_TT_14\n",
       "..                        ...\n",
       "120         STD_SUM_TT_60_bin\n",
       "121   RULE_1_TRE3_SHARE_7_bin\n",
       "122  RULE_1_TRE3_SHARE_14_bin\n",
       "123     COUNT_CONT_FIO7_7_bin\n",
       "124                  BAD_FLAG\n",
       "\n",
       "[125 rows x 1 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_col.to_csv('124+target_wo_btest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_pool(min_pool, n_pool, padding_pool,  str_pool, y, str_min = 1):\n",
    "    #for 3D-tensor\n",
    "    if y.shape[1] < (min_pool):\n",
    "        \n",
    "        return MaxPooling1D(pool_size = n_pool, padding=padding_pool, strides=str_min)(y)\n",
    "    else:\n",
    "        return MaxPooling1D(pool_size = n_pool, padding=padding_pool, strides=str_pool)(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_cnn_3(n_features=163, n_pool=2, n_kernel=5, n_filters=5,\n",
    "                n_strides=1, n_strides_pool=None, classes=2, hidden=64, drop_out=0.25,\n",
    "                l2_conv=None, reg=1E-5, reg_dense=1E-5, _bias=True, gl_pool_max=False, padding_pool='valid',\n",
    "                padding_conv = 'same', n_lay=3, min_pool = 15):\n",
    "\n",
    "    if reg == None:\n",
    "        l2_batch_gamma = None\n",
    "        l2_batch_betta = None\n",
    "    else:\n",
    "        l2_batch_gamma = l2(reg)\n",
    "        l2_batch_betta = l2(reg)\n",
    "\n",
    "    if reg_dense == None:\n",
    "        kernel_regularizer = None\n",
    "    else:\n",
    "        kernel_regularizer = l2(reg)\n",
    "\n",
    "    # 1 слой\n",
    "\n",
    "    x = Input(shape=(n_features, 1))\n",
    "    y = Conv1D(filters=n_filters, kernel_size=n_kernel,\n",
    "               strides=n_strides, padding=padding_conv, use_bias=_bias)(x)\n",
    "\n",
    "    y = BatchNormalization(gamma_regularizer=l2_batch_gamma,\n",
    "                           beta_regularizer=l2_batch_betta)(y)\n",
    "    y = ReLU()(y)\n",
    "    y = max_pool(min_pool, n_pool, padding_pool, n_strides_pool, y)\n",
    "\n",
    "    for i in range(1, n_lay):\n",
    "        y = Conv1D(filters=(i + 1)* n_filters, kernel_size=n_kernel,\n",
    "                   strides=n_strides, padding=padding_conv, use_bias=_bias)(y)\n",
    "        y = BatchNormalization(gamma_regularizer=l2_batch_gamma,\n",
    "                           beta_regularizer=l2_batch_betta)(y)\n",
    "        y = ReLU()(y)\n",
    "        y = max_pool(min_pool, n_pool, padding_pool, n_strides_pool, y)\n",
    "    if gl_pool_max:\n",
    "        z = GlobalMaxPooling1D()(y)\n",
    "        \n",
    "    else:\n",
    "        z = GlobalAveragePooling1D()(y)\n",
    "        \n",
    "    z = Dense(hidden, activation='relu', kernel_regularizer = kernel_regularizer)(z)\n",
    "    z = Dropout(drop_out)(z)\n",
    "    z = Dense(hidden, activation='relu', kernel_regularizer = kernel_regularizer)(z)\n",
    "    z = Dropout(drop_out)(z)\n",
    "    predictions = Dense(classes, activation='softmax')(z)\n",
    "\n",
    "    model = Model(inputs=x, outputs=predictions)\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN-3 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = model_cnn_3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 163, 1)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 163, 5)            30        \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 163, 5)            20        \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 163, 5)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 81, 5)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 81, 10)            260       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 81, 10)            40        \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 81, 10)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 40, 10)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 40, 15)            765       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 40, 15)            60        \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 40, 15)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 20, 15)            0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                1024      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 6,489\n",
      "Trainable params: 6,429\n",
      "Non-trainable params: 60\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_test.compile(loss='categorical_crossentropy',\n",
    "                   #optimizer = tf.keras.optimizers.Ftrl(learning_rate=0.003, learning_rate_power=-0.5,  l2_regularization_strength=0.3) ,\n",
    "                   optimizer=tf.keras.optimizers.Adam(learning_rate=0.005),\n",
    "                   #optimizer = tf.keras.optimizers.Adamax(learning_rate=0.006) ,\n",
    "                   #optimizer=tf.keras.optimizers.Adam(learning_rate=0.002), - не уменьшался loss\n",
    "              metrics=['accuracy', tf.keras.metrics.AUC(), tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "\n",
    "model_test.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN-6 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         [(None, 163, 1)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 163, 5)            30        \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 163, 5)            20        \n",
      "_________________________________________________________________\n",
      "re_lu_10 (ReLU)              (None, 163, 5)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 81, 5)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 81, 10)            260       \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 81, 10)            40        \n",
      "_________________________________________________________________\n",
      "re_lu_11 (ReLU)              (None, 81, 10)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 40, 10)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 40, 15)            765       \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 40, 15)            60        \n",
      "_________________________________________________________________\n",
      "re_lu_12 (ReLU)              (None, 40, 15)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 20, 15)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 20, 20)            1520      \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 20, 20)            80        \n",
      "_________________________________________________________________\n",
      "re_lu_13 (ReLU)              (None, 20, 20)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 10, 20)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 10, 25)            2525      \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 10, 25)            100       \n",
      "_________________________________________________________________\n",
      "re_lu_14 (ReLU)              (None, 10, 25)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 9, 25)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 9, 30)             3780      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 9, 30)             120       \n",
      "_________________________________________________________________\n",
      "re_lu_15 (ReLU)              (None, 9, 30)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 8, 30)             0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_3 ( (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 64)                1984      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 15,574\n",
      "Trainable params: 15,364\n",
      "Non-trainable params: 210\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_test = model_cnn_3(n_lay=6)\n",
    "model_test.compile(loss='categorical_crossentropy',\n",
    "                   #optimizer = tf.keras.optimizers.Ftrl(learning_rate=0.003, learning_rate_power=-0.5,  l2_regularization_strength=0.3) ,\n",
    "                   optimizer=tf.keras.optimizers.Adam(learning_rate=0.005),\n",
    "                   #optimizer = tf.keras.optimizers.Adamax(learning_rate=0.006) ,\n",
    "                   #optimizer=tf.keras.optimizers.Adam(learning_rate=0.002), - не уменьшался loss\n",
    "              metrics=['accuracy', tf.keras.metrics.AUC(), tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "\n",
    "model_test.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = itertools.product(gl_p, l2_batch, n_ker, n_fil, d_hidden, drop_out, reg_dense, min_pool, n_lay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (False, 0.0002, 5, 5, 60, 0.25, 0.0002, 20, 3)\n",
      "1 (False, 0.0002, 5, 5, 60, 0.25, 0.0002, 20, 6)\n",
      "2 (False, 0.0002, 5, 5, 100, 0.25, 0.0002, 20, 3)\n",
      "3 (False, 0.0002, 5, 5, 100, 0.25, 0.0002, 20, 6)\n",
      "4 (False, 0.0002, 5, 15, 60, 0.25, 0.0002, 20, 3)\n",
      "5 (False, 0.0002, 5, 15, 60, 0.25, 0.0002, 20, 6)\n",
      "6 (False, 0.0002, 5, 15, 100, 0.25, 0.0002, 20, 3)\n",
      "7 (False, 0.0002, 5, 15, 100, 0.25, 0.0002, 20, 6)\n",
      "8 (False, 0.0002, 7, 5, 60, 0.25, 0.0002, 20, 3)\n",
      "9 (False, 0.0002, 7, 5, 60, 0.25, 0.0002, 20, 6)\n",
      "10 (False, 0.0002, 7, 5, 100, 0.25, 0.0002, 20, 3)\n",
      "11 (False, 0.0002, 7, 5, 100, 0.25, 0.0002, 20, 6)\n",
      "12 (False, 0.0002, 7, 15, 60, 0.25, 0.0002, 20, 3)\n",
      "13 (False, 0.0002, 7, 15, 60, 0.25, 0.0002, 20, 6)\n",
      "14 (False, 0.0002, 7, 15, 100, 0.25, 0.0002, 20, 3)\n",
      "15 (False, 0.0002, 7, 15, 100, 0.25, 0.0002, 20, 6)\n",
      "16 (True, 0.0002, 5, 5, 60, 0.25, 0.0002, 20, 3)\n",
      "17 (True, 0.0002, 5, 5, 60, 0.25, 0.0002, 20, 6)\n",
      "18 (True, 0.0002, 5, 5, 100, 0.25, 0.0002, 20, 3)\n",
      "19 (True, 0.0002, 5, 5, 100, 0.25, 0.0002, 20, 6)\n",
      "20 (True, 0.0002, 5, 15, 60, 0.25, 0.0002, 20, 3)\n",
      "21 (True, 0.0002, 5, 15, 60, 0.25, 0.0002, 20, 6)\n",
      "22 (True, 0.0002, 5, 15, 100, 0.25, 0.0002, 20, 3)\n",
      "23 (True, 0.0002, 5, 15, 100, 0.25, 0.0002, 20, 6)\n",
      "24 (True, 0.0002, 7, 5, 60, 0.25, 0.0002, 20, 3)\n",
      "25 (True, 0.0002, 7, 5, 60, 0.25, 0.0002, 20, 6)\n",
      "26 (True, 0.0002, 7, 5, 100, 0.25, 0.0002, 20, 3)\n",
      "27 (True, 0.0002, 7, 5, 100, 0.25, 0.0002, 20, 6)\n",
      "28 (True, 0.0002, 7, 15, 60, 0.25, 0.0002, 20, 3)\n",
      "29 (True, 0.0002, 7, 15, 60, 0.25, 0.0002, 20, 6)\n",
      "30 (True, 0.0002, 7, 15, 100, 0.25, 0.0002, 20, 3)\n",
      "31 (True, 0.0002, 7, 15, 100, 0.25, 0.0002, 20, 6)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for p in param:\n",
    "    print(i, p)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl_p = [False, True] #0\n",
    "l2_batch = [ 0.0002] #1\n",
    "n_ker = [5, 7] #2\n",
    "n_fil = [ 5, 15] #3\n",
    "d_hidden = [60, 100] #4\n",
    "drop_out = [0.25] #5\n",
    "reg_dense = [ 0.0002] #6\n",
    "min_pool = [ 20] #7\n",
    "n_lay = [3, 6] #8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The best hyperparameters for CNN-3, CNN-6, CNN-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_best = ((False, 0.0002, 7, 5, 60, 0.25, 0.0002, 20, 3), # CNN-3\n",
    "         (False, 0.0002, 5, 15, 60, 0.25, 0.0002, 20, 6), # CNN-6\n",
    "         (False, 0.0001, 3, 10, 100, 0.25, 0.0002, 20, 8)) # CNN-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_shape = X_2_2.shape[1]\n",
    "inp_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((185400, 124), (185400, 2))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2_2.shape, Y_test_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col = X_2_2.columns\n",
    "y_col = 'BAD_FLAG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124 BAD_FLAG\n"
     ]
    }
   ],
   "source": [
    "training_generator = DataGenerator(train_for, x_col, y_col, batch_size=512, alpha = None, class_w = 0.05 )\n",
    "print(len(x_col), y_col )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the best CNN-3, CNN-6, CNN-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================================================\n",
      "124 (185400, 124) (False, 0.0002, 7, 5, 60, 0.25, 0.0002, 20, 3)\n",
      "train_begin | time:  12.05.2021 00:30:51\n",
      "Epoch 1/150\n",
      "epoch_end | time:  12.05.2021 00:42:10\n",
      " — val_aps:  0.064053 — val_a: 0.907989\n",
      "2945/2945 - 729s - loss: 0.0182 - accuracy: 0.9524 - auc_2: 0.9868 - precision_2: 0.9524 - recall_2: 0.9524 - val_loss: 0.0311 - val_accuracy: 0.9926 - val_auc_2: 0.9991 - val_precision_2: 0.9926 - val_recall_2: 0.9926\n",
      "Epoch 2/150\n",
      "epoch_end | time:  12.05.2021 00:53:35\n",
      " — val_aps:  0.062212 — val_a: 0.900581\n",
      "2945/2945 - 678s - loss: 0.0120 - accuracy: 0.9741 - auc_2: 0.9924 - precision_2: 0.9741 - recall_2: 0.9741 - val_loss: 0.3587 - val_accuracy: 0.8952 - val_auc_2: 0.9195 - val_precision_2: 0.8952 - val_recall_2: 0.8952\n",
      "Epoch 3/150\n",
      "epoch_end | time:  12.05.2021 01:04:26\n",
      " — val_aps:  0.063386 — val_a: 0.922695\n",
      "2945/2945 - 646s - loss: 0.0111 - accuracy: 0.9772 - auc_2: 0.9928 - precision_2: 0.9772 - recall_2: 0.9772 - val_loss: 0.0310 - val_accuracy: 0.9938 - val_auc_2: 0.9993 - val_precision_2: 0.9938 - val_recall_2: 0.9938\n",
      "Epoch 4/150\n",
      "epoch_end | time:  12.05.2021 01:15:30\n",
      " — val_aps:  0.064323 — val_a: 0.922052\n",
      "2945/2945 - 663s - loss: 0.0105 - accuracy: 0.9789 - auc_2: 0.9935 - precision_2: 0.9789 - recall_2: 0.9789 - val_loss: 0.0346 - val_accuracy: 0.9906 - val_auc_2: 0.9988 - val_precision_2: 0.9906 - val_recall_2: 0.9906\n",
      "Epoch 5/150\n",
      "epoch_end | time:  12.05.2021 01:26:39\n",
      " — val_aps:  0.066071 — val_a: 0.930469\n",
      "2945/2945 - 667s - loss: 0.0101 - accuracy: 0.9804 - auc_2: 0.9940 - precision_2: 0.9804 - recall_2: 0.9804 - val_loss: 0.0452 - val_accuracy: 0.9883 - val_auc_2: 0.9974 - val_precision_2: 0.9883 - val_recall_2: 0.9883\n",
      "Epoch 6/150\n",
      "epoch_end | time:  12.05.2021 01:37:41\n",
      " — val_aps:  0.068643 — val_a: 0.924565\n",
      "2945/2945 - 655s - loss: 0.0098 - accuracy: 0.9814 - auc_2: 0.9943 - precision_2: 0.9814 - recall_2: 0.9814 - val_loss: 0.0272 - val_accuracy: 0.9931 - val_auc_2: 0.9991 - val_precision_2: 0.9931 - val_recall_2: 0.9931\n",
      "Epoch 7/150\n",
      "epoch_end | time:  12.05.2021 01:47:28\n",
      " — val_aps:  0.053992 — val_a: 0.914643\n",
      "2945/2945 - 607s - loss: 0.0098 - accuracy: 0.9819 - auc_2: 0.9942 - precision_2: 0.9819 - recall_2: 0.9819 - val_loss: 0.0309 - val_accuracy: 0.9938 - val_auc_2: 0.9990 - val_precision_2: 0.9938 - val_recall_2: 0.9938\n",
      "Epoch 8/150\n",
      "epoch_end | time:  12.05.2021 01:58:58\n",
      " — val_aps:  0.073114 — val_a: 0.931399\n",
      "2945/2945 - 678s - loss: 0.0096 - accuracy: 0.9827 - auc_2: 0.9944 - precision_2: 0.9827 - recall_2: 0.9827 - val_loss: 0.0378 - val_accuracy: 0.9913 - val_auc_2: 0.9980 - val_precision_2: 0.9913 - val_recall_2: 0.9913\n",
      "Epoch 9/150\n",
      "epoch_end | time:  12.05.2021 02:09:50\n",
      " — val_aps:  0.064241 — val_a: 0.927078\n",
      "2945/2945 - 650s - loss: 0.0095 - accuracy: 0.9827 - auc_2: 0.9945 - precision_2: 0.9827 - recall_2: 0.9827 - val_loss: 0.1441 - val_accuracy: 0.9673 - val_auc_2: 0.9799 - val_precision_2: 0.9673 - val_recall_2: 0.9673\n",
      "Epoch 10/150\n",
      "epoch_end | time:  12.05.2021 02:21:06\n",
      " — val_aps:  0.067058 — val_a: 0.927294\n",
      "2945/2945 - 688s - loss: 0.0094 - accuracy: 0.9831 - auc_2: 0.9946 - precision_2: 0.9831 - recall_2: 0.9831 - val_loss: 0.1131 - val_accuracy: 0.9720 - val_auc_2: 0.9857 - val_precision_2: 0.9720 - val_recall_2: 0.9720\n",
      "Epoch 11/150\n",
      "epoch_end | time:  12.05.2021 02:32:34\n",
      " — val_aps:  0.053989 — val_a: 0.923581\n",
      "2945/2945 - 675s - loss: 0.0094 - accuracy: 0.9832 - auc_2: 0.9946 - precision_2: 0.9832 - recall_2: 0.9832 - val_loss: 0.2944 - val_accuracy: 0.9237 - val_auc_2: 0.9416 - val_precision_2: 0.9237 - val_recall_2: 0.9237\n",
      "Epoch 12/150\n",
      "epoch_end | time:  12.05.2021 02:43:50\n",
      " — val_aps:  0.070605 — val_a: 0.926140\n",
      "2945/2945 - 666s - loss: 0.0092 - accuracy: 0.9840 - auc_2: 0.9948 - precision_2: 0.9840 - recall_2: 0.9840 - val_loss: 0.0551 - val_accuracy: 0.9889 - val_auc_2: 0.9969 - val_precision_2: 0.9889 - val_recall_2: 0.9889\n",
      "Epoch 13/150\n",
      "epoch_end | time:  12.05.2021 02:53:27\n",
      " — val_aps:  0.052746 — val_a: 0.925313\n",
      "2945/2945 - 578s - loss: 0.0092 - accuracy: 0.9842 - auc_2: 0.9948 - precision_2: 0.9842 - recall_2: 0.9842 - val_loss: 0.2935 - val_accuracy: 0.9256 - val_auc_2: 0.9403 - val_precision_2: 0.9256 - val_recall_2: 0.9256\n",
      "Epoch 14/150\n",
      "epoch_end | time:  12.05.2021 03:02:45\n",
      " — val_aps:  0.051891 — val_a: 0.924566\n",
      "2945/2945 - 561s - loss: 0.0091 - accuracy: 0.9844 - auc_2: 0.9949 - precision_2: 0.9844 - recall_2: 0.9844 - val_loss: 0.3066 - val_accuracy: 0.9273 - val_auc_2: 0.9420 - val_precision_2: 0.9273 - val_recall_2: 0.9273\n",
      "Epoch 15/150\n",
      "epoch_end | time:  12.05.2021 03:11:11\n",
      " — val_aps:  0.065674 — val_a: 0.935972\n",
      "2945/2945 - 506s - loss: 0.0091 - accuracy: 0.9846 - auc_2: 0.9949 - precision_2: 0.9846 - recall_2: 0.9846 - val_loss: 0.0561 - val_accuracy: 0.9870 - val_auc_2: 0.9967 - val_precision_2: 0.9870 - val_recall_2: 0.9870\n",
      "Epoch 16/150\n",
      "epoch_end | time:  12.05.2021 03:20:15\n",
      " — val_aps:  0.057397 — val_a: 0.932477\n",
      "2945/2945 - 539s - loss: 0.0089 - accuracy: 0.9848 - auc_2: 0.9951 - precision_2: 0.9848 - recall_2: 0.9848 - val_loss: 0.2838 - val_accuracy: 0.9287 - val_auc_2: 0.9481 - val_precision_2: 0.9287 - val_recall_2: 0.9287\n",
      "Epoch 17/150\n",
      "epoch_end | time:  12.05.2021 03:28:24\n",
      " — val_aps:  0.065216 — val_a: 0.928674\n",
      "2945/2945 - 495s - loss: 0.0089 - accuracy: 0.9851 - auc_2: 0.9952 - precision_2: 0.9851 - recall_2: 0.9851 - val_loss: 0.0904 - val_accuracy: 0.9867 - val_auc_2: 0.9921 - val_precision_2: 0.9867 - val_recall_2: 0.9867\n",
      "Epoch 18/150\n",
      "epoch_end | time:  12.05.2021 03:36:57\n",
      " — val_aps:  0.061071 — val_a: 0.913180\n",
      "2945/2945 - 499s - loss: 0.0091 - accuracy: 0.9843 - auc_2: 0.9948 - precision_2: 0.9843 - recall_2: 0.9843 - val_loss: 0.0495 - val_accuracy: 0.9891 - val_auc_2: 0.9973 - val_precision_2: 0.9891 - val_recall_2: 0.9891\n",
      "Epoch 19/150\n",
      "epoch_end | time:  12.05.2021 03:44:47\n",
      " — val_aps:  0.064647 — val_a: 0.926358\n",
      "2945/2945 - 489s - loss: 0.0089 - accuracy: 0.9852 - auc_2: 0.9953 - precision_2: 0.9852 - recall_2: 0.9852 - val_loss: 0.0694 - val_accuracy: 0.9843 - val_auc_2: 0.9957 - val_precision_2: 0.9843 - val_recall_2: 0.9843\n",
      "Epoch 20/150\n",
      "epoch_end | time:  12.05.2021 03:53:32\n",
      " — val_aps:  0.060917 — val_a: 0.929312\n",
      "2945/2945 - 515s - loss: 0.0089 - accuracy: 0.9850 - auc_2: 0.9952 - precision_2: 0.9850 - recall_2: 0.9850 - val_loss: 0.1214 - val_accuracy: 0.9684 - val_auc_2: 0.9856 - val_precision_2: 0.9684 - val_recall_2: 0.9684\n",
      "Epoch 21/150\n",
      "epoch_end | time:  12.05.2021 04:01:55\n",
      " — val_aps:  0.066449 — val_a: 0.936171\n",
      "2945/2945 - 505s - loss: 0.0088 - accuracy: 0.9852 - auc_2: 0.9952 - precision_2: 0.9852 - recall_2: 0.9852 - val_loss: 0.0853 - val_accuracy: 0.9769 - val_auc_2: 0.9942 - val_precision_2: 0.9769 - val_recall_2: 0.9769\n",
      "Epoch 22/150\n",
      "epoch_end | time:  12.05.2021 04:10:15\n",
      " — val_aps:  0.065229 — val_a: 0.933738\n",
      "2945/2945 - 501s - loss: 0.0088 - accuracy: 0.9854 - auc_2: 0.9953 - precision_2: 0.9854 - recall_2: 0.9854 - val_loss: 0.1134 - val_accuracy: 0.9758 - val_auc_2: 0.9863 - val_precision_2: 0.9758 - val_recall_2: 0.9758\n",
      "Epoch 23/150\n",
      "epoch_end | time:  12.05.2021 04:18:43\n",
      " — val_aps:  0.064839 — val_a: 0.933919\n",
      "2945/2945 - 507s - loss: 0.0090 - accuracy: 0.9846 - auc_2: 0.9948 - precision_2: 0.9846 - recall_2: 0.9846 - val_loss: 0.1222 - val_accuracy: 0.9671 - val_auc_2: 0.9869 - val_precision_2: 0.9671 - val_recall_2: 0.9671\n",
      "Epoch 24/150\n",
      "epoch_end | time:  12.05.2021 04:26:54\n",
      " — val_aps:  0.058381 — val_a: 0.936213\n",
      "2945/2945 - 485s - loss: 0.0089 - accuracy: 0.9850 - auc_2: 0.9951 - precision_2: 0.9850 - recall_2: 0.9850 - val_loss: 0.3033 - val_accuracy: 0.9363 - val_auc_2: 0.9359 - val_precision_2: 0.9363 - val_recall_2: 0.9363\n",
      "Epoch 25/150\n",
      "epoch_end | time:  12.05.2021 04:34:46\n",
      " — val_aps:  0.065232 — val_a: 0.934852\n",
      "2945/2945 - 480s - loss: 0.0089 - accuracy: 0.9852 - auc_2: 0.9951 - precision_2: 0.9852 - recall_2: 0.9852 - val_loss: 0.1642 - val_accuracy: 0.9633 - val_auc_2: 0.9744 - val_precision_2: 0.9633 - val_recall_2: 0.9633\n",
      "Epoch 26/150\n",
      "epoch_end | time:  12.05.2021 04:43:09\n",
      " — val_aps:  0.065087 — val_a: 0.932678\n",
      "2945/2945 - 496s - loss: 0.0088 - accuracy: 0.9852 - auc_2: 0.9953 - precision_2: 0.9852 - recall_2: 0.9852 - val_loss: 0.0407 - val_accuracy: 0.9920 - val_auc_2: 0.9979 - val_precision_2: 0.9920 - val_recall_2: 0.9920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_cnn_best_internal_wo_btest_False_7_5_60_3_200512_4 valid_for_train:  0.8653559806867834 0.06508707621943371 | test:  0.8553191646008773 0.055213128910865134\n",
      "=====================================================================================================\n",
      "124 (185400, 124) (False, 0.0002, 5, 15, 60, 0.25, 0.0002, 20, 6)\n",
      "train_begin | time:  12.05.2021 04:44:51\n",
      "Epoch 1/150\n",
      "epoch_end | time:  12.05.2021 05:14:22\n",
      " — val_aps:  0.067846 — val_a: 0.928973\n",
      "2945/2945 - 1815s - loss: 0.0179 - accuracy: 0.9738 - auc_3: 0.9940 - precision_3: 0.9738 - recall_3: 0.9738 - val_loss: 0.0195 - val_accuracy: 0.9960 - val_auc_3: 0.9991 - val_precision_3: 0.9960 - val_recall_3: 0.9960\n",
      "Epoch 2/150\n",
      "epoch_end | time:  12.05.2021 05:44:04\n",
      " — val_aps:  0.077091 — val_a: 0.952237\n",
      "2945/2945 - 1783s - loss: 0.0073 - accuracy: 0.9855 - auc_3: 0.9974 - precision_3: 0.9855 - recall_3: 0.9855 - val_loss: 0.0260 - val_accuracy: 0.9952 - val_auc_3: 0.9997 - val_precision_3: 0.9952 - val_recall_3: 0.9952\n",
      "Epoch 3/150\n",
      "epoch_end | time:  12.05.2021 06:13:28\n",
      " — val_aps:  0.056388 — val_a: 0.940225\n",
      "2945/2945 - 1750s - loss: 0.0068 - accuracy: 0.9869 - auc_3: 0.9980 - precision_3: 0.9869 - recall_3: 0.9869 - val_loss: 0.1078 - val_accuracy: 0.9698 - val_auc_3: 0.9917 - val_precision_3: 0.9698 - val_recall_3: 0.9698\n",
      "Epoch 4/150\n",
      "epoch_end | time:  12.05.2021 06:43:00\n",
      " — val_aps:  0.067210 — val_a: 0.949112\n",
      "2945/2945 - 1784s - loss: 0.0063 - accuracy: 0.9876 - auc_3: 0.9983 - precision_3: 0.9876 - recall_3: 0.9876 - val_loss: 0.0405 - val_accuracy: 0.9895 - val_auc_3: 0.9987 - val_precision_3: 0.9895 - val_recall_3: 0.9895\n",
      "Epoch 5/150\n",
      "epoch_end | time:  12.05.2021 07:10:56\n",
      " — val_aps:  0.077142 — val_a: 0.948866\n",
      "2945/2945 - 1668s - loss: 0.0060 - accuracy: 0.9879 - auc_3: 0.9985 - precision_3: 0.9879 - recall_3: 0.9879 - val_loss: 0.0188 - val_accuracy: 0.9952 - val_auc_3: 0.9995 - val_precision_3: 0.9952 - val_recall_3: 0.9952\n",
      "Epoch 6/150\n",
      "epoch_end | time:  12.05.2021 07:37:29\n",
      " — val_aps:  0.070089 — val_a: 0.947271\n",
      "2945/2945 - 1592s - loss: 0.0059 - accuracy: 0.9876 - auc_3: 0.9986 - precision_3: 0.9876 - recall_3: 0.9876 - val_loss: 0.0241 - val_accuracy: 0.9955 - val_auc_3: 0.9996 - val_precision_3: 0.9955 - val_recall_3: 0.9955\n",
      "Epoch 7/150\n",
      "epoch_end | time:  12.05.2021 08:04:06\n",
      " — val_aps:  0.045065 — val_a: 0.938392\n",
      "2945/2945 - 1596s - loss: 0.0056 - accuracy: 0.9878 - auc_3: 0.9987 - precision_3: 0.9878 - recall_3: 0.9878 - val_loss: 0.0792 - val_accuracy: 0.9671 - val_auc_3: 0.9956 - val_precision_3: 0.9671 - val_recall_3: 0.9671\n",
      "Epoch 8/150\n",
      "epoch_end | time:  12.05.2021 08:30:34\n",
      " — val_aps:  0.073117 — val_a: 0.944176\n",
      "2945/2945 - 1588s - loss: 0.0056 - accuracy: 0.9879 - auc_3: 0.9987 - precision_3: 0.9879 - recall_3: 0.9879 - val_loss: 0.0196 - val_accuracy: 0.9957 - val_auc_3: 0.9994 - val_precision_3: 0.9957 - val_recall_3: 0.9957\n",
      "Epoch 9/150\n",
      "epoch_end | time:  12.05.2021 08:56:56\n",
      " — val_aps:  0.075803 — val_a: 0.947367\n",
      "2945/2945 - 1575s - loss: 0.0054 - accuracy: 0.9883 - auc_3: 0.9988 - precision_3: 0.9883 - recall_3: 0.9883 - val_loss: 0.0171 - val_accuracy: 0.9967 - val_auc_3: 0.9989 - val_precision_3: 0.9967 - val_recall_3: 0.9967\n",
      "Epoch 10/150\n",
      "epoch_end | time:  12.05.2021 09:22:58\n",
      " — val_aps:  0.053402 — val_a: 0.948979\n",
      "2945/2945 - 1566s - loss: 0.0054 - accuracy: 0.9880 - auc_3: 0.9988 - precision_3: 0.9880 - recall_3: 0.9880 - val_loss: 0.0351 - val_accuracy: 0.9908 - val_auc_3: 0.9989 - val_precision_3: 0.9908 - val_recall_3: 0.9908\n",
      "Epoch 11/150\n",
      "epoch_end | time:  12.05.2021 09:49:47\n",
      " — val_aps:  0.049894 — val_a: 0.936218\n",
      "2945/2945 - 1609s - loss: 0.0053 - accuracy: 0.9885 - auc_3: 0.9988 - precision_3: 0.9885 - recall_3: 0.9885 - val_loss: 0.0306 - val_accuracy: 0.9913 - val_auc_3: 0.9987 - val_precision_3: 0.9913 - val_recall_3: 0.9913\n",
      "Epoch 12/150\n",
      "epoch_end | time:  12.05.2021 10:16:06\n",
      " — val_aps:  0.063918 — val_a: 0.944632\n",
      "2945/2945 - 1576s - loss: 0.0052 - accuracy: 0.9883 - auc_3: 0.9988 - precision_3: 0.9883 - recall_3: 0.9883 - val_loss: 0.0212 - val_accuracy: 0.9950 - val_auc_3: 0.9993 - val_precision_3: 0.9950 - val_recall_3: 0.9950\n",
      "Epoch 13/150\n",
      "epoch_end | time:  12.05.2021 10:41:49\n",
      " — val_aps:  0.047376 — val_a: 0.938839\n",
      "2945/2945 - 1536s - loss: 0.0051 - accuracy: 0.9882 - auc_3: 0.9989 - precision_3: 0.9882 - recall_3: 0.9882 - val_loss: 0.1044 - val_accuracy: 0.9637 - val_auc_3: 0.9917 - val_precision_3: 0.9637 - val_recall_3: 0.9637\n",
      "Epoch 14/150\n",
      "epoch_end | time:  12.05.2021 11:07:25\n",
      " — val_aps:  0.064016 — val_a: 0.942832\n",
      "2945/2945 - 1535s - loss: 0.0051 - accuracy: 0.9886 - auc_3: 0.9989 - precision_3: 0.9886 - recall_3: 0.9886 - val_loss: 0.0175 - val_accuracy: 0.9965 - val_auc_3: 0.9989 - val_precision_3: 0.9965 - val_recall_3: 0.9965\n",
      "Epoch 15/150\n",
      "epoch_end | time:  12.05.2021 11:33:50\n",
      " — val_aps:  0.056831 — val_a: 0.940048\n",
      "2945/2945 - 1607s - loss: 0.0050 - accuracy: 0.9889 - auc_3: 0.9989 - precision_3: 0.9889 - recall_3: 0.9889 - val_loss: 0.0197 - val_accuracy: 0.9955 - val_auc_3: 0.9991 - val_precision_3: 0.9955 - val_recall_3: 0.9955\n",
      "Epoch 16/150\n",
      "epoch_end | time:  12.05.2021 12:02:24\n",
      " — val_aps:  0.041076 — val_a: 0.920905\n",
      "2945/2945 - 1701s - loss: 0.0050 - accuracy: 0.9889 - auc_3: 0.9989 - precision_3: 0.9889 - recall_3: 0.9889 - val_loss: 0.1060 - val_accuracy: 0.9565 - val_auc_3: 0.9930 - val_precision_3: 0.9565 - val_recall_3: 0.9565\n",
      "Epoch 17/150\n",
      "epoch_end | time:  12.05.2021 12:28:03\n",
      " — val_aps:  0.057168 — val_a: 0.936283\n",
      "2945/2945 - 1540s - loss: 0.0049 - accuracy: 0.9884 - auc_3: 0.9990 - precision_3: 0.9884 - recall_3: 0.9884 - val_loss: 0.0594 - val_accuracy: 0.9796 - val_auc_3: 0.9973 - val_precision_3: 0.9796 - val_recall_3: 0.9796\n",
      "Epoch 18/150\n",
      "epoch_end | time:  12.05.2021 12:52:58\n",
      " — val_aps:  0.063300 — val_a: 0.944223\n",
      "2945/2945 - 1486s - loss: 0.0049 - accuracy: 0.9887 - auc_3: 0.9990 - precision_3: 0.9887 - recall_3: 0.9887 - val_loss: 0.0184 - val_accuracy: 0.9958 - val_auc_3: 0.9992 - val_precision_3: 0.9958 - val_recall_3: 0.9958\n",
      "Epoch 19/150\n",
      "epoch_end | time:  12.05.2021 13:18:09\n",
      " — val_aps:  0.055503 — val_a: 0.936238\n",
      "2945/2945 - 1518s - loss: 0.0048 - accuracy: 0.9887 - auc_3: 0.9990 - precision_3: 0.9887 - recall_3: 0.9887 - val_loss: 0.0190 - val_accuracy: 0.9965 - val_auc_3: 0.9990 - val_precision_3: 0.9965 - val_recall_3: 0.9965\n",
      "Epoch 20/150\n",
      "epoch_end | time:  12.05.2021 13:43:24\n",
      " — val_aps:  0.066414 — val_a: 0.935047\n",
      "2945/2945 - 1513s - loss: 0.0048 - accuracy: 0.9888 - auc_3: 0.9990 - precision_3: 0.9888 - recall_3: 0.9888 - val_loss: 0.0249 - val_accuracy: 0.9946 - val_auc_3: 0.9993 - val_precision_3: 0.9946 - val_recall_3: 0.9946\n",
      "Epoch 21/150\n",
      "epoch_end | time:  12.05.2021 14:08:39\n",
      " — val_aps:  0.048823 — val_a: 0.926319\n",
      "2945/2945 - 1512s - loss: 0.0048 - accuracy: 0.9890 - auc_3: 0.9991 - precision_3: 0.9890 - recall_3: 0.9890 - val_loss: 0.0729 - val_accuracy: 0.9751 - val_auc_3: 0.9968 - val_precision_3: 0.9751 - val_recall_3: 0.9751\n",
      "Epoch 22/150\n",
      "epoch_end | time:  12.05.2021 14:34:37\n",
      " — val_aps:  0.058310 — val_a: 0.934209\n",
      "2945/2945 - 1563s - loss: 0.0047 - accuracy: 0.9891 - auc_3: 0.9990 - precision_3: 0.9891 - recall_3: 0.9891 - val_loss: 0.0182 - val_accuracy: 0.9965 - val_auc_3: 0.9987 - val_precision_3: 0.9965 - val_recall_3: 0.9965\n",
      "Epoch 23/150\n",
      "epoch_end | time:  12.05.2021 15:00:58\n",
      " — val_aps:  0.029299 — val_a: 0.908809\n",
      "2945/2945 - 1589s - loss: 0.0047 - accuracy: 0.9891 - auc_3: 0.9991 - precision_3: 0.9891 - recall_3: 0.9891 - val_loss: 0.2853 - val_accuracy: 0.9184 - val_auc_3: 0.9677 - val_precision_3: 0.9184 - val_recall_3: 0.9184\n",
      "Epoch 24/150\n",
      "epoch_end | time:  12.05.2021 15:27:30\n",
      " — val_aps:  0.077872 — val_a: 0.939165\n",
      "2945/2945 - 1578s - loss: 0.0046 - accuracy: 0.9891 - auc_3: 0.9991 - precision_3: 0.9891 - recall_3: 0.9891 - val_loss: 0.0189 - val_accuracy: 0.9957 - val_auc_3: 0.9990 - val_precision_3: 0.9957 - val_recall_3: 0.9957\n",
      "Epoch 25/150\n",
      "epoch_end | time:  12.05.2021 15:51:33\n",
      " — val_aps:  0.069677 — val_a: 0.938319\n",
      "2945/2945 - 1437s - loss: 0.0046 - accuracy: 0.9890 - auc_3: 0.9991 - precision_3: 0.9890 - recall_3: 0.9890 - val_loss: 0.0233 - val_accuracy: 0.9949 - val_auc_3: 0.9983 - val_precision_3: 0.9949 - val_recall_3: 0.9949\n",
      "Epoch 26/150\n",
      "epoch_end | time:  12.05.2021 16:15:37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — val_aps:  0.060525 — val_a: 0.938509\n",
      "2945/2945 - 1451s - loss: 0.0046 - accuracy: 0.9889 - auc_3: 0.9991 - precision_3: 0.9889 - recall_3: 0.9889 - val_loss: 0.0278 - val_accuracy: 0.9915 - val_auc_3: 0.9987 - val_precision_3: 0.9915 - val_recall_3: 0.9915\n",
      "Epoch 27/150\n",
      "epoch_end | time:  12.05.2021 16:43:16\n",
      " — val_aps:  0.058102 — val_a: 0.932877\n",
      "2945/2945 - 1666s - loss: 0.0046 - accuracy: 0.9893 - auc_3: 0.9991 - precision_3: 0.9893 - recall_3: 0.9893 - val_loss: 0.0562 - val_accuracy: 0.9845 - val_auc_3: 0.9983 - val_precision_3: 0.9845 - val_recall_3: 0.9845\n",
      "Epoch 28/150\n",
      "epoch_end | time:  12.05.2021 17:10:11\n",
      " — val_aps:  0.054581 — val_a: 0.920552\n",
      "2945/2945 - 1616s - loss: 0.0045 - accuracy: 0.9892 - auc_3: 0.9991 - precision_3: 0.9892 - recall_3: 0.9892 - val_loss: 0.0362 - val_accuracy: 0.9890 - val_auc_3: 0.9985 - val_precision_3: 0.9890 - val_recall_3: 0.9890\n",
      "Epoch 29/150\n",
      "epoch_end | time:  12.05.2021 17:39:47\n",
      " — val_aps:  0.058711 — val_a: 0.932275\n",
      "2945/2945 - 1807s - loss: 0.0045 - accuracy: 0.9891 - auc_3: 0.9991 - precision_3: 0.9891 - recall_3: 0.9891 - val_loss: 0.0775 - val_accuracy: 0.9704 - val_auc_3: 0.9958 - val_precision_3: 0.9704 - val_recall_3: 0.9704\n",
      "model_cnn_best_internal_wo_btest_False_5_15_60_6_200512_17 valid_for_train:  0.8645495115826367 0.05871103740980799 | test:  0.8832018279949518 0.05706165333981805\n",
      "=====================================================================================================\n",
      "124 (185400, 124) (False, 0.0001, 3, 10, 100, 0.25, 0.0002, 20, 8)\n",
      "train_begin | time:  12.05.2021 17:44:03\n",
      "Epoch 1/150\n",
      "epoch_end | time:  12.05.2021 18:07:16\n",
      " — val_aps:  0.043524 — val_a: 0.912638\n",
      "2945/2945 - 1472s - loss: 0.0169 - accuracy: 0.9748 - auc_4: 0.9942 - precision_4: 0.9748 - recall_4: 0.9748 - val_loss: 0.0238 - val_accuracy: 0.9957 - val_auc_4: 0.9993 - val_precision_4: 0.9957 - val_recall_4: 0.9957\n",
      "Epoch 2/150\n",
      "epoch_end | time:  12.05.2021 18:36:09\n",
      " — val_aps:  0.071550 — val_a: 0.949269\n",
      "2945/2945 - 1711s - loss: 0.0077 - accuracy: 0.9861 - auc_4: 0.9972 - precision_4: 0.9861 - recall_4: 0.9861 - val_loss: 0.0541 - val_accuracy: 0.9881 - val_auc_4: 0.9987 - val_precision_4: 0.9881 - val_recall_4: 0.9881\n",
      "Epoch 3/150\n",
      "epoch_end | time:  12.05.2021 19:00:57\n",
      " — val_aps:  0.047586 — val_a: 0.936068\n",
      "2945/2945 - 1481s - loss: 0.0069 - accuracy: 0.9876 - auc_4: 0.9978 - precision_4: 0.9876 - recall_4: 0.9876 - val_loss: 0.1291 - val_accuracy: 0.9691 - val_auc_4: 0.9873 - val_precision_4: 0.9691 - val_recall_4: 0.9691\n",
      "Epoch 4/150\n",
      "epoch_end | time:  12.05.2021 19:23:14\n",
      " — val_aps:  0.047210 — val_a: 0.936745\n",
      "2945/2945 - 1324s - loss: 0.0065 - accuracy: 0.9878 - auc_4: 0.9981 - precision_4: 0.9878 - recall_4: 0.9878 - val_loss: 0.1480 - val_accuracy: 0.9530 - val_auc_4: 0.9862 - val_precision_4: 0.9530 - val_recall_4: 0.9530\n",
      "Epoch 5/150\n",
      "epoch_end | time:  12.05.2021 19:45:09\n",
      " — val_aps:  0.051754 — val_a: 0.930781\n",
      "2945/2945 - 1311s - loss: 0.0063 - accuracy: 0.9874 - auc_4: 0.9982 - precision_4: 0.9874 - recall_4: 0.9874 - val_loss: 0.0575 - val_accuracy: 0.9847 - val_auc_4: 0.9969 - val_precision_4: 0.9847 - val_recall_4: 0.9847\n",
      "Epoch 6/150\n",
      "epoch_end | time:  12.05.2021 20:05:41\n",
      " — val_aps:  0.044174 — val_a: 0.935986\n",
      "2945/2945 - 1233s - loss: 0.0060 - accuracy: 0.9883 - auc_4: 0.9984 - precision_4: 0.9883 - recall_4: 0.9883 - val_loss: 0.0871 - val_accuracy: 0.9663 - val_auc_4: 0.9950 - val_precision_4: 0.9663 - val_recall_4: 0.9663\n",
      "Epoch 7/150\n",
      "epoch_end | time:  12.05.2021 20:26:04\n",
      " — val_aps:  0.056268 — val_a: 0.942994\n",
      "2945/2945 - 1219s - loss: 0.0058 - accuracy: 0.9879 - auc_4: 0.9985 - precision_4: 0.9879 - recall_4: 0.9879 - val_loss: 0.0463 - val_accuracy: 0.9853 - val_auc_4: 0.9986 - val_precision_4: 0.9853 - val_recall_4: 0.9853\n",
      "Epoch 8/150\n",
      "epoch_end | time:  12.05.2021 20:46:11\n",
      " — val_aps:  0.067089 — val_a: 0.940618\n",
      "2945/2945 - 1205s - loss: 0.0057 - accuracy: 0.9885 - auc_4: 0.9986 - precision_4: 0.9885 - recall_4: 0.9885 - val_loss: 0.0278 - val_accuracy: 0.9933 - val_auc_4: 0.9994 - val_precision_4: 0.9933 - val_recall_4: 0.9933\n",
      "Epoch 9/150\n",
      "epoch_end | time:  12.05.2021 21:06:39\n",
      " — val_aps:  0.037626 — val_a: 0.928793\n",
      "2945/2945 - 1221s - loss: 0.0056 - accuracy: 0.9884 - auc_4: 0.9986 - precision_4: 0.9884 - recall_4: 0.9884 - val_loss: 0.0424 - val_accuracy: 0.9896 - val_auc_4: 0.9979 - val_precision_4: 0.9896 - val_recall_4: 0.9896\n",
      "Epoch 10/150\n",
      "epoch_end | time:  12.05.2021 21:26:47\n",
      " — val_aps:  0.052502 — val_a: 0.941462\n",
      "2945/2945 - 1208s - loss: 0.0055 - accuracy: 0.9885 - auc_4: 0.9986 - precision_4: 0.9885 - recall_4: 0.9885 - val_loss: 0.1159 - val_accuracy: 0.9587 - val_auc_4: 0.9913 - val_precision_4: 0.9587 - val_recall_4: 0.9587\n",
      "Epoch 11/150\n",
      "epoch_end | time:  12.05.2021 21:47:23\n",
      " — val_aps:  0.057836 — val_a: 0.941666\n",
      "2945/2945 - 1239s - loss: 0.0054 - accuracy: 0.9887 - auc_4: 0.9987 - precision_4: 0.9887 - recall_4: 0.9887 - val_loss: 0.0616 - val_accuracy: 0.9829 - val_auc_4: 0.9968 - val_precision_4: 0.9829 - val_recall_4: 0.9829\n",
      "Epoch 12/150\n",
      "epoch_end | time:  12.05.2021 22:07:04\n",
      " — val_aps:  0.068001 — val_a: 0.931874\n",
      "2945/2945 - 1173s - loss: 0.0054 - accuracy: 0.9888 - auc_4: 0.9987 - precision_4: 0.9888 - recall_4: 0.9888 - val_loss: 0.0294 - val_accuracy: 0.9916 - val_auc_4: 0.9993 - val_precision_4: 0.9916 - val_recall_4: 0.9916\n",
      "Epoch 13/150\n",
      "epoch_end | time:  12.05.2021 22:25:04\n",
      " — val_aps:  0.047647 — val_a: 0.931302\n",
      "2945/2945 - 1080s - loss: 0.0053 - accuracy: 0.9889 - auc_4: 0.9988 - precision_4: 0.9889 - recall_4: 0.9889 - val_loss: 0.0236 - val_accuracy: 0.9942 - val_auc_4: 0.9990 - val_precision_4: 0.9942 - val_recall_4: 0.9942\n",
      "Epoch 14/150\n",
      "epoch_end | time:  12.05.2021 22:43:11\n",
      " — val_aps:  0.058739 — val_a: 0.943483\n",
      "2945/2945 - 1084s - loss: 0.0053 - accuracy: 0.9889 - auc_4: 0.9987 - precision_4: 0.9889 - recall_4: 0.9889 - val_loss: 0.0217 - val_accuracy: 0.9948 - val_auc_4: 0.9992 - val_precision_4: 0.9948 - val_recall_4: 0.9948\n",
      "Epoch 15/150\n",
      "epoch_end | time:  12.05.2021 23:01:10\n",
      " — val_aps:  0.056437 — val_a: 0.936035\n",
      "2945/2945 - 1080s - loss: 0.0052 - accuracy: 0.9885 - auc_4: 0.9988 - precision_4: 0.9885 - recall_4: 0.9885 - val_loss: 0.0492 - val_accuracy: 0.9856 - val_auc_4: 0.9980 - val_precision_4: 0.9856 - val_recall_4: 0.9856\n",
      "Epoch 16/150\n",
      "epoch_end | time:  12.05.2021 23:20:45\n",
      " — val_aps:  0.059935 — val_a: 0.929728\n",
      "2945/2945 - 1181s - loss: 0.0051 - accuracy: 0.9889 - auc_4: 0.9988 - precision_4: 0.9889 - recall_4: 0.9889 - val_loss: 0.0261 - val_accuracy: 0.9912 - val_auc_4: 0.9991 - val_precision_4: 0.9912 - val_recall_4: 0.9912\n",
      "Epoch 17/150\n",
      "epoch_end | time:  12.05.2021 23:41:04\n",
      " — val_aps:  0.055050 — val_a: 0.912002\n",
      "2945/2945 - 1221s - loss: 0.0051 - accuracy: 0.9889 - auc_4: 0.9989 - precision_4: 0.9889 - recall_4: 0.9889 - val_loss: 0.0194 - val_accuracy: 0.9964 - val_auc_4: 0.9985 - val_precision_4: 0.9964 - val_recall_4: 0.9964\n",
      "Epoch 18/150\n",
      "epoch_end | time:  13.05.2021 00:01:27\n",
      " — val_aps:  0.048309 — val_a: 0.943469\n",
      "2945/2945 - 1221s - loss: 0.0051 - accuracy: 0.9885 - auc_4: 0.9989 - precision_4: 0.9885 - recall_4: 0.9885 - val_loss: 0.0603 - val_accuracy: 0.9823 - val_auc_4: 0.9970 - val_precision_4: 0.9823 - val_recall_4: 0.9823\n",
      "Epoch 19/150\n",
      "epoch_end | time:  13.05.2021 00:21:41\n",
      " — val_aps:  0.055922 — val_a: 0.936910\n",
      "2945/2945 - 1214s - loss: 0.0050 - accuracy: 0.9888 - auc_4: 0.9989 - precision_4: 0.9888 - recall_4: 0.9888 - val_loss: 0.0286 - val_accuracy: 0.9918 - val_auc_4: 0.9990 - val_precision_4: 0.9918 - val_recall_4: 0.9918\n",
      "Epoch 20/150\n",
      "epoch_end | time:  13.05.2021 00:42:04\n",
      " — val_aps:  0.048534 — val_a: 0.939202\n",
      "2945/2945 - 1222s - loss: 0.0049 - accuracy: 0.9891 - auc_4: 0.9989 - precision_4: 0.9891 - recall_4: 0.9891 - val_loss: 0.0299 - val_accuracy: 0.9915 - val_auc_4: 0.9992 - val_precision_4: 0.9915 - val_recall_4: 0.9915\n",
      "Epoch 21/150\n",
      "epoch_end | time:  13.05.2021 01:02:19\n",
      " — val_aps:  0.047559 — val_a: 0.920546\n",
      "2945/2945 - 1216s - loss: 0.0049 - accuracy: 0.9890 - auc_4: 0.9990 - precision_4: 0.9890 - recall_4: 0.9890 - val_loss: 0.0453 - val_accuracy: 0.9851 - val_auc_4: 0.9979 - val_precision_4: 0.9851 - val_recall_4: 0.9851\n",
      "Epoch 22/150\n",
      "epoch_end | time:  13.05.2021 01:22:49\n",
      " — val_aps:  0.053817 — val_a: 0.941454\n",
      "2945/2945 - 1227s - loss: 0.0049 - accuracy: 0.9889 - auc_4: 0.9989 - precision_4: 0.9889 - recall_4: 0.9889 - val_loss: 0.0393 - val_accuracy: 0.9882 - val_auc_4: 0.9987 - val_precision_4: 0.9882 - val_recall_4: 0.9882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/150\n",
      "epoch_end | time:  13.05.2021 01:42:47\n",
      " — val_aps:  0.056040 — val_a: 0.937108\n",
      "2945/2945 - 1194s - loss: 0.0049 - accuracy: 0.9890 - auc_4: 0.9989 - precision_4: 0.9890 - recall_4: 0.9890 - val_loss: 0.0310 - val_accuracy: 0.9947 - val_auc_4: 0.9995 - val_precision_4: 0.9947 - val_recall_4: 0.9947\n",
      "Epoch 24/150\n",
      "epoch_end | time:  13.05.2021 02:02:38\n",
      " — val_aps:  0.057056 — val_a: 0.938439\n",
      "2945/2945 - 1190s - loss: 0.0049 - accuracy: 0.9891 - auc_4: 0.9990 - precision_4: 0.9891 - recall_4: 0.9891 - val_loss: 0.0528 - val_accuracy: 0.9866 - val_auc_4: 0.9985 - val_precision_4: 0.9866 - val_recall_4: 0.9866\n",
      "Epoch 25/150\n",
      "epoch_end | time:  13.05.2021 02:22:45\n",
      " — val_aps:  0.057996 — val_a: 0.942614\n",
      "2945/2945 - 1206s - loss: 0.0049 - accuracy: 0.9892 - auc_4: 0.9990 - precision_4: 0.9892 - recall_4: 0.9892 - val_loss: 0.0276 - val_accuracy: 0.9921 - val_auc_4: 0.9989 - val_precision_4: 0.9921 - val_recall_4: 0.9921\n",
      "Epoch 26/150\n",
      "epoch_end | time:  13.05.2021 02:43:00\n",
      " — val_aps:  0.057981 — val_a: 0.941766\n",
      "2945/2945 - 1214s - loss: 0.0048 - accuracy: 0.9890 - auc_4: 0.9990 - precision_4: 0.9890 - recall_4: 0.9890 - val_loss: 0.0308 - val_accuracy: 0.9910 - val_auc_4: 0.9993 - val_precision_4: 0.9910 - val_recall_4: 0.9910\n",
      "Epoch 27/150\n",
      "epoch_end | time:  13.05.2021 03:03:22\n",
      " — val_aps:  0.058052 — val_a: 0.935187\n",
      "2945/2945 - 1226s - loss: 0.0048 - accuracy: 0.9891 - auc_4: 0.9990 - precision_4: 0.9891 - recall_4: 0.9891 - val_loss: 0.0582 - val_accuracy: 0.9815 - val_auc_4: 0.9975 - val_precision_4: 0.9815 - val_recall_4: 0.9815\n",
      "Epoch 28/150\n",
      "epoch_end | time:  13.05.2021 03:23:41\n",
      " — val_aps:  0.042126 — val_a: 0.925592\n",
      "2945/2945 - 1217s - loss: 0.0047 - accuracy: 0.9890 - auc_4: 0.9990 - precision_4: 0.9890 - recall_4: 0.9890 - val_loss: 0.0496 - val_accuracy: 0.9770 - val_auc_4: 0.9982 - val_precision_4: 0.9770 - val_recall_4: 0.9770\n",
      "Epoch 29/150\n",
      "epoch_end | time:  13.05.2021 03:43:43\n",
      " — val_aps:  0.054597 — val_a: 0.933934\n",
      "2945/2945 - 1197s - loss: 0.0047 - accuracy: 0.9889 - auc_4: 0.9990 - precision_4: 0.9889 - recall_4: 0.9889 - val_loss: 0.0242 - val_accuracy: 0.9931 - val_auc_4: 0.9988 - val_precision_4: 0.9931 - val_recall_4: 0.9931\n",
      "Epoch 30/150\n",
      "epoch_end | time:  13.05.2021 04:03:38\n",
      " — val_aps:  0.040303 — val_a: 0.925453\n",
      "2945/2945 - 1196s - loss: 0.0047 - accuracy: 0.9892 - auc_4: 0.9990 - precision_4: 0.9892 - recall_4: 0.9892 - val_loss: 0.0803 - val_accuracy: 0.9690 - val_auc_4: 0.9957 - val_precision_4: 0.9690 - val_recall_4: 0.9690\n",
      "Epoch 31/150\n",
      "epoch_end | time:  13.05.2021 04:23:52\n",
      " — val_aps:  0.057175 — val_a: 0.934701\n",
      "2945/2945 - 1214s - loss: 0.0046 - accuracy: 0.9892 - auc_4: 0.9990 - precision_4: 0.9892 - recall_4: 0.9892 - val_loss: 0.0519 - val_accuracy: 0.9850 - val_auc_4: 0.9980 - val_precision_4: 0.9850 - val_recall_4: 0.9850\n",
      "Epoch 32/150\n",
      "epoch_end | time:  13.05.2021 04:43:48\n",
      " — val_aps:  0.051082 — val_a: 0.923134\n",
      "2945/2945 - 1198s - loss: 0.0046 - accuracy: 0.9893 - auc_4: 0.9991 - precision_4: 0.9893 - recall_4: 0.9893 - val_loss: 0.0218 - val_accuracy: 0.9952 - val_auc_4: 0.9987 - val_precision_4: 0.9952 - val_recall_4: 0.9952\n",
      "Epoch 33/150\n",
      "epoch_end | time:  13.05.2021 05:04:01\n",
      " — val_aps:  0.049745 — val_a: 0.932228\n",
      "2945/2945 - 1209s - loss: 0.0046 - accuracy: 0.9895 - auc_4: 0.9991 - precision_4: 0.9895 - recall_4: 0.9895 - val_loss: 0.0584 - val_accuracy: 0.9830 - val_auc_4: 0.9980 - val_precision_4: 0.9830 - val_recall_4: 0.9830\n",
      "Epoch 34/150\n",
      "epoch_end | time:  13.05.2021 05:23:49\n",
      " — val_aps:  0.058852 — val_a: 0.938272\n",
      "2945/2945 - 1188s - loss: 0.0046 - accuracy: 0.9898 - auc_4: 0.9990 - precision_4: 0.9898 - recall_4: 0.9898 - val_loss: 0.0212 - val_accuracy: 0.9951 - val_auc_4: 0.9989 - val_precision_4: 0.9951 - val_recall_4: 0.9951\n",
      "Epoch 35/150\n",
      "epoch_end | time:  13.05.2021 05:43:43\n",
      " — val_aps:  0.037906 — val_a: 0.928039\n",
      "2945/2945 - 1190s - loss: 0.0046 - accuracy: 0.9895 - auc_4: 0.9991 - precision_4: 0.9895 - recall_4: 0.9895 - val_loss: 0.0859 - val_accuracy: 0.9741 - val_auc_4: 0.9953 - val_precision_4: 0.9741 - val_recall_4: 0.9741\n",
      "Epoch 36/150\n",
      "epoch_end | time:  13.05.2021 06:03:29\n",
      " — val_aps:  0.045700 — val_a: 0.934387\n",
      "2945/2945 - 1188s - loss: 0.0045 - accuracy: 0.9894 - auc_4: 0.9991 - precision_4: 0.9894 - recall_4: 0.9894 - val_loss: 0.0466 - val_accuracy: 0.9833 - val_auc_4: 0.9980 - val_precision_4: 0.9833 - val_recall_4: 0.9833\n",
      "Epoch 37/150\n",
      "epoch_end | time:  13.05.2021 06:23:25\n",
      " — val_aps:  0.055529 — val_a: 0.927548\n",
      "2945/2945 - 1198s - loss: 0.0045 - accuracy: 0.9895 - auc_4: 0.9991 - precision_4: 0.9895 - recall_4: 0.9895 - val_loss: 0.0196 - val_accuracy: 0.9965 - val_auc_4: 0.9993 - val_precision_4: 0.9965 - val_recall_4: 0.9965\n",
      "model_cnn_best_internal_wo_btest_False_3_10_100_8_200513_6 valid_for_train:  0.8550952005128236 0.055529377753163627 | test:  0.8630870464528724 0.060441684809821795\n"
     ]
    }
   ],
   "source": [
    "VERBOSE = 2\n",
    "BATCH_SIZE = 512\n",
    "NB_EPOCH = 150\n",
    "class_weighting = {0: 0.05, 1: 1}\n",
    "\n",
    "result_all_8 = pd.DataFrame()\n",
    "result_all_8['name_model'] = None\n",
    "result_all_8['params'] = None\n",
    "result_all_8['val_GINI'] = None\n",
    "result_all_8['val_APS'] = None\n",
    "result_all_8['test_GINI'] = None\n",
    "result_all_8['test_APS'] = None\n",
    "j = 0\n",
    "\n",
    "for p in param_best:\n",
    "    print('=====================================================================================================')\n",
    "    print(inp_shape, X_2_2.shape, p)\n",
    "\n",
    "    model_grid = model_cnn_3(reg=p[1], reg_dense=p[6], n_features=inp_shape, n_pool=2, n_kernel=p[2],\n",
    "                             n_filters=p[3], n_strides=1, classes=2,\n",
    "                             hidden=p[4], drop_out=p[5],\n",
    "                             gl_pool_max=p[0], min_pool=p[7], n_lay=p[8])\n",
    "\n",
    "    model_grid.compile(loss='categorical_crossentropy',\n",
    "                       optimizer=tf.keras.optimizers.Adam(learning_rate=0.003),\n",
    "                       metrics=['accuracy', tf.keras.metrics.AUC(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "    history_XX = model_grid.fit_generator(generator=training_generator,  # training_aug,\n",
    "                                          # Y_test_2 = np_utils.to_categorical( y_val, 2)\n",
    "                                          validation_data=(X_2_2, Y_test_2),\n",
    "                                          epochs=NB_EPOCH, verbose=VERBOSE, class_weight=class_weighting,\n",
    "                                          callbacks=[_time, EarlyStopping(monitor='val_loss', patience=20),\n",
    "                                                     Metrics(valid_data=(X_2_2, Y_test_2))])\n",
    "\n",
    "    res_model_ = pd.DataFrame(\n",
    "        history_XX.history, columns=history_XX.history.keys())\n",
    "    dd = str(200000 + datetime.now().month*100 +\n",
    "             datetime.now().day) + '_' + str(datetime.now().hour)\n",
    "    name_m = 'model_cnn_best_internal_wo_btest_' + str(p[0]) + '_' + str(\n",
    "        p[2]) + '_' + str(p[3]) + '_' + str(p[4]) + '_' + str(p[8]) + '_' + str(dd)\n",
    "\n",
    "    model_grid.save(name_m + '.h5')\n",
    "    res_model_.to_csv(name_m + '.csv')\n",
    "\n",
    "    predict_class_val = model_grid.predict(X_2_2)\n",
    "    APS = metrics.average_precision_score(y_test, predict_class_val[:, 1])\n",
    "    GINI = 2*(metrics.roc_auc_score(y_test, predict_class_val[:, 1])) - 1\n",
    "\n",
    "    predict_class_test = model_grid.predict(X_3_2)\n",
    "    APS_t = metrics.average_precision_score( y_val, predict_class_test[:, 1])\n",
    "    GINI_t = 2*(metrics.roc_auc_score( y_val, predict_class_test[:, 1])) - 1\n",
    "\n",
    "    result_all_8.at[j, 'name_model'] = name_m\n",
    "    result_all_8.at[j, 'params'] = str(p)\n",
    "    result_all_8.at[j, 'val_GINI'] = GINI\n",
    "    result_all_8.at[j, 'val_APS'] = APS\n",
    "    result_all_8.at[j, 'test_GINI'] = GINI_t\n",
    "    result_all_8.at[j, 'test_APS'] = APS_t\n",
    "\n",
    "    result_all_8.to_csv('model_cnn_internal_wo_btest.csv')\n",
    "    j += 1\n",
    "    print(name_m, 'valid_for_train: ', GINI, APS, '| test: ', GINI_t, APS_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The best CNNs by Profit-metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_cnn_internal_grid_False_5_10_30_6_200505_13.h5 #cnn-6 best money\n",
    "# model_cnn_internal_grid_False_5_15_60_8_200508_11.h5 #cnn-8 best money\n",
    "# model_cnn_internal_grid_False_7_15_60_3_200502_12.h5 #cnn-3 best money\n",
    "\n",
    "# model_cnn_internal_grid_False_7_5_60_3_200501_13.h5 #cnn-3 best APS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_best = ((False, 0.0002, 7, 5, 60, 0.25, 0.0002, 20, 3), #cnn-3 best APS\n",
    "              \n",
    "         (False, 0.0002, 5, 10, 30, 0.25, 0.0002, 20, 6), #cnn-6 best money\n",
    "          (False, 0.0002, 5, 15, 60, 0.25, 0.0002, 20, 8) ,  #cnn-8 best money  \n",
    "              \n",
    "         (False, 0.0001, 7, 15, 60, 0.25, 0.0002, 20, 3)) #cnn-3 best money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_shape = X_2_2.shape[1]\n",
    "inp_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((185400, 124), (185400, 2))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2_2.shape, Y_test_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col = X_2_2.columns\n",
    "y_col = 'BAD_FLAG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124 BAD_FLAG\n"
     ]
    }
   ],
   "source": [
    "training_generator = DataGenerator(train_for, x_col, y_col, batch_size=512, alpha = None, class_w = 0.05 )\n",
    "print(len(x_col), y_col )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================================================\n",
      "124 (185400, 124) (False, 0.0002, 7, 5, 60, 0.25, 0.0002, 20, 3)\n",
      "train_begin | time:  14.05.2021 00:16:28\n",
      "Epoch 1/150\n",
      "epoch_end | time:  14.05.2021 00:22:57\n",
      " — val_aps:  0.057412 — val_a: 0.917690\n",
      "2945/2945 - 410s - loss: 0.0184 - accuracy: 0.9542 - auc_8: 0.9873 - precision_8: 0.9542 - recall_8: 0.9542 - val_loss: 0.1010 - val_accuracy: 0.9706 - val_auc_8: 0.9913 - val_precision_8: 0.9706 - val_recall_8: 0.9706\n",
      "Epoch 2/150\n",
      "epoch_end | time:  14.05.2021 00:29:39\n",
      " — val_aps:  0.056694 — val_a: 0.926985\n",
      "2945/2945 - 401s - loss: 0.0121 - accuracy: 0.9739 - auc_8: 0.9924 - precision_8: 0.9739 - recall_8: 0.9739 - val_loss: 0.2894 - val_accuracy: 0.9128 - val_auc_8: 0.9495 - val_precision_8: 0.9128 - val_recall_8: 0.9128\n",
      "Epoch 3/150\n",
      "epoch_end | time:  14.05.2021 00:36:19\n",
      " — val_aps:  0.068777 — val_a: 0.931738\n",
      "2945/2945 - 401s - loss: 0.0108 - accuracy: 0.9770 - auc_8: 0.9936 - precision_8: 0.9770 - recall_8: 0.9770 - val_loss: 0.0482 - val_accuracy: 0.9867 - val_auc_8: 0.9983 - val_precision_8: 0.9867 - val_recall_8: 0.9867\n",
      "Epoch 4/150\n",
      "epoch_end | time:  14.05.2021 00:43:03\n",
      " — val_aps:  0.059484 — val_a: 0.938054\n",
      "2945/2945 - 403s - loss: 0.0104 - accuracy: 0.9775 - auc_8: 0.9940 - precision_8: 0.9775 - recall_8: 0.9775 - val_loss: 0.1150 - val_accuracy: 0.9668 - val_auc_8: 0.9890 - val_precision_8: 0.9668 - val_recall_8: 0.9668\n",
      "Epoch 5/150\n",
      "epoch_end | time:  14.05.2021 00:49:36\n",
      " — val_aps:  0.057970 — val_a: 0.936967\n",
      "2945/2945 - 393s - loss: 0.0099 - accuracy: 0.9794 - auc_8: 0.9946 - precision_8: 0.9794 - recall_8: 0.9794 - val_loss: 0.0702 - val_accuracy: 0.9836 - val_auc_8: 0.9963 - val_precision_8: 0.9836 - val_recall_8: 0.9836\n",
      "Epoch 6/150\n",
      "epoch_end | time:  14.05.2021 00:56:12\n",
      " — val_aps:  0.062992 — val_a: 0.938995\n",
      "2945/2945 - 396s - loss: 0.0098 - accuracy: 0.9794 - auc_8: 0.9946 - precision_8: 0.9794 - recall_8: 0.9794 - val_loss: 0.0501 - val_accuracy: 0.9878 - val_auc_8: 0.9978 - val_precision_8: 0.9878 - val_recall_8: 0.9878\n",
      "Epoch 7/150\n",
      "epoch_end | time:  14.05.2021 01:03:03\n",
      " — val_aps:  0.062722 — val_a: 0.936044\n",
      "2945/2945 - 412s - loss: 0.0097 - accuracy: 0.9797 - auc_8: 0.9946 - precision_8: 0.9797 - recall_8: 0.9797 - val_loss: 0.0402 - val_accuracy: 0.9916 - val_auc_8: 0.9987 - val_precision_8: 0.9916 - val_recall_8: 0.9916\n",
      "Epoch 8/150\n",
      "epoch_end | time:  14.05.2021 01:09:47\n",
      " — val_aps:  0.062636 — val_a: 0.939678\n",
      "2945/2945 - 402s - loss: 0.0096 - accuracy: 0.9804 - auc_8: 0.9948 - precision_8: 0.9804 - recall_8: 0.9804 - val_loss: 0.0505 - val_accuracy: 0.9850 - val_auc_8: 0.9979 - val_precision_8: 0.9850 - val_recall_8: 0.9850\n",
      "Epoch 9/150\n",
      "epoch_end | time:  14.05.2021 01:16:28\n",
      " — val_aps:  0.052760 — val_a: 0.927165\n",
      "2945/2945 - 400s - loss: 0.0095 - accuracy: 0.9807 - auc_8: 0.9950 - precision_8: 0.9807 - recall_8: 0.9807 - val_loss: 0.2366 - val_accuracy: 0.9321 - val_auc_8: 0.9627 - val_precision_8: 0.9321 - val_recall_8: 0.9321\n",
      "Epoch 10/150\n",
      "epoch_end | time:  14.05.2021 01:23:05\n",
      " — val_aps:  0.057093 — val_a: 0.935593\n",
      "2945/2945 - 396s - loss: 0.0093 - accuracy: 0.9816 - auc_8: 0.9953 - precision_8: 0.9816 - recall_8: 0.9816 - val_loss: 0.0677 - val_accuracy: 0.9816 - val_auc_8: 0.9950 - val_precision_8: 0.9816 - val_recall_8: 0.9816\n",
      "Epoch 11/150\n",
      "epoch_end | time:  14.05.2021 01:29:35\n",
      " — val_aps:  0.048901 — val_a: 0.933230\n",
      "2945/2945 - 392s - loss: 0.0092 - accuracy: 0.9819 - auc_8: 0.9954 - precision_8: 0.9819 - recall_8: 0.9819 - val_loss: 0.1192 - val_accuracy: 0.9656 - val_auc_8: 0.9876 - val_precision_8: 0.9656 - val_recall_8: 0.9656\n",
      "Epoch 12/150\n",
      "epoch_end | time:  14.05.2021 01:36:16\n",
      " — val_aps:  0.070392 — val_a: 0.940822\n",
      "2945/2945 - 402s - loss: 0.0093 - accuracy: 0.9821 - auc_8: 0.9954 - precision_8: 0.9821 - recall_8: 0.9821 - val_loss: 0.0477 - val_accuracy: 0.9865 - val_auc_8: 0.9989 - val_precision_8: 0.9865 - val_recall_8: 0.9865\n",
      "Epoch 13/150\n",
      "epoch_end | time:  14.05.2021 01:42:48\n",
      " — val_aps:  0.063231 — val_a: 0.939149\n",
      "2945/2945 - 389s - loss: 0.0091 - accuracy: 0.9825 - auc_8: 0.9956 - precision_8: 0.9825 - recall_8: 0.9825 - val_loss: 0.1308 - val_accuracy: 0.9657 - val_auc_8: 0.9869 - val_precision_8: 0.9657 - val_recall_8: 0.9657\n",
      "Epoch 14/150\n",
      "epoch_end | time:  14.05.2021 01:49:34\n",
      " — val_aps:  0.064078 — val_a: 0.941832\n",
      "2945/2945 - 407s - loss: 0.0091 - accuracy: 0.9823 - auc_8: 0.9956 - precision_8: 0.9823 - recall_8: 0.9823 - val_loss: 0.0436 - val_accuracy: 0.9885 - val_auc_8: 0.9978 - val_precision_8: 0.9885 - val_recall_8: 0.9885\n",
      "Epoch 15/150\n",
      "epoch_end | time:  14.05.2021 01:56:13\n",
      " — val_aps:  0.065486 — val_a: 0.936058\n",
      "2945/2945 - 397s - loss: 0.0089 - accuracy: 0.9831 - auc_8: 0.9959 - precision_8: 0.9831 - recall_8: 0.9831 - val_loss: 0.0382 - val_accuracy: 0.9901 - val_auc_8: 0.9989 - val_precision_8: 0.9901 - val_recall_8: 0.9901\n",
      "Epoch 16/150\n",
      "epoch_end | time:  14.05.2021 02:02:46\n",
      " — val_aps:  0.068418 — val_a: 0.940722\n",
      "2945/2945 - 391s - loss: 0.0090 - accuracy: 0.9826 - auc_8: 0.9958 - precision_8: 0.9826 - recall_8: 0.9826 - val_loss: 0.0721 - val_accuracy: 0.9775 - val_auc_8: 0.9961 - val_precision_8: 0.9775 - val_recall_8: 0.9775\n",
      "Epoch 17/150\n",
      "epoch_end | time:  14.05.2021 02:09:22\n",
      " — val_aps:  0.064197 — val_a: 0.939237\n",
      "2945/2945 - 399s - loss: 0.0090 - accuracy: 0.9828 - auc_8: 0.9957 - precision_8: 0.9828 - recall_8: 0.9828 - val_loss: 0.0623 - val_accuracy: 0.9873 - val_auc_8: 0.9971 - val_precision_8: 0.9873 - val_recall_8: 0.9873\n",
      "Epoch 18/150\n",
      "epoch_end | time:  14.05.2021 02:16:01\n",
      " — val_aps:  0.067773 — val_a: 0.934898\n",
      "2945/2945 - 397s - loss: 0.0090 - accuracy: 0.9831 - auc_8: 0.9958 - precision_8: 0.9831 - recall_8: 0.9831 - val_loss: 0.0419 - val_accuracy: 0.9883 - val_auc_8: 0.9985 - val_precision_8: 0.9883 - val_recall_8: 0.9883\n",
      "Epoch 19/150\n",
      "epoch_end | time:  14.05.2021 02:22:34\n",
      " — val_aps:  0.067098 — val_a: 0.935488\n",
      "2945/2945 - 393s - loss: 0.0090 - accuracy: 0.9830 - auc_8: 0.9958 - precision_8: 0.9830 - recall_8: 0.9830 - val_loss: 0.0559 - val_accuracy: 0.9854 - val_auc_8: 0.9970 - val_precision_8: 0.9854 - val_recall_8: 0.9854\n",
      "Epoch 20/150\n",
      "epoch_end | time:  14.05.2021 02:29:15\n",
      " — val_aps:  0.065615 — val_a: 0.940047\n",
      "2945/2945 - 400s - loss: 0.0089 - accuracy: 0.9831 - auc_8: 0.9958 - precision_8: 0.9831 - recall_8: 0.9831 - val_loss: 0.1069 - val_accuracy: 0.9681 - val_auc_8: 0.9906 - val_precision_8: 0.9681 - val_recall_8: 0.9681\n",
      "Epoch 21/150\n",
      "epoch_end | time:  14.05.2021 02:35:48\n",
      " — val_aps:  0.065184 — val_a: 0.939378\n",
      "2945/2945 - 393s - loss: 0.0088 - accuracy: 0.9837 - auc_8: 0.9960 - precision_8: 0.9837 - recall_8: 0.9837 - val_loss: 0.0590 - val_accuracy: 0.9848 - val_auc_8: 0.9964 - val_precision_8: 0.9848 - val_recall_8: 0.9848\n",
      "Epoch 22/150\n",
      "epoch_end | time:  14.05.2021 02:42:22\n",
      " — val_aps:  0.065488 — val_a: 0.940105\n",
      "2945/2945 - 394s - loss: 0.0089 - accuracy: 0.9831 - auc_8: 0.9959 - precision_8: 0.9831 - recall_8: 0.9831 - val_loss: 0.0364 - val_accuracy: 0.9918 - val_auc_8: 0.9993 - val_precision_8: 0.9918 - val_recall_8: 0.9918\n",
      "Epoch 23/150\n",
      "epoch_end | time:  14.05.2021 02:49:03\n",
      " — val_aps:  0.057590 — val_a: 0.939361\n",
      "2945/2945 - 401s - loss: 0.0088 - accuracy: 0.9836 - auc_8: 0.9960 - precision_8: 0.9836 - recall_8: 0.9836 - val_loss: 0.0266 - val_accuracy: 0.9959 - val_auc_8: 0.9995 - val_precision_8: 0.9959 - val_recall_8: 0.9959\n",
      "Epoch 24/150\n",
      "epoch_end | time:  14.05.2021 02:55:33\n",
      " — val_aps:  0.068538 — val_a: 0.937844\n",
      "2945/2945 - 389s - loss: 0.0089 - accuracy: 0.9834 - auc_8: 0.9959 - precision_8: 0.9834 - recall_8: 0.9834 - val_loss: 0.0247 - val_accuracy: 0.9956 - val_auc_8: 0.9994 - val_precision_8: 0.9956 - val_recall_8: 0.9956\n",
      "Epoch 25/150\n",
      "epoch_end | time:  14.05.2021 03:02:12\n",
      " — val_aps:  0.063576 — val_a: 0.935439\n",
      "2945/2945 - 400s - loss: 0.0087 - accuracy: 0.9840 - auc_8: 0.9961 - precision_8: 0.9840 - recall_8: 0.9840 - val_loss: 0.0321 - val_accuracy: 0.9926 - val_auc_8: 0.9990 - val_precision_8: 0.9926 - val_recall_8: 0.9926\n",
      "Epoch 26/150\n",
      "epoch_end | time:  14.05.2021 03:08:40\n",
      " — val_aps:  0.054244 — val_a: 0.933573\n",
      "2945/2945 - 385s - loss: 0.0088 - accuracy: 0.9840 - auc_8: 0.9961 - precision_8: 0.9840 - recall_8: 0.9840 - val_loss: 0.2758 - val_accuracy: 0.9229 - val_auc_8: 0.9620 - val_precision_8: 0.9229 - val_recall_8: 0.9229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/150\n",
      "epoch_end | time:  14.05.2021 03:15:01\n",
      " — val_aps:  0.067395 — val_a: 0.935312\n",
      "2945/2945 - 382s - loss: 0.0088 - accuracy: 0.9835 - auc_8: 0.9962 - precision_8: 0.9835 - recall_8: 0.9835 - val_loss: 0.0272 - val_accuracy: 0.9929 - val_auc_8: 0.9994 - val_precision_8: 0.9929 - val_recall_8: 0.9929\n",
      "Epoch 28/150\n",
      "epoch_end | time:  14.05.2021 03:21:42\n",
      " — val_aps:  0.066938 — val_a: 0.934310\n",
      "2945/2945 - 400s - loss: 0.0087 - accuracy: 0.9839 - auc_8: 0.9963 - precision_8: 0.9839 - recall_8: 0.9839 - val_loss: 0.0281 - val_accuracy: 0.9940 - val_auc_8: 0.9994 - val_precision_8: 0.9940 - val_recall_8: 0.9940\n",
      "Epoch 29/150\n",
      "epoch_end | time:  14.05.2021 03:28:09\n",
      " — val_aps:  0.070075 — val_a: 0.937779\n",
      "2945/2945 - 388s - loss: 0.0086 - accuracy: 0.9841 - auc_8: 0.9963 - precision_8: 0.9841 - recall_8: 0.9841 - val_loss: 0.0897 - val_accuracy: 0.9754 - val_auc_8: 0.9951 - val_precision_8: 0.9754 - val_recall_8: 0.9754\n",
      "Epoch 30/150\n",
      "epoch_end | time:  14.05.2021 03:34:49\n",
      " — val_aps:  0.052631 — val_a: 0.935038\n",
      "2945/2945 - 400s - loss: 0.0087 - accuracy: 0.9841 - auc_8: 0.9961 - precision_8: 0.9841 - recall_8: 0.9841 - val_loss: 0.2695 - val_accuracy: 0.9111 - val_auc_8: 0.9654 - val_precision_8: 0.9111 - val_recall_8: 0.9111\n",
      "Epoch 31/150\n",
      "epoch_end | time:  14.05.2021 03:41:23\n",
      " — val_aps:  0.061360 — val_a: 0.938743\n",
      "2945/2945 - 392s - loss: 0.0087 - accuracy: 0.9840 - auc_8: 0.9962 - precision_8: 0.9840 - recall_8: 0.9840 - val_loss: 0.1286 - val_accuracy: 0.9679 - val_auc_8: 0.9859 - val_precision_8: 0.9679 - val_recall_8: 0.9679\n",
      "Epoch 32/150\n",
      "epoch_end | time:  14.05.2021 03:47:56\n",
      " — val_aps:  0.066214 — val_a: 0.937650\n",
      "2945/2945 - 393s - loss: 0.0087 - accuracy: 0.9843 - auc_8: 0.9963 - precision_8: 0.9843 - recall_8: 0.9843 - val_loss: 0.0691 - val_accuracy: 0.9780 - val_auc_8: 0.9966 - val_precision_8: 0.9780 - val_recall_8: 0.9780\n",
      "Epoch 33/150\n",
      "epoch_end | time:  14.05.2021 03:54:33\n",
      " — val_aps:  0.064314 — val_a: 0.937766\n",
      "2945/2945 - 399s - loss: 0.0086 - accuracy: 0.9843 - auc_8: 0.9962 - precision_8: 0.9843 - recall_8: 0.9843 - val_loss: 0.0279 - val_accuracy: 0.9932 - val_auc_8: 0.9992 - val_precision_8: 0.9932 - val_recall_8: 0.9932\n",
      "Epoch 34/150\n",
      "epoch_end | time:  14.05.2021 04:01:11\n",
      " — val_aps:  0.064465 — val_a: 0.934190\n",
      "2945/2945 - 396s - loss: 0.0088 - accuracy: 0.9835 - auc_8: 0.9959 - precision_8: 0.9835 - recall_8: 0.9835 - val_loss: 0.0478 - val_accuracy: 0.9884 - val_auc_8: 0.9973 - val_precision_8: 0.9884 - val_recall_8: 0.9884\n",
      "Epoch 35/150\n",
      "epoch_end | time:  14.05.2021 04:07:49\n",
      " — val_aps:  0.055550 — val_a: 0.937152\n",
      "2945/2945 - 401s - loss: 0.0088 - accuracy: 0.9837 - auc_8: 0.9961 - precision_8: 0.9837 - recall_8: 0.9837 - val_loss: 0.1833 - val_accuracy: 0.9486 - val_auc_8: 0.9763 - val_precision_8: 0.9486 - val_recall_8: 0.9486\n",
      "Epoch 36/150\n",
      "epoch_end | time:  14.05.2021 04:14:18\n",
      " — val_aps:  0.068922 — val_a: 0.936442\n",
      "2945/2945 - 384s - loss: 0.0086 - accuracy: 0.9846 - auc_8: 0.9963 - precision_8: 0.9846 - recall_8: 0.9846 - val_loss: 0.0363 - val_accuracy: 0.9897 - val_auc_8: 0.9990 - val_precision_8: 0.9897 - val_recall_8: 0.9897\n",
      "Epoch 37/150\n",
      "epoch_end | time:  14.05.2021 04:20:45\n",
      " — val_aps:  0.060663 — val_a: 0.938044\n",
      "2945/2945 - 390s - loss: 0.0087 - accuracy: 0.9839 - auc_8: 0.9962 - precision_8: 0.9839 - recall_8: 0.9839 - val_loss: 0.0619 - val_accuracy: 0.9866 - val_auc_8: 0.9968 - val_precision_8: 0.9866 - val_recall_8: 0.9866\n",
      "Epoch 38/150\n",
      "epoch_end | time:  14.05.2021 04:27:31\n",
      " — val_aps:  0.056861 — val_a: 0.932649\n",
      "2945/2945 - 406s - loss: 0.0085 - accuracy: 0.9848 - auc_8: 0.9965 - precision_8: 0.9848 - recall_8: 0.9848 - val_loss: 0.3235 - val_accuracy: 0.9260 - val_auc_8: 0.9505 - val_precision_8: 0.9260 - val_recall_8: 0.9260\n",
      "Epoch 39/150\n",
      "epoch_end | time:  14.05.2021 04:34:07\n",
      " — val_aps:  0.065590 — val_a: 0.938928\n",
      "2945/2945 - 394s - loss: 0.0086 - accuracy: 0.9845 - auc_8: 0.9964 - precision_8: 0.9845 - recall_8: 0.9845 - val_loss: 0.0368 - val_accuracy: 0.9917 - val_auc_8: 0.9988 - val_precision_8: 0.9917 - val_recall_8: 0.9917\n",
      "Epoch 40/150\n",
      "epoch_end | time:  14.05.2021 04:40:40\n",
      " — val_aps:  0.060295 — val_a: 0.935228\n",
      "2945/2945 - 393s - loss: 0.0086 - accuracy: 0.9842 - auc_8: 0.9963 - precision_8: 0.9842 - recall_8: 0.9842 - val_loss: 0.0755 - val_accuracy: 0.9752 - val_auc_8: 0.9956 - val_precision_8: 0.9752 - val_recall_8: 0.9752\n",
      "Epoch 41/150\n",
      "epoch_end | time:  14.05.2021 04:47:16\n",
      " — val_aps:  0.059331 — val_a: 0.936442\n",
      "2945/2945 - 395s - loss: 0.0086 - accuracy: 0.9846 - auc_8: 0.9964 - precision_8: 0.9846 - recall_8: 0.9846 - val_loss: 0.0903 - val_accuracy: 0.9758 - val_auc_8: 0.9922 - val_precision_8: 0.9758 - val_recall_8: 0.9758\n",
      "Epoch 42/150\n",
      "epoch_end | time:  14.05.2021 04:53:56\n",
      " — val_aps:  0.064538 — val_a: 0.932354\n",
      "2945/2945 - 401s - loss: 0.0085 - accuracy: 0.9845 - auc_8: 0.9965 - precision_8: 0.9845 - recall_8: 0.9845 - val_loss: 0.0775 - val_accuracy: 0.9770 - val_auc_8: 0.9959 - val_precision_8: 0.9770 - val_recall_8: 0.9770\n",
      "Epoch 43/150\n",
      "epoch_end | time:  14.05.2021 05:00:38\n",
      " — val_aps:  0.056347 — val_a: 0.934885\n",
      "2945/2945 - 401s - loss: 0.0086 - accuracy: 0.9847 - auc_8: 0.9964 - precision_8: 0.9847 - recall_8: 0.9847 - val_loss: 0.1214 - val_accuracy: 0.9724 - val_auc_8: 0.9897 - val_precision_8: 0.9724 - val_recall_8: 0.9724\n",
      "Epoch 44/150\n",
      "epoch_end | time:  14.05.2021 05:07:11\n",
      " — val_aps:  0.060072 — val_a: 0.934819\n",
      "2945/2945 - 394s - loss: 0.0086 - accuracy: 0.9842 - auc_8: 0.9964 - precision_8: 0.9842 - recall_8: 0.9842 - val_loss: 0.1983 - val_accuracy: 0.9503 - val_auc_8: 0.9733 - val_precision_8: 0.9503 - val_recall_8: 0.9503\n",
      "model_cnn_best_internal_wo_btest_MONEY_False_7_5_60_3_200514_5 valid_for_train:  0.8696379912843524 0.06007152278439476 | test:  0.8572421921904823 0.05376218488683336\n",
      "=====================================================================================================\n",
      "124 (185400, 124) (False, 0.0002, 5, 10, 30, 0.25, 0.0002, 20, 6)\n",
      "train_begin | time:  14.05.2021 05:08:20\n",
      "Epoch 1/150\n",
      "epoch_end | time:  14.05.2021 05:25:03\n",
      " — val_aps:  0.026801 — val_a: 0.878010\n",
      "2945/2945 - 1030s - loss: 0.0167 - accuracy: 0.9740 - auc_9: 0.9936 - precision_9: 0.9740 - recall_9: 0.9740 - val_loss: 0.0991 - val_accuracy: 0.9713 - val_auc_9: 0.9929 - val_precision_9: 0.9713 - val_recall_9: 0.9713\n",
      "Epoch 2/150\n",
      "epoch_end | time:  14.05.2021 05:41:56\n",
      " — val_aps:  0.070128 — val_a: 0.933083\n",
      "2945/2945 - 1016s - loss: 0.0078 - accuracy: 0.9862 - auc_9: 0.9969 - precision_9: 0.9862 - recall_9: 0.9862 - val_loss: 0.0550 - val_accuracy: 0.9843 - val_auc_9: 0.9985 - val_precision_9: 0.9843 - val_recall_9: 0.9843\n",
      "Epoch 3/150\n",
      "epoch_end | time:  14.05.2021 05:59:10\n",
      " — val_aps:  0.059157 — val_a: 0.941769\n",
      "2945/2945 - 1031s - loss: 0.0069 - accuracy: 0.9874 - auc_9: 0.9978 - precision_9: 0.9874 - recall_9: 0.9874 - val_loss: 0.1256 - val_accuracy: 0.9687 - val_auc_9: 0.9892 - val_precision_9: 0.9687 - val_recall_9: 0.9687\n",
      "Epoch 4/150\n",
      "epoch_end | time:  14.05.2021 06:16:12\n",
      " — val_aps:  0.079036 — val_a: 0.935464\n",
      "2945/2945 - 1022s - loss: 0.0065 - accuracy: 0.9881 - auc_9: 0.9981 - precision_9: 0.9881 - recall_9: 0.9881 - val_loss: 0.0273 - val_accuracy: 0.9949 - val_auc_9: 0.9995 - val_precision_9: 0.9949 - val_recall_9: 0.9949\n",
      "Epoch 5/150\n",
      "epoch_end | time:  14.05.2021 06:33:01\n",
      " — val_aps:  0.055524 — val_a: 0.936368\n",
      "2945/2945 - 1010s - loss: 0.0062 - accuracy: 0.9877 - auc_9: 0.9983 - precision_9: 0.9877 - recall_9: 0.9877 - val_loss: 0.0731 - val_accuracy: 0.9725 - val_auc_9: 0.9964 - val_precision_9: 0.9725 - val_recall_9: 0.9725\n",
      "Epoch 6/150\n",
      "epoch_end | time:  14.05.2021 06:49:38\n",
      " — val_aps:  0.055904 — val_a: 0.949131\n",
      "2945/2945 - 996s - loss: 0.0060 - accuracy: 0.9875 - auc_9: 0.9984 - precision_9: 0.9875 - recall_9: 0.9875 - val_loss: 0.0406 - val_accuracy: 0.9911 - val_auc_9: 0.9984 - val_precision_9: 0.9911 - val_recall_9: 0.9911\n",
      "Epoch 7/150\n",
      "epoch_end | time:  14.05.2021 07:06:47\n",
      " — val_aps:  0.074733 — val_a: 0.943266\n",
      "2945/2945 - 1028s - loss: 0.0058 - accuracy: 0.9880 - auc_9: 0.9985 - precision_9: 0.9880 - recall_9: 0.9880 - val_loss: 0.0232 - val_accuracy: 0.9931 - val_auc_9: 0.9993 - val_precision_9: 0.9931 - val_recall_9: 0.9931\n",
      "Epoch 8/150\n",
      "epoch_end | time:  14.05.2021 07:23:49\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " — val_aps:  0.064423 — val_a: 0.948606\n",
      "2945/2945 - 1024s - loss: 0.0057 - accuracy: 0.9880 - auc_9: 0.9986 - precision_9: 0.9880 - recall_9: 0.9880 - val_loss: 0.1454 - val_accuracy: 0.9397 - val_auc_9: 0.9876 - val_precision_9: 0.9397 - val_recall_9: 0.9397\n",
      "Epoch 9/150\n",
      "epoch_end | time:  14.05.2021 07:40:56\n",
      " — val_aps:  0.083948 — val_a: 0.950765\n",
      "2945/2945 - 1025s - loss: 0.0056 - accuracy: 0.9878 - auc_9: 0.9987 - precision_9: 0.9878 - recall_9: 0.9878 - val_loss: 0.0222 - val_accuracy: 0.9948 - val_auc_9: 0.9995 - val_precision_9: 0.9948 - val_recall_9: 0.9948\n",
      "Epoch 10/150\n",
      "epoch_end | time:  14.05.2021 07:57:52\n",
      " — val_aps:  0.026378 — val_a: 0.914183\n",
      "2945/2945 - 1016s - loss: 0.0056 - accuracy: 0.9878 - auc_9: 0.9987 - precision_9: 0.9878 - recall_9: 0.9878 - val_loss: 0.1973 - val_accuracy: 0.9498 - val_auc_9: 0.9810 - val_precision_9: 0.9498 - val_recall_9: 0.9498\n",
      "Epoch 11/150\n",
      "epoch_end | time:  14.05.2021 08:15:12\n",
      " — val_aps:  0.085860 — val_a: 0.953531\n",
      "2945/2945 - 1040s - loss: 0.0055 - accuracy: 0.9881 - auc_9: 0.9987 - precision_9: 0.9881 - recall_9: 0.9881 - val_loss: 0.0332 - val_accuracy: 0.9891 - val_auc_9: 0.9994 - val_precision_9: 0.9891 - val_recall_9: 0.9891\n",
      "Epoch 12/150\n",
      "epoch_end | time:  14.05.2021 08:31:59\n",
      " — val_aps:  0.065039 — val_a: 0.947183\n",
      "2945/2945 - 1006s - loss: 0.0054 - accuracy: 0.9881 - auc_9: 0.9988 - precision_9: 0.9881 - recall_9: 0.9881 - val_loss: 0.0319 - val_accuracy: 0.9948 - val_auc_9: 0.9993 - val_precision_9: 0.9948 - val_recall_9: 0.9948\n",
      "Epoch 13/150\n",
      "epoch_end | time:  14.05.2021 08:48:54\n",
      " — val_aps:  0.062655 — val_a: 0.945539\n",
      "2945/2945 - 1016s - loss: 0.0054 - accuracy: 0.9877 - auc_9: 0.9988 - precision_9: 0.9877 - recall_9: 0.9877 - val_loss: 0.0505 - val_accuracy: 0.9891 - val_auc_9: 0.9987 - val_precision_9: 0.9891 - val_recall_9: 0.9891\n",
      "Epoch 14/150\n",
      "epoch_end | time:  14.05.2021 09:05:39\n",
      " — val_aps:  0.080190 — val_a: 0.937500\n",
      "2945/2945 - 1003s - loss: 0.0053 - accuracy: 0.9879 - auc_9: 0.9988 - precision_9: 0.9879 - recall_9: 0.9879 - val_loss: 0.0212 - val_accuracy: 0.9953 - val_auc_9: 0.9993 - val_precision_9: 0.9953 - val_recall_9: 0.9953\n",
      "Epoch 15/150\n",
      "epoch_end | time:  14.05.2021 09:22:46\n",
      " — val_aps:  0.035905 — val_a: 0.908823\n",
      "2945/2945 - 1028s - loss: 0.0052 - accuracy: 0.9881 - auc_9: 0.9988 - precision_9: 0.9881 - recall_9: 0.9881 - val_loss: 0.0470 - val_accuracy: 0.9855 - val_auc_9: 0.9984 - val_precision_9: 0.9855 - val_recall_9: 0.9855\n",
      "Epoch 16/150\n",
      "epoch_end | time:  14.05.2021 09:39:45\n",
      " — val_aps:  0.067267 — val_a: 0.943435\n",
      "2945/2945 - 1021s - loss: 0.0052 - accuracy: 0.9882 - auc_9: 0.9988 - precision_9: 0.9882 - recall_9: 0.9882 - val_loss: 0.0188 - val_accuracy: 0.9957 - val_auc_9: 0.9991 - val_precision_9: 0.9957 - val_recall_9: 0.9957\n",
      "Epoch 17/150\n",
      "epoch_end | time:  14.05.2021 09:56:40\n",
      " — val_aps:  0.073704 — val_a: 0.942704\n",
      "2945/2945 - 1007s - loss: 0.0052 - accuracy: 0.9881 - auc_9: 0.9989 - precision_9: 0.9881 - recall_9: 0.9881 - val_loss: 0.0386 - val_accuracy: 0.9917 - val_auc_9: 0.9991 - val_precision_9: 0.9917 - val_recall_9: 0.9917\n",
      "Epoch 18/150\n",
      "epoch_end | time:  14.05.2021 10:12:02\n",
      " — val_aps:  0.081946 — val_a: 0.934683\n",
      "2945/2945 - 921s - loss: 0.0051 - accuracy: 0.9880 - auc_9: 0.9989 - precision_9: 0.9880 - recall_9: 0.9880 - val_loss: 0.0264 - val_accuracy: 0.9940 - val_auc_9: 0.9994 - val_precision_9: 0.9940 - val_recall_9: 0.9940\n",
      "Epoch 19/150\n",
      "epoch_end | time:  14.05.2021 10:29:54\n",
      " — val_aps:  0.064732 — val_a: 0.942911\n",
      "2945/2945 - 1078s - loss: 0.0051 - accuracy: 0.9879 - auc_9: 0.9989 - precision_9: 0.9879 - recall_9: 0.9879 - val_loss: 0.0235 - val_accuracy: 0.9949 - val_auc_9: 0.9995 - val_precision_9: 0.9949 - val_recall_9: 0.9949\n",
      "Epoch 20/150\n",
      "epoch_end | time:  14.05.2021 10:49:02\n",
      " — val_aps:  0.045339 — val_a: 0.931575\n",
      "2945/2945 - 1156s - loss: 0.0051 - accuracy: 0.9883 - auc_9: 0.9989 - precision_9: 0.9883 - recall_9: 0.9883 - val_loss: 0.0318 - val_accuracy: 0.9914 - val_auc_9: 0.9989 - val_precision_9: 0.9914 - val_recall_9: 0.9914\n",
      "Epoch 21/150\n",
      "epoch_end | time:  14.05.2021 11:06:53\n",
      " — val_aps:  0.060770 — val_a: 0.937821\n",
      "2945/2945 - 1060s - loss: 0.0050 - accuracy: 0.9880 - auc_9: 0.9989 - precision_9: 0.9880 - recall_9: 0.9880 - val_loss: 0.0304 - val_accuracy: 0.9909 - val_auc_9: 0.9989 - val_precision_9: 0.9909 - val_recall_9: 0.9909\n",
      "Epoch 22/150\n",
      "epoch_end | time:  14.05.2021 11:24:16\n",
      " — val_aps:  0.062952 — val_a: 0.936873\n",
      "2945/2945 - 1043s - loss: 0.0050 - accuracy: 0.9881 - auc_9: 0.9990 - precision_9: 0.9881 - recall_9: 0.9881 - val_loss: 0.0369 - val_accuracy: 0.9875 - val_auc_9: 0.9990 - val_precision_9: 0.9875 - val_recall_9: 0.9875\n",
      "Epoch 23/150\n",
      "epoch_end | time:  14.05.2021 11:42:41\n",
      " — val_aps:  0.071729 — val_a: 0.941625\n",
      "2945/2945 - 1112s - loss: 0.0050 - accuracy: 0.9880 - auc_9: 0.9989 - precision_9: 0.9880 - recall_9: 0.9880 - val_loss: 0.0233 - val_accuracy: 0.9933 - val_auc_9: 0.9989 - val_precision_9: 0.9933 - val_recall_9: 0.9933\n",
      "Epoch 24/150\n",
      "epoch_end | time:  14.05.2021 11:59:41\n",
      " — val_aps:  0.035342 — val_a: 0.921528\n",
      "2945/2945 - 1005s - loss: 0.0049 - accuracy: 0.9883 - auc_9: 0.9989 - precision_9: 0.9883 - recall_9: 0.9883 - val_loss: 0.1043 - val_accuracy: 0.9673 - val_auc_9: 0.9925 - val_precision_9: 0.9673 - val_recall_9: 0.9673\n",
      "Epoch 25/150\n",
      "epoch_end | time:  14.05.2021 12:16:46\n",
      " — val_aps:  0.063372 — val_a: 0.933033\n",
      "2945/2945 - 1024s - loss: 0.0050 - accuracy: 0.9883 - auc_9: 0.9989 - precision_9: 0.9883 - recall_9: 0.9883 - val_loss: 0.0488 - val_accuracy: 0.9859 - val_auc_9: 0.9986 - val_precision_9: 0.9859 - val_recall_9: 0.9859\n",
      "Epoch 26/150\n",
      "epoch_end | time:  14.05.2021 12:36:02\n",
      " — val_aps:  0.049378 — val_a: 0.915342\n",
      "2945/2945 - 1157s - loss: 0.0049 - accuracy: 0.9882 - auc_9: 0.9990 - precision_9: 0.9882 - recall_9: 0.9882 - val_loss: 0.0275 - val_accuracy: 0.9917 - val_auc_9: 0.9990 - val_precision_9: 0.9917 - val_recall_9: 0.9917\n",
      "Epoch 27/150\n",
      "epoch_end | time:  14.05.2021 12:55:27\n",
      " — val_aps:  0.096746 — val_a: 0.943257\n",
      "2945/2945 - 1168s - loss: 0.0048 - accuracy: 0.9883 - auc_9: 0.9990 - precision_9: 0.9883 - recall_9: 0.9883 - val_loss: 0.0203 - val_accuracy: 0.9963 - val_auc_9: 0.9995 - val_precision_9: 0.9963 - val_recall_9: 0.9963\n",
      "Epoch 28/150\n",
      "epoch_end | time:  14.05.2021 13:12:24\n",
      " — val_aps:  0.076581 — val_a: 0.938307\n",
      "2945/2945 - 1016s - loss: 0.0048 - accuracy: 0.9883 - auc_9: 0.9990 - precision_9: 0.9883 - recall_9: 0.9883 - val_loss: 0.0252 - val_accuracy: 0.9918 - val_auc_9: 0.9993 - val_precision_9: 0.9918 - val_recall_9: 0.9918\n",
      "Epoch 29/150\n",
      "epoch_end | time:  14.05.2021 13:29:33\n",
      " — val_aps:  0.050466 — val_a: 0.929497\n",
      "2945/2945 - 1029s - loss: 0.0048 - accuracy: 0.9883 - auc_9: 0.9990 - precision_9: 0.9883 - recall_9: 0.9883 - val_loss: 0.0901 - val_accuracy: 0.9693 - val_auc_9: 0.9938 - val_precision_9: 0.9693 - val_recall_9: 0.9693\n",
      "Epoch 30/150\n",
      "epoch_end | time:  14.05.2021 13:46:52\n",
      " — val_aps:  0.081066 — val_a: 0.937995\n",
      "2945/2945 - 1039s - loss: 0.0048 - accuracy: 0.9885 - auc_9: 0.9989 - precision_9: 0.9885 - recall_9: 0.9885 - val_loss: 0.0309 - val_accuracy: 0.9903 - val_auc_9: 0.9992 - val_precision_9: 0.9903 - val_recall_9: 0.9903\n",
      "Epoch 31/150\n",
      "epoch_end | time:  14.05.2021 14:08:35\n",
      " — val_aps:  0.073757 — val_a: 0.933010\n",
      "2945/2945 - 1335s - loss: 0.0048 - accuracy: 0.9885 - auc_9: 0.9990 - precision_9: 0.9885 - recall_9: 0.9885 - val_loss: 0.0263 - val_accuracy: 0.9931 - val_auc_9: 0.9992 - val_precision_9: 0.9931 - val_recall_9: 0.9931\n",
      "Epoch 32/150\n",
      "epoch_end | time:  14.05.2021 14:29:28\n",
      " — val_aps:  0.064664 — val_a: 0.920739\n",
      "2945/2945 - 1223s - loss: 0.0047 - accuracy: 0.9888 - auc_9: 0.9990 - precision_9: 0.9888 - recall_9: 0.9888 - val_loss: 0.0325 - val_accuracy: 0.9902 - val_auc_9: 0.9990 - val_precision_9: 0.9902 - val_recall_9: 0.9902\n",
      "Epoch 33/150\n",
      "epoch_end | time:  14.05.2021 14:47:36\n",
      " — val_aps:  0.042318 — val_a: 0.930384\n",
      "2945/2945 - 1089s - loss: 0.0047 - accuracy: 0.9889 - auc_9: 0.9990 - precision_9: 0.9889 - recall_9: 0.9889 - val_loss: 0.1097 - val_accuracy: 0.9703 - val_auc_9: 0.9918 - val_precision_9: 0.9703 - val_recall_9: 0.9703\n",
      "Epoch 34/150\n",
      "epoch_end | time:  14.05.2021 15:06:09\n",
      " — val_aps:  0.061734 — val_a: 0.930384\n",
      "2945/2945 - 1111s - loss: 0.0047 - accuracy: 0.9884 - auc_9: 0.9990 - precision_9: 0.9884 - recall_9: 0.9884 - val_loss: 0.0224 - val_accuracy: 0.9959 - val_auc_9: 0.9993 - val_precision_9: 0.9959 - val_recall_9: 0.9959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/150\n",
      "epoch_end | time:  14.05.2021 15:30:01\n",
      " — val_aps:  0.054799 — val_a: 0.930489\n",
      "2945/2945 - 1484s - loss: 0.0047 - accuracy: 0.9887 - auc_9: 0.9990 - precision_9: 0.9887 - recall_9: 0.9887 - val_loss: 0.0220 - val_accuracy: 0.9952 - val_auc_9: 0.9986 - val_precision_9: 0.9952 - val_recall_9: 0.9952\n",
      "Epoch 36/150\n",
      "epoch_end | time:  14.05.2021 15:55:40\n",
      " — val_aps:  0.060814 — val_a: 0.917873\n",
      "2945/2945 - 1546s - loss: 0.0046 - accuracy: 0.9884 - auc_9: 0.9990 - precision_9: 0.9884 - recall_9: 0.9884 - val_loss: 0.0390 - val_accuracy: 0.9897 - val_auc_9: 0.9988 - val_precision_9: 0.9897 - val_recall_9: 0.9897\n",
      "model_cnn_best_internal_wo_btest_MONEY_False_5_10_30_6_200514_15 valid_for_train:  0.8357454560424373 0.06081387852977906 | test:  0.853276910029289 0.0678130944005578\n",
      "=====================================================================================================\n",
      "124 (185400, 124) (False, 0.0002, 5, 15, 60, 0.25, 0.0002, 20, 8)\n",
      "train_begin | time:  14.05.2021 15:59:57\n",
      "Epoch 1/150\n",
      "epoch_end | time:  14.05.2021 16:56:04\n",
      " — val_aps:  0.068362 — val_a: 0.937372\n",
      "2945/2945 - 3479s - loss: 0.0206 - accuracy: 0.9726 - auc_10: 0.9936 - precision_10: 0.9726 - recall_10: 0.9726 - val_loss: 0.0220 - val_accuracy: 0.9961 - val_auc_10: 0.9994 - val_precision_10: 0.9961 - val_recall_10: 0.9961\n",
      "Epoch 2/150\n",
      "epoch_end | time:  14.05.2021 17:51:23\n",
      " — val_aps:  0.062059 — val_a: 0.938411\n",
      "2945/2945 - 3274s - loss: 0.0074 - accuracy: 0.9863 - auc_10: 0.9973 - precision_10: 0.9863 - recall_10: 0.9863 - val_loss: 0.0485 - val_accuracy: 0.9894 - val_auc_10: 0.9990 - val_precision_10: 0.9894 - val_recall_10: 0.9894\n",
      "Epoch 3/150\n",
      "epoch_end | time:  14.05.2021 18:44:01\n",
      " — val_aps:  0.054285 — val_a: 0.943183\n",
      "2945/2945 - 3153s - loss: 0.0067 - accuracy: 0.9871 - auc_10: 0.9979 - precision_10: 0.9871 - recall_10: 0.9871 - val_loss: 0.1894 - val_accuracy: 0.9452 - val_auc_10: 0.9750 - val_precision_10: 0.9452 - val_recall_10: 0.9452\n",
      "Epoch 4/150\n",
      "epoch_end | time:  14.05.2021 19:33:29\n",
      " — val_aps:  0.060367 — val_a: 0.948458\n",
      "2945/2945 - 2965s - loss: 0.0062 - accuracy: 0.9878 - auc_10: 0.9984 - precision_10: 0.9878 - recall_10: 0.9878 - val_loss: 0.0227 - val_accuracy: 0.9944 - val_auc_10: 0.9992 - val_precision_10: 0.9944 - val_recall_10: 0.9944\n",
      "Epoch 5/150\n",
      "epoch_end | time:  14.05.2021 20:23:05\n",
      " — val_aps:  0.062231 — val_a: 0.947829\n",
      "2945/2945 - 2980s - loss: 0.0060 - accuracy: 0.9875 - auc_10: 0.9985 - precision_10: 0.9875 - recall_10: 0.9875 - val_loss: 0.0571 - val_accuracy: 0.9844 - val_auc_10: 0.9971 - val_precision_10: 0.9844 - val_recall_10: 0.9844\n",
      "Epoch 6/150\n",
      "epoch_end | time:  14.05.2021 21:12:43\n",
      " — val_aps:  0.071258 — val_a: 0.942926\n",
      "2945/2945 - 2973s - loss: 0.0059 - accuracy: 0.9879 - auc_10: 0.9986 - precision_10: 0.9879 - recall_10: 0.9879 - val_loss: 0.0357 - val_accuracy: 0.9919 - val_auc_10: 0.9992 - val_precision_10: 0.9919 - val_recall_10: 0.9919\n",
      "Epoch 7/150\n",
      "epoch_end | time:  14.05.2021 22:01:39\n",
      " — val_aps:  0.049667 — val_a: 0.936562\n",
      "2945/2945 - 2933s - loss: 0.0057 - accuracy: 0.9880 - auc_10: 0.9986 - precision_10: 0.9880 - recall_10: 0.9880 - val_loss: 0.0680 - val_accuracy: 0.9822 - val_auc_10: 0.9961 - val_precision_10: 0.9822 - val_recall_10: 0.9822\n",
      "Epoch 8/150\n",
      "epoch_end | time:  14.05.2021 22:50:55\n",
      " — val_aps:  0.080383 — val_a: 0.941701\n",
      "2945/2945 - 2957s - loss: 0.0056 - accuracy: 0.9884 - auc_10: 0.9987 - precision_10: 0.9884 - recall_10: 0.9884 - val_loss: 0.0280 - val_accuracy: 0.9914 - val_auc_10: 0.9993 - val_precision_10: 0.9914 - val_recall_10: 0.9914\n",
      "Epoch 9/150\n",
      "epoch_end | time:  14.05.2021 23:39:09\n",
      " — val_aps:  0.085822 — val_a: 0.946860\n",
      "2945/2945 - 2890s - loss: 0.0054 - accuracy: 0.9888 - auc_10: 0.9988 - precision_10: 0.9888 - recall_10: 0.9888 - val_loss: 0.0709 - val_accuracy: 0.9635 - val_auc_10: 0.9969 - val_precision_10: 0.9635 - val_recall_10: 0.9635\n",
      "Epoch 10/150\n",
      "epoch_end | time:  15.05.2021 00:22:39\n",
      " — val_aps:  0.067831 — val_a: 0.931567\n",
      "2945/2945 - 2610s - loss: 0.0053 - accuracy: 0.9885 - auc_10: 0.9988 - precision_10: 0.9885 - recall_10: 0.9885 - val_loss: 0.1212 - val_accuracy: 0.9579 - val_auc_10: 0.9937 - val_precision_10: 0.9579 - val_recall_10: 0.9579\n",
      "Epoch 11/150\n",
      "epoch_end | time:  15.05.2021 01:06:42\n",
      " — val_aps:  0.068829 — val_a: 0.941968\n",
      "2945/2945 - 2642s - loss: 0.0052 - accuracy: 0.9886 - auc_10: 0.9988 - precision_10: 0.9886 - recall_10: 0.9886 - val_loss: 0.0672 - val_accuracy: 0.9765 - val_auc_10: 0.9972 - val_precision_10: 0.9765 - val_recall_10: 0.9765\n",
      "Epoch 12/150\n",
      "epoch_end | time:  15.05.2021 01:50:33\n",
      " — val_aps:  0.054715 — val_a: 0.931693\n",
      "2945/2945 - 2626s - loss: 0.0052 - accuracy: 0.9887 - auc_10: 0.9989 - precision_10: 0.9887 - recall_10: 0.9887 - val_loss: 0.0491 - val_accuracy: 0.9867 - val_auc_10: 0.9988 - val_precision_10: 0.9867 - val_recall_10: 0.9867\n",
      "Epoch 13/150\n",
      "epoch_end | time:  15.05.2021 02:33:45\n",
      " — val_aps:  0.046500 — val_a: 0.923952\n",
      "2945/2945 - 2590s - loss: 0.0051 - accuracy: 0.9890 - auc_10: 0.9989 - precision_10: 0.9890 - recall_10: 0.9890 - val_loss: 0.0474 - val_accuracy: 0.9867 - val_auc_10: 0.9973 - val_precision_10: 0.9867 - val_recall_10: 0.9867\n",
      "Epoch 14/150\n",
      "epoch_end | time:  15.05.2021 03:15:53\n",
      " — val_aps:  0.072781 — val_a: 0.936920\n",
      "2945/2945 - 2528s - loss: 0.0050 - accuracy: 0.9891 - auc_10: 0.9989 - precision_10: 0.9891 - recall_10: 0.9891 - val_loss: 0.0335 - val_accuracy: 0.9917 - val_auc_10: 0.9992 - val_precision_10: 0.9917 - val_recall_10: 0.9917\n",
      "Epoch 15/150\n",
      "epoch_end | time:  15.05.2021 03:58:17\n",
      " — val_aps:  0.066619 — val_a: 0.932964\n",
      "2945/2945 - 2547s - loss: 0.0049 - accuracy: 0.9891 - auc_10: 0.9990 - precision_10: 0.9891 - recall_10: 0.9891 - val_loss: 0.0240 - val_accuracy: 0.9939 - val_auc_10: 0.9988 - val_precision_10: 0.9939 - val_recall_10: 0.9939\n",
      "Epoch 16/150\n",
      "epoch_end | time:  15.05.2021 04:40:54\n",
      " — val_aps:  0.024552 — val_a: 0.872783\n",
      "2945/2945 - 2563s - loss: 0.0049 - accuracy: 0.9893 - auc_10: 0.9990 - precision_10: 0.9893 - recall_10: 0.9893 - val_loss: 0.7210 - val_accuracy: 0.7798 - val_auc_10: 0.8688 - val_precision_10: 0.7798 - val_recall_10: 0.7798\n",
      "Epoch 17/150\n",
      "epoch_end | time:  15.05.2021 05:23:36\n",
      " — val_aps:  0.056414 — val_a: 0.928262\n",
      "2945/2945 - 2552s - loss: 0.0049 - accuracy: 0.9895 - auc_10: 0.9990 - precision_10: 0.9895 - recall_10: 0.9895 - val_loss: 0.0193 - val_accuracy: 0.9958 - val_auc_10: 0.9988 - val_precision_10: 0.9958 - val_recall_10: 0.9958\n",
      "Epoch 18/150\n",
      "epoch_end | time:  15.05.2021 06:06:00\n",
      " — val_aps:  0.045173 — val_a: 0.933652\n",
      "2945/2945 - 2544s - loss: 0.0048 - accuracy: 0.9891 - auc_10: 0.9990 - precision_10: 0.9891 - recall_10: 0.9891 - val_loss: 0.0560 - val_accuracy: 0.9831 - val_auc_10: 0.9979 - val_precision_10: 0.9831 - val_recall_10: 0.9831\n",
      "Epoch 19/150\n",
      "epoch_end | time:  15.05.2021 06:48:19\n",
      " — val_aps:  0.069752 — val_a: 0.919038\n",
      "2945/2945 - 2536s - loss: 0.0047 - accuracy: 0.9894 - auc_10: 0.9990 - precision_10: 0.9894 - recall_10: 0.9894 - val_loss: 0.0207 - val_accuracy: 0.9948 - val_auc_10: 0.9990 - val_precision_10: 0.9948 - val_recall_10: 0.9948\n",
      "Epoch 20/150\n",
      "epoch_end | time:  15.05.2021 07:30:17\n",
      " — val_aps:  0.045621 — val_a: 0.919747\n",
      "2945/2945 - 2512s - loss: 0.0047 - accuracy: 0.9895 - auc_10: 0.9990 - precision_10: 0.9895 - recall_10: 0.9895 - val_loss: 0.0571 - val_accuracy: 0.9814 - val_auc_10: 0.9970 - val_precision_10: 0.9814 - val_recall_10: 0.9814\n",
      "Epoch 21/150\n",
      "epoch_end | time:  15.05.2021 08:12:35\n",
      " — val_aps:  0.061675 — val_a: 0.930943\n",
      "2945/2945 - 2542s - loss: 0.0047 - accuracy: 0.9893 - auc_10: 0.9990 - precision_10: 0.9893 - recall_10: 0.9893 - val_loss: 0.0292 - val_accuracy: 0.9932 - val_auc_10: 0.9993 - val_precision_10: 0.9932 - val_recall_10: 0.9932\n",
      "Epoch 22/150\n",
      "epoch_end | time:  15.05.2021 08:54:30\n",
      " — val_aps:  0.051102 — val_a: 0.926127\n",
      "2945/2945 - 2513s - loss: 0.0046 - accuracy: 0.9892 - auc_10: 0.9990 - precision_10: 0.9892 - recall_10: 0.9892 - val_loss: 0.0305 - val_accuracy: 0.9925 - val_auc_10: 0.9991 - val_precision_10: 0.9925 - val_recall_10: 0.9925\n",
      "Epoch 23/150\n",
      "epoch_end | time:  15.05.2021 09:36:11\n",
      " — val_aps:  0.061819 — val_a: 0.932808\n",
      "2945/2945 - 2502s - loss: 0.0046 - accuracy: 0.9898 - auc_10: 0.9990 - precision_10: 0.9898 - recall_10: 0.9898 - val_loss: 0.0437 - val_accuracy: 0.9846 - val_auc_10: 0.9987 - val_precision_10: 0.9846 - val_recall_10: 0.9846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/150\n",
      "epoch_end | time:  15.05.2021 10:15:50\n",
      " — val_aps:  0.051218 — val_a: 0.906138\n",
      "2945/2945 - 2350s - loss: 0.0045 - accuracy: 0.9897 - auc_10: 0.9991 - precision_10: 0.9897 - recall_10: 0.9897 - val_loss: 0.0225 - val_accuracy: 0.9953 - val_auc_10: 0.9985 - val_precision_10: 0.9953 - val_recall_10: 0.9953\n",
      "Epoch 25/150\n",
      "epoch_end | time:  15.05.2021 10:48:09\n",
      " — val_aps:  0.066014 — val_a: 0.937481\n",
      "2945/2945 - 1940s - loss: 0.0045 - accuracy: 0.9895 - auc_10: 0.9991 - precision_10: 0.9895 - recall_10: 0.9895 - val_loss: 0.0234 - val_accuracy: 0.9937 - val_auc_10: 0.9993 - val_precision_10: 0.9937 - val_recall_10: 0.9937\n",
      "Epoch 26/150\n",
      "epoch_end | time:  15.05.2021 11:19:32\n",
      " — val_aps:  0.043861 — val_a: 0.914250\n",
      "2945/2945 - 1881s - loss: 0.0045 - accuracy: 0.9898 - auc_10: 0.9991 - precision_10: 0.9898 - recall_10: 0.9898 - val_loss: 0.0454 - val_accuracy: 0.9880 - val_auc_10: 0.9982 - val_precision_10: 0.9880 - val_recall_10: 0.9880\n",
      "Epoch 27/150\n",
      "epoch_end | time:  15.05.2021 11:50:52\n",
      " — val_aps:  0.072072 — val_a: 0.931135\n",
      "2945/2945 - 1877s - loss: 0.0045 - accuracy: 0.9897 - auc_10: 0.9991 - precision_10: 0.9897 - recall_10: 0.9897 - val_loss: 0.0876 - val_accuracy: 0.9696 - val_auc_10: 0.9949 - val_precision_10: 0.9696 - val_recall_10: 0.9696\n",
      "Epoch 28/150\n",
      "epoch_end | time:  15.05.2021 12:22:01\n",
      " — val_aps:  0.065494 — val_a: 0.919345\n",
      "2945/2945 - 1869s - loss: 0.0044 - accuracy: 0.9899 - auc_10: 0.9991 - precision_10: 0.9899 - recall_10: 0.9899 - val_loss: 0.0205 - val_accuracy: 0.9967 - val_auc_10: 0.9991 - val_precision_10: 0.9967 - val_recall_10: 0.9967\n",
      "Epoch 29/150\n",
      "epoch_end | time:  15.05.2021 12:53:04\n",
      " — val_aps:  0.051658 — val_a: 0.936415\n",
      "2945/2945 - 1861s - loss: 0.0044 - accuracy: 0.9900 - auc_10: 0.9991 - precision_10: 0.9900 - recall_10: 0.9900 - val_loss: 0.0497 - val_accuracy: 0.9826 - val_auc_10: 0.9981 - val_precision_10: 0.9826 - val_recall_10: 0.9826\n",
      "Epoch 30/150\n",
      "epoch_end | time:  15.05.2021 13:23:58\n",
      " — val_aps:  0.048001 — val_a: 0.926406\n",
      "2945/2945 - 1853s - loss: 0.0044 - accuracy: 0.9897 - auc_10: 0.9991 - precision_10: 0.9897 - recall_10: 0.9897 - val_loss: 0.1064 - val_accuracy: 0.9653 - val_auc_10: 0.9927 - val_precision_10: 0.9653 - val_recall_10: 0.9653\n",
      "Epoch 31/150\n",
      "epoch_end | time:  15.05.2021 13:55:02\n",
      " — val_aps:  0.082495 — val_a: 0.930003\n",
      "2945/2945 - 1863s - loss: 0.0044 - accuracy: 0.9900 - auc_10: 0.9992 - precision_10: 0.9900 - recall_10: 0.9900 - val_loss: 0.0217 - val_accuracy: 0.9958 - val_auc_10: 0.9984 - val_precision_10: 0.9958 - val_recall_10: 0.9958\n",
      "Epoch 32/150\n",
      "epoch_end | time:  15.05.2021 14:26:15\n",
      " — val_aps:  0.054208 — val_a: 0.928069\n",
      "2945/2945 - 1873s - loss: 0.0043 - accuracy: 0.9901 - auc_10: 0.9991 - precision_10: 0.9901 - recall_10: 0.9901 - val_loss: 0.0225 - val_accuracy: 0.9952 - val_auc_10: 0.9989 - val_precision_10: 0.9952 - val_recall_10: 0.9952\n",
      "Epoch 33/150\n",
      "epoch_end | time:  15.05.2021 14:56:55\n",
      " — val_aps:  0.046214 — val_a: 0.922625\n",
      "2945/2945 - 1840s - loss: 0.0044 - accuracy: 0.9897 - auc_10: 0.9991 - precision_10: 0.9897 - recall_10: 0.9897 - val_loss: 0.0205 - val_accuracy: 0.9963 - val_auc_10: 0.9991 - val_precision_10: 0.9963 - val_recall_10: 0.9963\n",
      "Epoch 34/150\n",
      "epoch_end | time:  15.05.2021 15:28:11\n",
      " — val_aps:  0.046560 — val_a: 0.879057\n",
      "2945/2945 - 1875s - loss: 0.0043 - accuracy: 0.9900 - auc_10: 0.9991 - precision_10: 0.9900 - recall_10: 0.9900 - val_loss: 0.0200 - val_accuracy: 0.9964 - val_auc_10: 0.9984 - val_precision_10: 0.9964 - val_recall_10: 0.9964\n",
      "Epoch 35/150\n",
      "epoch_end | time:  15.05.2021 15:59:25\n",
      " — val_aps:  0.072733 — val_a: 0.917018\n",
      "2945/2945 - 1874s - loss: 0.0042 - accuracy: 0.9903 - auc_10: 0.9992 - precision_10: 0.9903 - recall_10: 0.9903 - val_loss: 0.0237 - val_accuracy: 0.9938 - val_auc_10: 0.9985 - val_precision_10: 0.9938 - val_recall_10: 0.9938\n",
      "Epoch 36/150\n",
      "epoch_end | time:  15.05.2021 16:30:25\n",
      " — val_aps:  0.060629 — val_a: 0.925458\n",
      "2945/2945 - 1858s - loss: 0.0042 - accuracy: 0.9903 - auc_10: 0.9992 - precision_10: 0.9903 - recall_10: 0.9903 - val_loss: 0.0490 - val_accuracy: 0.9876 - val_auc_10: 0.9989 - val_precision_10: 0.9876 - val_recall_10: 0.9876\n",
      "Epoch 37/150\n",
      "epoch_end | time:  15.05.2021 17:01:18\n",
      " — val_aps:  0.037817 — val_a: 0.906626\n",
      "2945/2945 - 1852s - loss: 0.0042 - accuracy: 0.9907 - auc_10: 0.9992 - precision_10: 0.9907 - recall_10: 0.9907 - val_loss: 0.3904 - val_accuracy: 0.8693 - val_auc_10: 0.9458 - val_precision_10: 0.8693 - val_recall_10: 0.8693\n",
      "model_cnn_best_internal_wo_btest_MONEY_False_5_15_60_8_200515_17 valid_for_train:  0.81325202806415 0.037816903826610536 | test:  0.8108678715791289 0.04132781084284788\n",
      "=====================================================================================================\n",
      "124 (185400, 124) (False, 0.0001, 7, 15, 60, 0.25, 0.0002, 20, 3)\n",
      "train_begin | time:  15.05.2021 17:03:16\n",
      "Epoch 1/150\n",
      "epoch_end | time:  15.05.2021 17:15:45\n",
      " — val_aps:  0.053057 — val_a: 0.924782\n",
      "2945/2945 - 763s - loss: 0.0156 - accuracy: 0.9681 - auc_11: 0.9924 - precision_11: 0.9681 - recall_11: 0.9681 - val_loss: 0.0240 - val_accuracy: 0.9951 - val_auc_11: 0.9988 - val_precision_11: 0.9951 - val_recall_11: 0.9951\n",
      "Epoch 2/150\n",
      "epoch_end | time:  15.05.2021 17:28:30\n",
      " — val_aps:  0.070046 — val_a: 0.947300\n",
      "2945/2945 - 764s - loss: 0.0093 - accuracy: 0.9818 - auc_11: 0.9960 - precision_11: 0.9818 - recall_11: 0.9818 - val_loss: 0.1355 - val_accuracy: 0.9675 - val_auc_11: 0.9873 - val_precision_11: 0.9675 - val_recall_11: 0.9675\n",
      "Epoch 3/150\n",
      "epoch_end | time:  15.05.2021 17:41:03\n",
      " — val_aps:  0.056595 — val_a: 0.942044\n",
      "2945/2945 - 753s - loss: 0.0084 - accuracy: 0.9824 - auc_11: 0.9966 - precision_11: 0.9824 - recall_11: 0.9824 - val_loss: 0.3437 - val_accuracy: 0.8942 - val_auc_11: 0.9342 - val_precision_11: 0.8942 - val_recall_11: 0.8942\n",
      "Epoch 4/150\n",
      "epoch_end | time:  15.05.2021 17:53:45\n",
      " — val_aps:  0.074336 — val_a: 0.936411\n",
      "2945/2945 - 762s - loss: 0.0078 - accuracy: 0.9840 - auc_11: 0.9972 - precision_11: 0.9840 - recall_11: 0.9840 - val_loss: 0.2449 - val_accuracy: 0.9317 - val_auc_11: 0.9654 - val_precision_11: 0.9317 - val_recall_11: 0.9317\n",
      "Epoch 5/150\n",
      "epoch_end | time:  15.05.2021 18:06:24\n",
      " — val_aps:  0.075710 — val_a: 0.950464\n",
      "2945/2945 - 758s - loss: 0.0074 - accuracy: 0.9845 - auc_11: 0.9974 - precision_11: 0.9845 - recall_11: 0.9845 - val_loss: 0.0322 - val_accuracy: 0.9925 - val_auc_11: 0.9992 - val_precision_11: 0.9925 - val_recall_11: 0.9925\n",
      "Epoch 6/150\n",
      "epoch_end | time:  15.05.2021 18:19:07\n",
      " — val_aps:  0.071259 — val_a: 0.949960\n",
      "2945/2945 - 763s - loss: 0.0072 - accuracy: 0.9850 - auc_11: 0.9978 - precision_11: 0.9850 - recall_11: 0.9850 - val_loss: 0.0390 - val_accuracy: 0.9879 - val_auc_11: 0.9987 - val_precision_11: 0.9879 - val_recall_11: 0.9879\n",
      "Epoch 7/150\n",
      "epoch_end | time:  15.05.2021 18:31:50\n",
      " — val_aps:  0.063973 — val_a: 0.951016\n",
      "2945/2945 - 763s - loss: 0.0071 - accuracy: 0.9852 - auc_11: 0.9977 - precision_11: 0.9852 - recall_11: 0.9852 - val_loss: 0.0706 - val_accuracy: 0.9804 - val_auc_11: 0.9966 - val_precision_11: 0.9804 - val_recall_11: 0.9804\n",
      "Epoch 8/150\n",
      "epoch_end | time:  15.05.2021 18:44:37\n",
      " — val_aps:  0.072908 — val_a: 0.940939\n",
      "2945/2945 - 767s - loss: 0.0069 - accuracy: 0.9855 - auc_11: 0.9979 - precision_11: 0.9855 - recall_11: 0.9855 - val_loss: 0.1063 - val_accuracy: 0.9694 - val_auc_11: 0.9919 - val_precision_11: 0.9694 - val_recall_11: 0.9694\n",
      "Epoch 9/150\n",
      "epoch_end | time:  15.05.2021 18:57:17\n",
      " — val_aps:  0.060071 — val_a: 0.923512\n",
      "2945/2945 - 760s - loss: 0.0068 - accuracy: 0.9857 - auc_11: 0.9980 - precision_11: 0.9857 - recall_11: 0.9857 - val_loss: 0.0462 - val_accuracy: 0.9897 - val_auc_11: 0.9994 - val_precision_11: 0.9897 - val_recall_11: 0.9897\n",
      "Epoch 10/150\n",
      "epoch_end | time:  15.05.2021 19:10:23\n",
      " — val_aps:  0.071610 — val_a: 0.952905\n",
      "2945/2945 - 787s - loss: 0.0067 - accuracy: 0.9858 - auc_11: 0.9981 - precision_11: 0.9858 - recall_11: 0.9858 - val_loss: 0.0291 - val_accuracy: 0.9898 - val_auc_11: 0.9994 - val_precision_11: 0.9898 - val_recall_11: 0.9898\n",
      "Epoch 11/150\n",
      "epoch_end | time:  15.05.2021 19:23:20\n",
      " — val_aps:  0.073248 — val_a: 0.950907\n",
      "2945/2945 - 775s - loss: 0.0067 - accuracy: 0.9857 - auc_11: 0.9981 - precision_11: 0.9857 - recall_11: 0.9857 - val_loss: 0.0745 - val_accuracy: 0.9807 - val_auc_11: 0.9948 - val_precision_11: 0.9807 - val_recall_11: 0.9807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/150\n",
      "epoch_end | time:  15.05.2021 19:36:13\n",
      " — val_aps:  0.073854 — val_a: 0.952608\n",
      "2945/2945 - 772s - loss: 0.0066 - accuracy: 0.9863 - auc_11: 0.9982 - precision_11: 0.9863 - recall_11: 0.9863 - val_loss: 0.0200 - val_accuracy: 0.9953 - val_auc_11: 0.9995 - val_precision_11: 0.9953 - val_recall_11: 0.9953\n",
      "Epoch 13/150\n",
      "epoch_end | time:  15.05.2021 19:48:58\n",
      " — val_aps:  0.068319 — val_a: 0.950767\n",
      "2945/2945 - 765s - loss: 0.0065 - accuracy: 0.9861 - auc_11: 0.9982 - precision_11: 0.9861 - recall_11: 0.9861 - val_loss: 0.0386 - val_accuracy: 0.9936 - val_auc_11: 0.9992 - val_precision_11: 0.9936 - val_recall_11: 0.9936\n",
      "Epoch 14/150\n",
      "epoch_end | time:  15.05.2021 20:01:39\n",
      " — val_aps:  0.066342 — val_a: 0.948216\n",
      "2945/2945 - 760s - loss: 0.0064 - accuracy: 0.9864 - auc_11: 0.9983 - precision_11: 0.9864 - recall_11: 0.9864 - val_loss: 0.0705 - val_accuracy: 0.9861 - val_auc_11: 0.9979 - val_precision_11: 0.9861 - val_recall_11: 0.9861\n",
      "Epoch 15/150\n",
      "epoch_end | time:  15.05.2021 20:14:07\n",
      " — val_aps:  0.056882 — val_a: 0.945063\n",
      "2945/2945 - 748s - loss: 0.0063 - accuracy: 0.9865 - auc_11: 0.9983 - precision_11: 0.9865 - recall_11: 0.9865 - val_loss: 0.0455 - val_accuracy: 0.9889 - val_auc_11: 0.9981 - val_precision_11: 0.9889 - val_recall_11: 0.9889\n",
      "Epoch 16/150\n",
      "epoch_end | time:  15.05.2021 20:26:45\n",
      " — val_aps:  0.067024 — val_a: 0.947887\n",
      "2945/2945 - 757s - loss: 0.0063 - accuracy: 0.9864 - auc_11: 0.9983 - precision_11: 0.9864 - recall_11: 0.9864 - val_loss: 0.0238 - val_accuracy: 0.9942 - val_auc_11: 0.9992 - val_precision_11: 0.9942 - val_recall_11: 0.9942\n",
      "Epoch 17/150\n",
      "epoch_end | time:  15.05.2021 20:39:30\n",
      " — val_aps:  0.056084 — val_a: 0.943749\n",
      "2945/2945 - 765s - loss: 0.0063 - accuracy: 0.9863 - auc_11: 0.9983 - precision_11: 0.9863 - recall_11: 0.9863 - val_loss: 0.1003 - val_accuracy: 0.9618 - val_auc_11: 0.9951 - val_precision_11: 0.9618 - val_recall_11: 0.9618\n",
      "Epoch 18/150\n",
      "epoch_end | time:  15.05.2021 20:52:15\n",
      " — val_aps:  0.067460 — val_a: 0.949025\n",
      "2945/2945 - 765s - loss: 0.0062 - accuracy: 0.9866 - auc_11: 0.9984 - precision_11: 0.9866 - recall_11: 0.9866 - val_loss: 0.0318 - val_accuracy: 0.9918 - val_auc_11: 0.9990 - val_precision_11: 0.9918 - val_recall_11: 0.9918\n",
      "Epoch 19/150\n",
      "epoch_end | time:  15.05.2021 21:04:46\n",
      " — val_aps:  0.074425 — val_a: 0.952839\n",
      "2945/2945 - 751s - loss: 0.0063 - accuracy: 0.9857 - auc_11: 0.9983 - precision_11: 0.9857 - recall_11: 0.9857 - val_loss: 0.0264 - val_accuracy: 0.9932 - val_auc_11: 0.9994 - val_precision_11: 0.9932 - val_recall_11: 0.9932\n",
      "Epoch 20/150\n",
      "epoch_end | time:  15.05.2021 21:16:54\n",
      " — val_aps:  0.059305 — val_a: 0.942271\n",
      "2945/2945 - 727s - loss: 0.0062 - accuracy: 0.9865 - auc_11: 0.9983 - precision_11: 0.9865 - recall_11: 0.9865 - val_loss: 0.0356 - val_accuracy: 0.9887 - val_auc_11: 0.9989 - val_precision_11: 0.9887 - val_recall_11: 0.9887\n",
      "Epoch 21/150\n",
      "epoch_end | time:  15.05.2021 21:28:53\n",
      " — val_aps:  0.064399 — val_a: 0.949164\n",
      "2945/2945 - 718s - loss: 0.0061 - accuracy: 0.9863 - auc_11: 0.9984 - precision_11: 0.9863 - recall_11: 0.9863 - val_loss: 0.0472 - val_accuracy: 0.9870 - val_auc_11: 0.9976 - val_precision_11: 0.9870 - val_recall_11: 0.9870\n",
      "Epoch 22/150\n",
      "epoch_end | time:  15.05.2021 21:40:54\n",
      " — val_aps:  0.066318 — val_a: 0.948459\n",
      "2945/2945 - 721s - loss: 0.0061 - accuracy: 0.9863 - auc_11: 0.9984 - precision_11: 0.9863 - recall_11: 0.9863 - val_loss: 0.0317 - val_accuracy: 0.9914 - val_auc_11: 0.9993 - val_precision_11: 0.9914 - val_recall_11: 0.9914\n",
      "Epoch 23/150\n",
      "epoch_end | time:  15.05.2021 21:52:54\n",
      " — val_aps:  0.058932 — val_a: 0.943745\n",
      "2945/2945 - 719s - loss: 0.0060 - accuracy: 0.9865 - auc_11: 0.9984 - precision_11: 0.9865 - recall_11: 0.9865 - val_loss: 0.0588 - val_accuracy: 0.9876 - val_auc_11: 0.9981 - val_precision_11: 0.9876 - val_recall_11: 0.9876\n",
      "Epoch 24/150\n",
      "epoch_end | time:  15.05.2021 22:04:55\n",
      " — val_aps:  0.058350 — val_a: 0.945485\n",
      "2945/2945 - 721s - loss: 0.0061 - accuracy: 0.9864 - auc_11: 0.9984 - precision_11: 0.9864 - recall_11: 0.9864 - val_loss: 0.0794 - val_accuracy: 0.9782 - val_auc_11: 0.9943 - val_precision_11: 0.9782 - val_recall_11: 0.9782\n",
      "Epoch 25/150\n",
      "epoch_end | time:  15.05.2021 22:17:03\n",
      " — val_aps:  0.062742 — val_a: 0.947791\n",
      "2945/2945 - 728s - loss: 0.0060 - accuracy: 0.9864 - auc_11: 0.9984 - precision_11: 0.9864 - recall_11: 0.9864 - val_loss: 0.0271 - val_accuracy: 0.9922 - val_auc_11: 0.9993 - val_precision_11: 0.9922 - val_recall_11: 0.9922\n",
      "Epoch 26/150\n",
      "epoch_end | time:  15.05.2021 22:29:07\n",
      " — val_aps:  0.074771 — val_a: 0.947866\n",
      "2945/2945 - 724s - loss: 0.0060 - accuracy: 0.9862 - auc_11: 0.9984 - precision_11: 0.9862 - recall_11: 0.9862 - val_loss: 0.0291 - val_accuracy: 0.9907 - val_auc_11: 0.9993 - val_precision_11: 0.9907 - val_recall_11: 0.9907\n",
      "Epoch 27/150\n",
      "epoch_end | time:  15.05.2021 22:41:10\n",
      " — val_aps:  0.058087 — val_a: 0.944134\n",
      "2945/2945 - 721s - loss: 0.0059 - accuracy: 0.9864 - auc_11: 0.9985 - precision_11: 0.9864 - recall_11: 0.9864 - val_loss: 0.0329 - val_accuracy: 0.9912 - val_auc_11: 0.9986 - val_precision_11: 0.9912 - val_recall_11: 0.9912\n",
      "Epoch 28/150\n",
      "epoch_end | time:  15.05.2021 22:53:07\n",
      " — val_aps:  0.070302 — val_a: 0.950638\n",
      "2945/2945 - 717s - loss: 0.0059 - accuracy: 0.9867 - auc_11: 0.9985 - precision_11: 0.9867 - recall_11: 0.9867 - val_loss: 0.0314 - val_accuracy: 0.9901 - val_auc_11: 0.9992 - val_precision_11: 0.9901 - val_recall_11: 0.9901\n",
      "Epoch 29/150\n",
      "epoch_end | time:  15.05.2021 23:05:05\n",
      " — val_aps:  0.060842 — val_a: 0.940286\n",
      "2945/2945 - 718s - loss: 0.0060 - accuracy: 0.9861 - auc_11: 0.9984 - precision_11: 0.9861 - recall_11: 0.9861 - val_loss: 0.0508 - val_accuracy: 0.9819 - val_auc_11: 0.9982 - val_precision_11: 0.9819 - val_recall_11: 0.9819\n",
      "Epoch 30/150\n",
      "epoch_end | time:  15.05.2021 23:16:58\n",
      " — val_aps:  0.059940 — val_a: 0.934900\n",
      "2945/2945 - 713s - loss: 0.0059 - accuracy: 0.9862 - auc_11: 0.9985 - precision_11: 0.9862 - recall_11: 0.9862 - val_loss: 0.0941 - val_accuracy: 0.9701 - val_auc_11: 0.9934 - val_precision_11: 0.9701 - val_recall_11: 0.9701\n",
      "Epoch 31/150\n",
      "epoch_end | time:  15.05.2021 23:28:57\n",
      " — val_aps:  0.061439 — val_a: 0.950111\n",
      "2945/2945 - 718s - loss: 0.0058 - accuracy: 0.9867 - auc_11: 0.9985 - precision_11: 0.9867 - recall_11: 0.9867 - val_loss: 0.0683 - val_accuracy: 0.9891 - val_auc_11: 0.9973 - val_precision_11: 0.9891 - val_recall_11: 0.9891\n",
      "Epoch 32/150\n",
      "epoch_end | time:  15.05.2021 23:40:53\n",
      " — val_aps:  0.066700 — val_a: 0.949796\n",
      "2945/2945 - 717s - loss: 0.0059 - accuracy: 0.9869 - auc_11: 0.9985 - precision_11: 0.9869 - recall_11: 0.9869 - val_loss: 0.0285 - val_accuracy: 0.9929 - val_auc_11: 0.9993 - val_precision_11: 0.9929 - val_recall_11: 0.9929\n",
      "model_cnn_best_internal_wo_btest_MONEY_False_7_15_60_3_200515_23 valid_for_train:  0.8995922676562436 0.06670009854090603 | test:  0.8868471519869177 0.06488889652340633\n"
     ]
    }
   ],
   "source": [
    "VERBOSE = 2\n",
    "BATCH_SIZE = 512\n",
    "NB_EPOCH = 150\n",
    "class_weighting = {0: 0.05, 1: 1}\n",
    "\n",
    "result_all_8 = pd.DataFrame()\n",
    "result_all_8['name_model'] = None\n",
    "result_all_8['params'] = None\n",
    "result_all_8['val_GINI'] = None\n",
    "result_all_8['val_APS'] = None\n",
    "result_all_8['test_GINI'] = None\n",
    "result_all_8['test_APS'] = None\n",
    "j = 0\n",
    "\n",
    "for p in param_best:\n",
    "    print('=====================================================================================================')\n",
    "    print(inp_shape, X_2_2.shape, p)\n",
    "\n",
    "    model_grid = model_cnn_3(reg=p[1], reg_dense=p[6], n_features=inp_shape, n_pool=2, n_kernel=p[2],\n",
    "                             n_filters=p[3], n_strides=1, classes=2,\n",
    "                             hidden=p[4], drop_out=p[5],\n",
    "                             gl_pool_max=p[0], min_pool=p[7], n_lay=p[8])\n",
    "\n",
    "    model_grid.compile(loss='categorical_crossentropy',\n",
    "                       optimizer=tf.keras.optimizers.Adam(learning_rate=0.003),\n",
    "                       metrics=['accuracy', tf.keras.metrics.AUC(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
    "\n",
    "    history_XX = model_grid.fit_generator(generator=training_generator,  # training_aug,\n",
    "                                          # Y_test_2 = np_utils.to_categorical( y_val, 2)\n",
    "                                          validation_data=(X_2_2, Y_test_2),\n",
    "                                          epochs=NB_EPOCH, verbose=VERBOSE, class_weight=class_weighting,\n",
    "                                          callbacks=[_time, EarlyStopping(monitor='val_loss', patience=20),\n",
    "                                                     Metrics(valid_data=(X_2_2, Y_test_2))])\n",
    "\n",
    "    res_model_ = pd.DataFrame(\n",
    "        history_XX.history, columns=history_XX.history.keys())\n",
    "    dd = str(200000 + datetime.now().month*100 +\n",
    "             datetime.now().day) + '_' + str(datetime.now().hour)\n",
    "    name_m = 'model_cnn_best_internal_wo_btest_MONEY_' + str(p[0]) + '_' + str(\n",
    "        p[2]) + '_' + str(p[3]) + '_' + str(p[4]) + '_' + str(p[8]) + '_' + str(dd)\n",
    "\n",
    "    model_grid.save(name_m + '.h5')\n",
    "    res_model_.to_csv(name_m + '.csv')\n",
    "\n",
    "    predict_class_val = model_grid.predict(X_2_2)\n",
    "    APS = metrics.average_precision_score(y_test, predict_class_val[:, 1])\n",
    "    GINI = 2*(metrics.roc_auc_score(y_test, predict_class_val[:, 1])) - 1\n",
    "\n",
    "    predict_class_test = model_grid.predict(X_3_2)\n",
    "    APS_t = metrics.average_precision_score( y_val, predict_class_test[:, 1])\n",
    "    GINI_t = 2*(metrics.roc_auc_score( y_val, predict_class_test[:, 1])) - 1\n",
    "\n",
    "    result_all_8.at[j, 'name_model'] = name_m\n",
    "    result_all_8.at[j, 'params'] = str(p)\n",
    "    result_all_8.at[j, 'val_GINI'] = GINI\n",
    "    result_all_8.at[j, 'val_APS'] = APS\n",
    "    result_all_8.at[j, 'test_GINI'] = GINI_t\n",
    "    result_all_8.at[j, 'test_APS'] = APS_t\n",
    "\n",
    "    result_all_8.to_csv('model_cnn_internal_wo_btest_MONEY.csv')\n",
    "    j += 1\n",
    "    print(name_m, 'valid_for_train: ', GINI, APS, '| test: ', GINI_t, APS_t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
