{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing, GridSearch and Training SpiderNet-6 on Private Data without B/W-tests features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import math\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.pyplot import cm\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import collections\n",
    "from collections import OrderedDict, Counter\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import normaltest, kstest, ttest_ind, ttest_rel, mannwhitneyu, wilcoxon, levene, bartlett\n",
    "from scipy.stats import chi2_contingency, fisher_exact, mode, pearsonr, f_oneway, kruskal, spearmanr\n",
    "\n",
    "from rfpimp import *\n",
    "\n",
    "from datetime import datetime\n",
    "import re\n",
    "from seaborn import heatmap\n",
    "import random\n",
    "import statsmodels.distributions.empirical_distribution as edf\n",
    "from scipy.interpolate import interp1d\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from functools import reduce\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score\n",
    "\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, log_loss, recall_score\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler, PowerTransformer\n",
    "\n",
    "from sklearn.utils import check_consistent_length, column_or_1d, assert_all_finite\n",
    "from sklearn.utils.extmath import stable_cumsum\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import re\n",
    "import gc\n",
    "\n",
    "import os\n",
    "\n",
    "#from sklearn.externals import joblib\n",
    "import joblib\n",
    "\n",
    "from importlib import reload\n",
    "import Filter_and_Grid_Search\n",
    "Filter_and_Grid_Search = reload(Filter_and_Grid_Search)\n",
    "from Filter_and_Grid_Search import stratified_split\n",
    "from Filter_and_Grid_Search import attributes_list, attributes_list_new\n",
    "from Filter_and_Grid_Search import get_s_stat, get_PSI_stat, get_stats_by_month, get_stats, stable_unstable\n",
    "from Filter_and_Grid_Search import stable_unstable_by_month_divide, union_datas, individual_hists_all \n",
    "from Filter_and_Grid_Search import paired_time_hists_by_month, statistics_with_target\n",
    "from Filter_and_Grid_Search import receive_correlations, find_doubles_corr\n",
    "from Filter_and_Grid_Search import statistics_with_target, attributes_list, attributes_list_new, make_standard\n",
    "from Filter_and_Grid_Search import data_preprocessing_train, data_preprocessing_test\n",
    "from Filter_and_Grid_Search import receive_correlations, find_doubles_corr\n",
    "from Filter_and_Grid_Search import stratified_split, two_forests, turn_variables_with_values\n",
    "from Filter_and_Grid_Search import find_meta_params, calculate_vif#, find_meta_params_mem\n",
    "from Filter_and_Grid_Search import plot_meta_2d, data_preprocessing, find_ouliers_iqr\n",
    "from Filter_and_Grid_Search import train_model_receive_stats, simple_b_score_risk\n",
    "from Filter_and_Grid_Search import max_prof_corve, by_month_gini, check_attribute_list_cases\n",
    "\n",
    "from Filter_and_Grid_Search import to_zip, br_correction, br_stat\n",
    "\n",
    "from statsmodels.stats.proportion import proportions_ztest\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import pathlib\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/Share/01 -Risk Desc Science/AntiFraud/Chinese_data/Datasets/\n",
      "D:/Share/safanasev/Python-notebook/AF_ML_chinese/\n"
     ]
    }
   ],
   "source": [
    "PATH_DATA = 'D:/Share/01 -Risk Desc Science/AntiFraud/Chinese_data/Datasets/'\n",
    "PATH = 'D:/Share/safanasev/Python-notebook/AF_ML_chinese/'\n",
    "print(PATH_DATA)\n",
    "print(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'binary'\n",
    "missing_strings = 'MISSING'\n",
    "p_value = 0.05\n",
    "target_dict = {'good': 0, 'bad': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'BAD_FLAG'\n",
    "index_month = 'MONTH_YEAR'\n",
    "list_of_vars_for_strat = ['MONTH_YEAR']\n",
    "sort_by_var = 'APPPOSID'\n",
    "\n",
    "necessary_fields = [target, index_month, sort_by_var]\n",
    "\n",
    "COL_DEL = ['Unnamed: 0', 'PERIOD_7', 'LOSS_90P'] \n",
    "COL_DEL = [x.upper() for x in COL_DEL]\n",
    "COL_TRG = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UNNAMED: 0', 'PERIOD_7', 'LOSS_90P']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COL_DEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BAD_FLAG', 'MONTH_YEAR', 'APPPOSID']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "necessary_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_jobs = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start of selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (Input, Activation, Dense, Flatten, Dropout)\n",
    "from tensorflow.keras.layers import (Conv1D, MaxPooling1D, AveragePooling1D)\n",
    "from tensorflow.keras.layers import add\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import ReLU, Concatenate, GlobalAveragePooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, Callback, LearningRateScheduler\n",
    "#from keras.callbacks import EarlyStopping, Callback\n",
    "\n",
    "# объявляем класс метрик\n",
    "\n",
    "class E_time(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        tm = datetime.strftime(datetime.now(), \"%d.%m.%Y %H:%M:%S\")\n",
    "        print ('train_begin', '| time: ' , tm)\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        tm = datetime.strftime(datetime.now(), \"%d.%m.%Y %H:%M:%S\")\n",
    "        print ('epoch_end', '| time: ' , tm)\n",
    "    \n",
    "        return\n",
    "\n",
    "_time = E_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#если alpha не задано, то не делаем br_correction\n",
    "\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self,  dataset, x_col, y_col,  batch_size=256, num_classes=2, alpha = 0.1, random_state = 42, \n",
    "                 shuffle=True, class_w = None):\n",
    "        self.batch_size = batch_size\n",
    "        self.dataset = dataset\n",
    "        self.x_col = x_col\n",
    "        self.y_col = y_col\n",
    "        self.indices = self.dataset.index.tolist()\n",
    "        self.num_classes = num_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.alpha = alpha\n",
    "        self.random_state = random_state\n",
    "        self.class_w = class_w\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.indices) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        index = self.index[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch = [self.indices[k] for k in index]\n",
    "        \n",
    "        data_tmp = self.dataset.loc[batch]\n",
    "        data_tmp_b = data_tmp[data_tmp[self.y_col] == 1]\n",
    "        data_tmp_b_all = self.dataset[self.dataset[self.y_col] == 1]\n",
    "        X_tmp = data_tmp.head(0)\n",
    "        \n",
    "        \n",
    "        #print(data_tmp_b.shape[0], data_tmp.shape[0], data_tmp_b_all.shape[0])\n",
    "        if (self.alpha is None) and (self.class_w is None):\n",
    "            X = data_tmp[self.x_col] #.reshape(-1)\n",
    "            y = data_tmp[self.y_col] \n",
    "            \n",
    "        elif (self.alpha is None) and self.class_w > 0:\n",
    "            k = (self.class_w*self.batch_size)/(1-self.class_w)\n",
    "            k = k - data_tmp_b.shape[0]\n",
    "            if int(k) < 1:\n",
    "                k = k+1\n",
    "            ix2 = np.random.RandomState(self.random_state + int(k)).choice(data_tmp_b_all.shape[0], int(k))\n",
    "            X_tmp = data_tmp_b_all.iloc[ix2]\n",
    "            data_tmp = data_tmp.append(X_tmp, ignore_index=True)\n",
    "            X = data_tmp[self.x_col] #.reshape(-1)\n",
    "            y = data_tmp[self.y_col]\n",
    "            #print(data_tmp_b.shape[0], data_tmp.shape[0],  data_tmp_b.shape[0]/(data_tmp.shape[0] - X_tmp.shape[0]), np.mean(y)) \n",
    "            \n",
    "            \n",
    "            \n",
    "        else:\n",
    "            if data_tmp_b.shape[0] > 0:\n",
    "                k=(self.alpha*self.batch_size/data_tmp_b.shape[0] -1 )/(1-self.alpha)\n",
    "                for i in range(0,int(k)):\n",
    "                    X_tmp = X_tmp.append(data_tmp_b, ignore_index=True)\n",
    "            else:\n",
    "                k = (self.alpha*self.batch_size)/(1-self.alpha)\n",
    "                ix2 = np.random.RandomState(self.random_state + int(k)).choice(data_tmp_b_all.shape[0], int(k))\n",
    "                X_tmp = data_tmp_b_all.iloc[ix2]\n",
    "                data_tmp_b = X_tmp\n",
    "\n",
    "    #         print('Добавим дробное число строк')    \n",
    "            k_fraction = k - int(k)\n",
    "            n_samples = int(round(data_tmp_b.shape[0]*k_fraction))\n",
    "    #         print(k_fraction, n_samples)\n",
    "\n",
    "            ix = np.random.RandomState(self.random_state).choice(data_tmp_b.shape[0], n_samples)\n",
    "            data_add_fraction = data_tmp_b.iloc[ix]\n",
    "            X_tmp.append(data_add_fraction, ignore_index=True)\n",
    "\n",
    "            data_tmp = data_tmp.append(X_tmp, ignore_index=True)\n",
    "\n",
    "\n",
    "            X = data_tmp[self.x_col] #.reshape(-1)\n",
    "            y = data_tmp[self.y_col]   \n",
    "        #print(sum(self.dataset.loc[batch][self.y_col])/len(index), np.mean(y))\n",
    "        \n",
    "        if self.num_classes > 1:\n",
    "            y = np_utils.to_categorical( y, self.num_classes)\n",
    "            \n",
    "        ####for tf 2.3.0, [np.array(X)], np.array(y)\n",
    "\n",
    "        #return [np.array(X).reshape(X.shape[0], X.shape[1], 1)], np.array(y)\n",
    "        return [np.array(X)], np.array(y)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.index = np.arange(len(self.indices))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'D:/Share/safanasev/Python-notebook/AF_ML_v2_2014/'\n",
    "#загружаем данные для 163 переменных\n",
    "\n",
    "train_for = pd.read_csv(PATH + 'train_163_prep.csv')\n",
    "valid_for = pd.read_csv(PATH + 'valid_163_prep.csv')\n",
    "test_for = pd.read_csv(PATH + 'test_163_prep.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_for[target]\n",
    "#y_test = valid_for[target]\n",
    "#y_val = test_for[target]\n",
    "\n",
    "y_test = test_for[target]\n",
    "y_val = valid_for[target]\n",
    "\n",
    "train_for.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "valid_for.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "test_for.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "col = train_for.columns.to_list()\n",
    "col.remove(target)\n",
    "\n",
    "\n",
    "X_1_2 = train_for[col]\n",
    "X_2_2 = valid_for[col]\n",
    "X_3_2 = test_for[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1507599, 163), (1507599, 164), 1507599)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#проверка корректности\n",
    "X_1_2.shape, train_for.shape, len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col = X_2_2.columns\n",
    "y_col = 'BAD_FLAG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#проверка корректности, должно быть везде True\n",
    "print(X_2_2.shape[0] == valid_for.shape[0])\n",
    "print(X_2_2.shape[1] == valid_for.shape[1] - 1)\n",
    "print(len(y_val) == valid_for.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#если alpha не задано, то не делаем br_correction\n",
    "#новая версия, исправлены индексы\n",
    "\n",
    "class DataGenerator_new(tf.keras.utils.Sequence):\n",
    "    def __init__(self,  dataset, x_col, y_col,  batch_size=256, num_classes=2, alpha = 0.1, random_state = 42, \n",
    "                 shuffle=True, class_w = None):\n",
    "        self.batch_size = batch_size\n",
    "        self.dataset = dataset\n",
    "        self.x_col = x_col\n",
    "        self.y_col = y_col\n",
    "        self.indices = self.dataset.index.tolist()\n",
    "        self.num_classes = num_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.alpha = alpha\n",
    "        self.random_state = random_state\n",
    "        self.class_w = class_w\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.indices) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch = [self.indices[k] for k in indexes]\n",
    "        \n",
    "        data_tmp = self.dataset.loc[batch]\n",
    "        data_tmp_b = data_tmp[data_tmp[self.y_col] == 1]\n",
    "        data_tmp_b_all = self.dataset[self.dataset[self.y_col] == 1]\n",
    "        X_tmp = data_tmp.head(0)\n",
    "        \n",
    "        \n",
    "        #print(data_tmp_b.shape[0], data_tmp.shape[0], data_tmp_b_all.shape[0])\n",
    "        if (self.alpha is None) and (self.class_w is None):\n",
    "            X = data_tmp[self.x_col] #.reshape(-1)\n",
    "            y = data_tmp[self.y_col] \n",
    "            \n",
    "        elif (self.alpha is None) and self.class_w > 0:\n",
    "            k = (self.class_w*self.batch_size)/(1-self.class_w)\n",
    "            k = k - data_tmp_b.shape[0]\n",
    "            if int(k) < 1:\n",
    "                k = k+1\n",
    "            ix2 = np.random.RandomState(self.random_state + int(k)).choice(data_tmp_b_all.shape[0], int(k))\n",
    "            X_tmp = data_tmp_b_all.iloc[ix2]\n",
    "            data_tmp = data_tmp.append(X_tmp, ignore_index=True)\n",
    "            X = data_tmp[self.x_col] #.reshape(-1)\n",
    "            y = data_tmp[self.y_col]\n",
    "            #print(data_tmp_b.shape[0], data_tmp.shape[0],  data_tmp_b.shape[0]/(data_tmp.shape[0] - X_tmp.shape[0]), np.mean(y)) \n",
    "            \n",
    "            \n",
    "            \n",
    "        else:\n",
    "            if data_tmp_b.shape[0] > 0:\n",
    "                k=(self.alpha*self.batch_size/data_tmp_b.shape[0] -1 )/(1-self.alpha)\n",
    "                for i in range(0,int(k)):\n",
    "                    X_tmp = X_tmp.append(data_tmp_b, ignore_index=True)\n",
    "            else:\n",
    "                k = (self.alpha*self.batch_size)/(1-self.alpha)\n",
    "                ix2 = np.random.RandomState(self.random_state + int(k)).choice(data_tmp_b_all.shape[0], int(k))\n",
    "                X_tmp = data_tmp_b_all.iloc[ix2]\n",
    "                data_tmp_b = X_tmp\n",
    "\n",
    "    #         print('Добавим дробное число строк')    \n",
    "            k_fraction = k - int(k)\n",
    "            n_samples = int(round(data_tmp_b.shape[0]*k_fraction))\n",
    "    #         print(k_fraction, n_samples)\n",
    "\n",
    "            ix = np.random.RandomState(self.random_state).choice(data_tmp_b.shape[0], n_samples)\n",
    "            data_add_fraction = data_tmp_b.iloc[ix]\n",
    "            X_tmp.append(data_add_fraction, ignore_index=True)\n",
    "\n",
    "            data_tmp = data_tmp.append(X_tmp, ignore_index=True)\n",
    "\n",
    "\n",
    "            X = data_tmp[self.x_col] #.reshape(-1)\n",
    "            y = data_tmp[self.y_col]   \n",
    "        #print(sum(self.dataset.loc[batch][self.y_col])/len(index), np.mean(y))\n",
    "        \n",
    "        if self.num_classes > 1:\n",
    "            y = np_utils.to_categorical( y, self.num_classes)\n",
    "            \n",
    "        ####for tf 2.3.0, [np.array(X)], np.array(y)\n",
    "\n",
    "        return [np.array(X).reshape(X.shape[0], X.shape[1], 1)], np.array(y)\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.indices))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = DataGenerator(train_for, x_col, y_col, batch_size=512, alpha = None, class_w = 0.05 )\n",
    "#validation_generator = DataGenerator(valid_for, x_col, y_col, batch_size=valid_for.shape[0], alpha = None, class_w = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test_2 = np_utils.to_categorical( y_val, 2) # преобразовываем в 2 класса "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((185400, 163), (185400, 2))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2_2.shape, Y_test_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_test = []\n",
    "w_test = []\n",
    "del_all = []\n",
    "\n",
    "for i in X_2_2.columns:\n",
    "    if i.find('W_TEST') >= 0:\n",
    "        w_test.append(i)\n",
    "        del_all.append(i)\n",
    "    if i.find('B_TEST') >= 0:\n",
    "        b_test.append(i)\n",
    "        del_all.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = train_for.columns.to_list()\n",
    "col.remove(target)\n",
    "\n",
    "col_2 = [i for i in col if i not in del_all]\n",
    "\n",
    "\n",
    "X_1_2 = train_for[col_2]\n",
    "X_2_2 = valid_for[col_2]\n",
    "X_3_2 = test_for[col_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1507599, 124), 124)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1_2.shape, 163 - len(b_test) - len(w_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col = X_2_2.columns\n",
    "y_col = 'BAD_FLAG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 29\n",
    "\n",
    "# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.set_random_seed(seed_value)\n",
    "\n",
    "\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "# for later versions:\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, valid_data):\n",
    "        super(Metrics, self).__init__()\n",
    "        self.validation_data = valid_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        val_predict = self.model.predict(self.validation_data[0])[:, 1]\n",
    "        val_targ = self.validation_data[1]\n",
    "        \n",
    "        if len(val_targ.shape) == 2: #and val_targ.shape[1] != 1:\n",
    "            val_targ = val_targ[:,1]\n",
    "\n",
    "        _val_aps = metrics.average_precision_score(val_targ, val_predict)\n",
    "        #_val_recall = metrics.recall_score(val_targ, val_predict)\n",
    "        _val_a = metrics.roc_auc_score(val_targ, val_predict)\n",
    "\n",
    "        logs['val_aps'] = _val_aps\n",
    "        logs['val_a'] = _val_a\n",
    "        print(\" — val_aps:  %f — val_a: %f\" % (_val_aps, _val_a))\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:\\\\Program Files (x86)\\\\Graphviz2.38\\\\bin\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_aug = DataGenerator(aug_for, x_col, y_col, batch_size=512, alpha = None, class_w = 0.05 )\n",
    "training_generator = DataGenerator(train_for, x_col, y_col, batch_size=512, alpha = None, class_w = 0.05 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning_rate=0.005\n",
    "initial_learning_rate = 0.005\n",
    "\n",
    "def lr_step_decay(epoch, lr):\n",
    "    drop_rate = 0.1\n",
    "    epochs_drop = 20.0\n",
    "    \n",
    "    return initial_learning_rate * math.pow(drop_rate, math.floor(epoch/epochs_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import optuna\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "from optuna.trial import TrialState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl_p = [False] #0\n",
    "l2_batch = [ 0.0002] #1\n",
    "n_ker = [5, 7] #2\n",
    "n_fil = [ 5, 15] #3\n",
    "d_hidden = [30, 100] #4\n",
    "drop_out = [0.30] #5\n",
    "drop_out_conv = [0.001] #6\n",
    "reg_dense = [ 0.0002] #7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = itertools.product(gl_p, l2_batch, n_ker, n_fil, d_hidden, drop_out, drop_out_conv, reg_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(False, 0.0002, 5, 5, 30, 0.3, 0.001, 0.0002)\n",
      "(False, 0.0002, 5, 5, 100, 0.3, 0.001, 0.0002)\n",
      "(False, 0.0002, 5, 15, 30, 0.3, 0.001, 0.0002)\n",
      "(False, 0.0002, 5, 15, 100, 0.3, 0.001, 0.0002)\n",
      "(False, 0.0002, 7, 5, 30, 0.3, 0.001, 0.0002)\n",
      "(False, 0.0002, 7, 5, 100, 0.3, 0.001, 0.0002)\n",
      "(False, 0.0002, 7, 15, 30, 0.3, 0.001, 0.0002)\n",
      "(False, 0.0002, 7, 15, 100, 0.3, 0.001, 0.0002)\n"
     ]
    }
   ],
   "source": [
    "for i in param:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator = DataGenerator(train_for, x_col, y_col, batch_size=512, alpha = None, class_w = 0.05 ) #было 0,05\n",
    "#validation_generator = DataGenerator(valid_for, x_col, y_col, batch_size=valid_for.shape[0], alpha = None, class_w = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_shape = X_2_2.shape[1] #китайский датасэт\n",
    "inp_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The best SpiderNet-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spider_model(l2_conv = None, reg = 1E-5 ,\n",
    "                 _bias = True,  n_features = 163, n_pool = 2, n_kernel = 5, n_filters = 5, n_strides = 1,\n",
    "                 classes = 2, hidden = 64 , drop_out = 0.25, drop_out_conv = 0.001, drop_out_rate = 4 ,\n",
    "                 padding_pool = 'valid' ,\n",
    "                gl_pool_max = False):\n",
    "    \n",
    "    if reg == None:\n",
    "        l2_batch_gamma = None \n",
    "        l2_batch_betta = None\n",
    "    else:\n",
    "        l2_batch_gamma = l2(reg)\n",
    "        l2_batch_betta =l2(reg)\n",
    "    \n",
    "    \n",
    "    x = Input(shape=(  n_features, 1))\n",
    "    n = 0\n",
    "    y = Conv1D(filters=n_filters, kernel_size=n_kernel, strides=n_strides, padding='same', \n",
    "           use_bias=_bias, kernel_regularizer=l2_conv)(x) \n",
    "\n",
    "    y = BatchNormalization(gamma_regularizer=l2_batch_gamma ,beta_regularizer=l2_batch_betta)(y)\n",
    "    y = ReLU()(y)\n",
    "#y = Dropout(rate=drop_rate)(y)\n",
    "\n",
    "    y = MaxPooling1D(pool_size = n_pool, padding=padding_pool)(y) ##\n",
    "    shortcut1_2 = MaxPooling1D(pool_size = n_pool, padding=padding_pool)(y)## поправить\n",
    "    shortcut1_3 = MaxPooling1D(pool_size = n_pool, padding=padding_pool)(shortcut1_2)##\n",
    "    shortcut1_4 = MaxPooling1D(pool_size = n_pool, padding=padding_pool)(shortcut1_3)##\n",
    "    shortcut1_5 = MaxPooling1D(pool_size = n_pool, padding=padding_pool)(shortcut1_4)\n",
    "\n",
    "    # второй spider-block\n",
    "    y = Conv1D(filters=n_filters*2, kernel_size=n_kernel, strides=n_strides, padding='same',\n",
    "              use_bias=_bias, kernel_regularizer=l2_conv)(y) \n",
    "    y = BatchNormalization(gamma_regularizer=l2_batch_gamma ,beta_regularizer=l2_batch_betta)(y)\n",
    "    y = ReLU()(y)\n",
    "\n",
    "    y = MaxPooling1D(pool_size = n_pool, padding=padding_pool)(y) ##\n",
    "    shortcut2_2 = MaxPooling1D(pool_size = n_pool, padding=padding_pool)(y)##\n",
    "    shortcut2_3 = MaxPooling1D(pool_size = n_pool, padding=padding_pool)(shortcut2_2)##\n",
    "    shortcut2_4 = MaxPooling1D(pool_size = n_pool, padding=padding_pool)(shortcut2_3)\n",
    "\n",
    "\n",
    "    y= Concatenate(axis=-1)([shortcut1_2, y])\n",
    "    n = n+1\n",
    "\n",
    "    # третий spider-block\n",
    "    y = Conv1D(filters=n_filters*(3 + 1), kernel_size=n_kernel, strides=n_strides, padding='same',\n",
    "              use_bias=_bias, kernel_regularizer=l2_conv)(y) \n",
    "    y = BatchNormalization(gamma_regularizer=l2_batch_gamma ,beta_regularizer=l2_batch_betta)(y)\n",
    "    y = ReLU()(y)\n",
    "\n",
    "    y = MaxPooling1D(pool_size = n_pool, padding=padding_pool)(y) ##\n",
    "    shortcut3_2 = MaxPooling1D(pool_size = n_pool, padding=padding_pool)(y)##\n",
    "    shortcut3_3 = MaxPooling1D(pool_size = n_pool, padding=padding_pool)(shortcut3_2)##\n",
    "\n",
    "    y= Concatenate(axis=-1)([shortcut2_2, shortcut1_3, y])\n",
    "    n = n+1\n",
    "    # четвертый spider-block\n",
    "    y = Conv1D(filters=n_filters*(4 + 1), kernel_size=n_kernel, strides=n_strides, padding='same',\n",
    "              use_bias=_bias, kernel_regularizer=l2_conv)(y) \n",
    "    y = BatchNormalization(gamma_regularizer=l2_batch_gamma ,beta_regularizer=l2_batch_betta)(y)\n",
    "    y = ReLU()(y)\n",
    "\n",
    "    y = MaxPooling1D(pool_size = n_pool, padding=padding_pool)(y) ##\n",
    "    shortcut4_2 = MaxPooling1D(pool_size = n_pool, padding=padding_pool)(y)##\n",
    "\n",
    "    y= Concatenate(axis=-1)([shortcut3_2, shortcut2_3, shortcut1_4, y])\n",
    "    n = n+1\n",
    "    y = Dropout(drop_out_conv*(n**drop_out_rate))(y)\n",
    "    print(n, drop_out_conv*(n**drop_out_rate))\n",
    "\n",
    "    # пятый spider-block\n",
    "    y = Conv1D(filters=n_filters*(5 + 1), kernel_size=n_kernel, strides=n_strides, padding='same',\n",
    "              use_bias=_bias, kernel_regularizer=l2_conv)(y) \n",
    "    y = BatchNormalization(gamma_regularizer=l2_batch_gamma ,beta_regularizer=l2_batch_betta)(y)\n",
    "    y = ReLU()(y)\n",
    "\n",
    "    y = MaxPooling1D(pool_size = n_pool, padding=padding_pool)(y) ##\n",
    "    y= Concatenate(axis=-1)([shortcut4_2, shortcut3_3, shortcut2_4, shortcut1_5, y])\n",
    "    n = n+1\n",
    "    y = Dropout(drop_out_conv*(n**drop_out_rate))(y)\n",
    "    print(n, drop_out_conv*(n**drop_out_rate))\n",
    "\n",
    "    # шестой spider-block\n",
    "    y = Conv1D(filters=n_filters*(6 + 1), kernel_size=n_kernel, strides=n_strides, padding='same',\n",
    "              use_bias=_bias, kernel_regularizer=l2_conv)(y) \n",
    "    y = BatchNormalization(gamma_regularizer=l2_batch_gamma ,beta_regularizer=l2_batch_betta)(y)\n",
    "    y = ReLU()(y)\n",
    "    if gl_pool_max:\n",
    "        z = GlobalMaxPooling1D()(y)\n",
    "        \n",
    "    else:\n",
    "        z = GlobalAveragePooling1D()(y)\n",
    "    #z = Flatten()(y) #сглаживание, пример использования - https://stackoverflow.com/questions/43237124/what-is-the-role-of-flatten-in-keras\n",
    "    z = Dense(hidden, activation='relu')(z)\n",
    "    z = Dropout(drop_out)(z)\n",
    "    z = Dense(hidden, activation='relu')(z)\n",
    "    z = Dropout(drop_out)(z)\n",
    "    predictions = Dense(classes, activation='softmax')(z)\n",
    "\n",
    "    #model = Sequential()\n",
    "    model_15 = Model(inputs=x, outputs=predictions)\n",
    "    \n",
    "    return model_15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl_p = [True]\n",
    "l2_batch = [1E-5]\n",
    "n_ker = [5]\n",
    "n_fil = [ 5]\n",
    "d_hidden = [64] \n",
    "drop_out = [ 0.25]\n",
    "drop_out_conv = [0.001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = itertools.product(gl_p, l2_batch, n_ker, n_fil, d_hidden, drop_out, drop_out_conv, reg_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (True, 1e-05, 5, 5, 64, 0.25, 0.001, 1e-05)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for p in param:\n",
    "    print(i, p)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================================================\n",
      "124 (185400, 124) (True, 1e-05, 5, 5, 64, 0.25, 0.001, 1e-05)\n",
      "3 0.081\n",
      "4 0.256\n",
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 124, 1)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 124, 5)       30          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 124, 5)       20          conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_12 (ReLU)                 (None, 124, 5)       0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling1D) (None, 62, 5)        0           re_lu_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 62, 10)       260         max_pooling1d_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 62, 10)       40          conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_13 (ReLU)                 (None, 62, 10)       0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling1D) (None, 31, 10)       0           re_lu_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling1D) (None, 31, 5)        0           max_pooling1d_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 31, 15)       0           max_pooling1d_31[0][0]           \n",
      "                                                                 max_pooling1d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 31, 20)       1520        concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 31, 20)       80          conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_14 (ReLU)                 (None, 31, 20)       0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling1D) (None, 15, 10)       0           max_pooling1d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling1D) (None, 15, 5)        0           max_pooling1d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling1D) (None, 15, 20)       0           re_lu_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 15, 35)       0           max_pooling1d_36[0][0]           \n",
      "                                                                 max_pooling1d_32[0][0]           \n",
      "                                                                 max_pooling1d_39[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 15, 25)       4400        concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 15, 25)       100         conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_15 (ReLU)                 (None, 15, 25)       0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling1D) (None, 7, 25)        0           re_lu_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling1D) (None, 7, 20)        0           max_pooling1d_39[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling1D) (None, 7, 10)        0           max_pooling1d_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling1D) (None, 7, 5)         0           max_pooling1d_32[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 7, 60)        0           max_pooling1d_40[0][0]           \n",
      "                                                                 max_pooling1d_37[0][0]           \n",
      "                                                                 max_pooling1d_33[0][0]           \n",
      "                                                                 max_pooling1d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 7, 60)        0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 7, 30)        9030        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 7, 30)        120         conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_16 (ReLU)                 (None, 7, 30)        0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling1D) (None, 3, 25)        0           max_pooling1d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling1D) (None, 3, 20)        0           max_pooling1d_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling1D) (None, 3, 10)        0           max_pooling1d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling1D) (None, 3, 5)         0           max_pooling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling1D) (None, 3, 30)        0           re_lu_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 3, 90)        0           max_pooling1d_43[0][0]           \n",
      "                                                                 max_pooling1d_41[0][0]           \n",
      "                                                                 max_pooling1d_38[0][0]           \n",
      "                                                                 max_pooling1d_34[0][0]           \n",
      "                                                                 max_pooling1d_44[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 3, 90)        0           concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 3, 35)        15785       dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 3, 35)        140         conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_17 (ReLU)                 (None, 3, 35)        0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 35)           0           re_lu_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 64)           2304        global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 64)           0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 64)           4160        dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 64)           0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 2)            130         dropout_11[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 38,119\n",
      "Trainable params: 37,869\n",
      "Non-trainable params: 250\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for p in param:\n",
    "    print('=====================================================================================================')\n",
    "    print(inp_shape, X_2_2.shape, p)\n",
    "    \n",
    "    model_grid = spider_model(gl_pool_max = p[0], reg = p[1],\n",
    "                             n_kernel = p[2], n_filters = p[3], hidden = p[4], drop_out = p[5], drop_out_conv = p[6],\n",
    "                             n_features = inp_shape)\n",
    "    \n",
    "    model_grid.compile(loss='categorical_crossentropy', \n",
    "                 optimizer=tf.keras.optimizers.Adam(learning_rate=0.003),\n",
    "              metrics=['accuracy', tf.keras.metrics.AUC(), tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "    model_grid.summary()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124 BAD_FLAG\n"
     ]
    }
   ],
   "source": [
    "training_generator = DataGenerator(train_for, x_col, y_col, batch_size=512, alpha = None, class_w = 0.05 )\n",
    "print(len(x_col), y_col )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_step_decay(epoch, lr):\n",
    "    drop_rate = 0.1\n",
    "    epochs_drop = 20.0\n",
    "    initial_learning_rate = 0.005\n",
    "    \n",
    "    return initial_learning_rate * math.pow(drop_rate, math.floor(epoch/epochs_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================================================\n",
      "124 (185400, 124) (True, 1e-05, 5, 5, 64, 0.25, 0.001, 1e-05)\n",
      "3 0.081\n",
      "4 0.256\n",
      "train_begin | time:  12.05.2021 00:27:54\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 1/150\n",
      "epoch_end | time:  12.05.2021 00:40:24\n",
      " — val_aps:  0.071814 — val_a: 0.933132\n",
      "2945/2945 - 787s - loss: 0.0109 - accuracy: 0.9677 - auc_3: 0.9924 - precision_3: 0.9677 - recall_3: 0.9677 - val_loss: 0.0275 - val_accuracy: 0.9951 - val_auc_3: 0.9995 - val_precision_3: 0.9951 - val_recall_3: 0.9951\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 2/150\n",
      "epoch_end | time:  12.05.2021 00:52:51\n",
      " — val_aps:  0.074780 — val_a: 0.945938\n",
      "2945/2945 - 746s - loss: 0.0069 - accuracy: 0.9852 - auc_3: 0.9971 - precision_3: 0.9852 - recall_3: 0.9852 - val_loss: 0.0380 - val_accuracy: 0.9908 - val_auc_3: 0.9989 - val_precision_3: 0.9908 - val_recall_3: 0.9908\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 3/150\n",
      "epoch_end | time:  12.05.2021 01:05:21\n",
      " — val_aps:  0.075069 — val_a: 0.942333\n",
      "2945/2945 - 752s - loss: 0.0062 - accuracy: 0.9871 - auc_3: 0.9978 - precision_3: 0.9871 - recall_3: 0.9871 - val_loss: 0.0217 - val_accuracy: 0.9959 - val_auc_3: 0.9995 - val_precision_3: 0.9959 - val_recall_3: 0.9959\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 4/150\n",
      "epoch_end | time:  12.05.2021 01:17:55\n",
      " — val_aps:  0.058892 — val_a: 0.949439\n",
      "2945/2945 - 750s - loss: 0.0058 - accuracy: 0.9876 - auc_3: 0.9981 - precision_3: 0.9876 - recall_3: 0.9876 - val_loss: 0.0485 - val_accuracy: 0.9908 - val_auc_3: 0.9984 - val_precision_3: 0.9908 - val_recall_3: 0.9908\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 5/150\n",
      "epoch_end | time:  12.05.2021 01:31:00\n",
      " — val_aps:  0.067552 — val_a: 0.943447\n",
      "2945/2945 - 790s - loss: 0.0056 - accuracy: 0.9875 - auc_3: 0.9983 - precision_3: 0.9875 - recall_3: 0.9875 - val_loss: 0.0657 - val_accuracy: 0.9866 - val_auc_3: 0.9979 - val_precision_3: 0.9866 - val_recall_3: 0.9866\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 6/150\n",
      "epoch_end | time:  12.05.2021 01:43:44\n",
      " — val_aps:  0.063877 — val_a: 0.948662\n",
      "2945/2945 - 761s - loss: 0.0054 - accuracy: 0.9878 - auc_3: 0.9984 - precision_3: 0.9878 - recall_3: 0.9878 - val_loss: 0.0310 - val_accuracy: 0.9930 - val_auc_3: 0.9993 - val_precision_3: 0.9930 - val_recall_3: 0.9930\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 7/150\n",
      "epoch_end | time:  12.05.2021 01:56:08\n",
      " — val_aps:  0.064350 — val_a: 0.938235\n",
      "2945/2945 - 741s - loss: 0.0053 - accuracy: 0.9879 - auc_3: 0.9985 - precision_3: 0.9879 - recall_3: 0.9879 - val_loss: 0.0236 - val_accuracy: 0.9946 - val_auc_3: 0.9994 - val_precision_3: 0.9946 - val_recall_3: 0.9946\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 8/150\n",
      "epoch_end | time:  12.05.2021 02:08:58\n",
      " — val_aps:  0.054017 — val_a: 0.941469\n",
      "2945/2945 - 764s - loss: 0.0051 - accuracy: 0.9881 - auc_3: 0.9985 - precision_3: 0.9881 - recall_3: 0.9881 - val_loss: 0.0347 - val_accuracy: 0.9918 - val_auc_3: 0.9991 - val_precision_3: 0.9918 - val_recall_3: 0.9918\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 9/150\n",
      "epoch_end | time:  12.05.2021 02:20:57\n",
      " — val_aps:  0.067029 — val_a: 0.945353\n",
      "2945/2945 - 726s - loss: 0.0051 - accuracy: 0.9885 - auc_3: 0.9986 - precision_3: 0.9885 - recall_3: 0.9885 - val_loss: 0.0380 - val_accuracy: 0.9904 - val_auc_3: 0.9991 - val_precision_3: 0.9904 - val_recall_3: 0.9904\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 10/150\n",
      "epoch_end | time:  12.05.2021 02:34:07\n",
      " — val_aps:  0.056657 — val_a: 0.940216\n",
      "2945/2945 - 787s - loss: 0.0050 - accuracy: 0.9883 - auc_3: 0.9987 - precision_3: 0.9883 - recall_3: 0.9883 - val_loss: 0.0725 - val_accuracy: 0.9816 - val_auc_3: 0.9962 - val_precision_3: 0.9816 - val_recall_3: 0.9816\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 11/150\n",
      "epoch_end | time:  12.05.2021 02:46:58\n",
      " — val_aps:  0.072415 — val_a: 0.948588\n",
      "2945/2945 - 768s - loss: 0.0049 - accuracy: 0.9883 - auc_3: 0.9987 - precision_3: 0.9883 - recall_3: 0.9883 - val_loss: 0.0226 - val_accuracy: 0.9953 - val_auc_3: 0.9995 - val_precision_3: 0.9953 - val_recall_3: 0.9953\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 12/150\n",
      "epoch_end | time:  12.05.2021 02:58:50\n",
      " — val_aps:  0.054678 — val_a: 0.938818\n",
      "2945/2945 - 704s - loss: 0.0048 - accuracy: 0.9885 - auc_3: 0.9987 - precision_3: 0.9885 - recall_3: 0.9885 - val_loss: 0.0359 - val_accuracy: 0.9897 - val_auc_3: 0.9984 - val_precision_3: 0.9897 - val_recall_3: 0.9897\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 13/150\n",
      "epoch_end | time:  12.05.2021 03:10:24\n",
      " — val_aps:  0.065226 — val_a: 0.942878\n",
      "2945/2945 - 703s - loss: 0.0048 - accuracy: 0.9883 - auc_3: 0.9988 - precision_3: 0.9883 - recall_3: 0.9883 - val_loss: 0.0487 - val_accuracy: 0.9903 - val_auc_3: 0.9991 - val_precision_3: 0.9903 - val_recall_3: 0.9903\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 14/150\n",
      "epoch_end | time:  12.05.2021 03:22:53\n",
      " — val_aps:  0.063337 — val_a: 0.934177\n",
      "2945/2945 - 747s - loss: 0.0048 - accuracy: 0.9886 - auc_3: 0.9988 - precision_3: 0.9886 - recall_3: 0.9886 - val_loss: 0.0248 - val_accuracy: 0.9955 - val_auc_3: 0.9994 - val_precision_3: 0.9955 - val_recall_3: 0.9955\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 15/150\n",
      "epoch_end | time:  12.05.2021 03:34:27\n",
      " — val_aps:  0.067630 — val_a: 0.940989\n",
      "2945/2945 - 696s - loss: 0.0047 - accuracy: 0.9884 - auc_3: 0.9988 - precision_3: 0.9884 - recall_3: 0.9884 - val_loss: 0.0316 - val_accuracy: 0.9937 - val_auc_3: 0.9993 - val_precision_3: 0.9937 - val_recall_3: 0.9937\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 16/150\n",
      "epoch_end | time:  12.05.2021 03:46:31\n",
      " — val_aps:  0.053250 — val_a: 0.938027\n",
      "2945/2945 - 721s - loss: 0.0047 - accuracy: 0.9885 - auc_3: 0.9988 - precision_3: 0.9885 - recall_3: 0.9885 - val_loss: 0.0475 - val_accuracy: 0.9884 - val_auc_3: 0.9982 - val_precision_3: 0.9884 - val_recall_3: 0.9884\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 17/150\n",
      "epoch_end | time:  12.05.2021 03:58:27\n",
      " — val_aps:  0.067208 — val_a: 0.950414\n",
      "2945/2945 - 716s - loss: 0.0046 - accuracy: 0.9886 - auc_3: 0.9989 - precision_3: 0.9886 - recall_3: 0.9886 - val_loss: 0.0350 - val_accuracy: 0.9902 - val_auc_3: 0.9990 - val_precision_3: 0.9902 - val_recall_3: 0.9902\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 18/150\n",
      "epoch_end | time:  12.05.2021 04:10:31\n",
      " — val_aps:  0.059895 — val_a: 0.942975\n",
      "2945/2945 - 725s - loss: 0.0046 - accuracy: 0.9888 - auc_3: 0.9989 - precision_3: 0.9888 - recall_3: 0.9888 - val_loss: 0.0258 - val_accuracy: 0.9952 - val_auc_3: 0.9994 - val_precision_3: 0.9952 - val_recall_3: 0.9952\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 19/150\n",
      "epoch_end | time:  12.05.2021 04:22:15\n",
      " — val_aps:  0.064281 — val_a: 0.949461\n",
      "2945/2945 - 702s - loss: 0.0045 - accuracy: 0.9890 - auc_3: 0.9989 - precision_3: 0.9890 - recall_3: 0.9890 - val_loss: 0.0236 - val_accuracy: 0.9945 - val_auc_3: 0.9992 - val_precision_3: 0.9945 - val_recall_3: 0.9945\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 20/150\n",
      "epoch_end | time:  12.05.2021 04:34:13\n",
      " — val_aps:  0.066146 — val_a: 0.946700\n",
      "2945/2945 - 717s - loss: 0.0046 - accuracy: 0.9886 - auc_3: 0.9989 - precision_3: 0.9886 - recall_3: 0.9886 - val_loss: 0.0280 - val_accuracy: 0.9953 - val_auc_3: 0.9995 - val_precision_3: 0.9953 - val_recall_3: 0.9953\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 21/150\n",
      "epoch_end | time:  12.05.2021 04:46:18\n",
      " — val_aps:  0.076653 — val_a: 0.950377\n",
      "2945/2945 - 726s - loss: 0.0039 - accuracy: 0.9897 - auc_3: 0.9993 - precision_3: 0.9897 - recall_3: 0.9897 - val_loss: 0.0207 - val_accuracy: 0.9956 - val_auc_3: 0.9995 - val_precision_3: 0.9956 - val_recall_3: 0.9956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 22/150\n",
      "epoch_end | time:  12.05.2021 04:57:15\n",
      " — val_aps:  0.075493 — val_a: 0.948222\n",
      "2945/2945 - 656s - loss: 0.0036 - accuracy: 0.9898 - auc_3: 0.9994 - precision_3: 0.9898 - recall_3: 0.9898 - val_loss: 0.0204 - val_accuracy: 0.9954 - val_auc_3: 0.9995 - val_precision_3: 0.9954 - val_recall_3: 0.9954\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 23/150\n",
      "epoch_end | time:  12.05.2021 05:09:06\n",
      " — val_aps:  0.076447 — val_a: 0.947662\n",
      "2945/2945 - 725s - loss: 0.0036 - accuracy: 0.9895 - auc_3: 0.9994 - precision_3: 0.9895 - recall_3: 0.9895 - val_loss: 0.0196 - val_accuracy: 0.9961 - val_auc_3: 0.9995 - val_precision_3: 0.9961 - val_recall_3: 0.9961\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 24/150\n",
      "epoch_end | time:  12.05.2021 05:21:12\n",
      " — val_aps:  0.074972 — val_a: 0.945920\n",
      "2945/2945 - 710s - loss: 0.0035 - accuracy: 0.9894 - auc_3: 0.9994 - precision_3: 0.9894 - recall_3: 0.9894 - val_loss: 0.0198 - val_accuracy: 0.9957 - val_auc_3: 0.9994 - val_precision_3: 0.9957 - val_recall_3: 0.9957\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 25/150\n",
      "epoch_end | time:  12.05.2021 05:33:21\n",
      " — val_aps:  0.074680 — val_a: 0.946970\n",
      "2945/2945 - 729s - loss: 0.0035 - accuracy: 0.9893 - auc_3: 0.9994 - precision_3: 0.9893 - recall_3: 0.9893 - val_loss: 0.0231 - val_accuracy: 0.9947 - val_auc_3: 0.9995 - val_precision_3: 0.9947 - val_recall_3: 0.9947\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 26/150\n",
      "epoch_end | time:  12.05.2021 05:45:32\n",
      " — val_aps:  0.070621 — val_a: 0.943487\n",
      "2945/2945 - 731s - loss: 0.0034 - accuracy: 0.9893 - auc_3: 0.9994 - precision_3: 0.9893 - recall_3: 0.9893 - val_loss: 0.0193 - val_accuracy: 0.9959 - val_auc_3: 0.9993 - val_precision_3: 0.9959 - val_recall_3: 0.9959\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 27/150\n",
      "epoch_end | time:  12.05.2021 05:57:07\n",
      " — val_aps:  0.073689 — val_a: 0.946161\n",
      "2945/2945 - 696s - loss: 0.0034 - accuracy: 0.9893 - auc_3: 0.9994 - precision_3: 0.9893 - recall_3: 0.9893 - val_loss: 0.0199 - val_accuracy: 0.9957 - val_auc_3: 0.9994 - val_precision_3: 0.9957 - val_recall_3: 0.9957\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 28/150\n",
      "epoch_end | time:  12.05.2021 06:08:51\n",
      " — val_aps:  0.076641 — val_a: 0.948390\n",
      "2945/2945 - 696s - loss: 0.0033 - accuracy: 0.9892 - auc_3: 0.9994 - precision_3: 0.9892 - recall_3: 0.9892 - val_loss: 0.0196 - val_accuracy: 0.9954 - val_auc_3: 0.9992 - val_precision_3: 0.9954 - val_recall_3: 0.9954\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 29/150\n",
      "epoch_end | time:  12.05.2021 06:20:25\n",
      " — val_aps:  0.073132 — val_a: 0.943116\n",
      "2945/2945 - 698s - loss: 0.0033 - accuracy: 0.9895 - auc_3: 0.9995 - precision_3: 0.9895 - recall_3: 0.9895 - val_loss: 0.0219 - val_accuracy: 0.9957 - val_auc_3: 0.9994 - val_precision_3: 0.9957 - val_recall_3: 0.9957\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 30/150\n",
      "epoch_end | time:  12.05.2021 06:32:19\n",
      " — val_aps:  0.072229 — val_a: 0.939828\n",
      "2945/2945 - 728s - loss: 0.0033 - accuracy: 0.9894 - auc_3: 0.9994 - precision_3: 0.9894 - recall_3: 0.9894 - val_loss: 0.0188 - val_accuracy: 0.9960 - val_auc_3: 0.9993 - val_precision_3: 0.9960 - val_recall_3: 0.9960\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 31/150\n",
      "epoch_end | time:  12.05.2021 06:44:15\n",
      " — val_aps:  0.069806 — val_a: 0.942043\n",
      "2945/2945 - 698s - loss: 0.0033 - accuracy: 0.9893 - auc_3: 0.9994 - precision_3: 0.9893 - recall_3: 0.9893 - val_loss: 0.0202 - val_accuracy: 0.9955 - val_auc_3: 0.9993 - val_precision_3: 0.9955 - val_recall_3: 0.9955\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 32/150\n",
      "epoch_end | time:  12.05.2021 06:54:08\n",
      " — val_aps:  0.070768 — val_a: 0.937307\n",
      "2945/2945 - 585s - loss: 0.0032 - accuracy: 0.9893 - auc_3: 0.9995 - precision_3: 0.9893 - recall_3: 0.9893 - val_loss: 0.0185 - val_accuracy: 0.9960 - val_auc_3: 0.9992 - val_precision_3: 0.9960 - val_recall_3: 0.9960\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 33/150\n",
      "epoch_end | time:  12.05.2021 07:03:45\n",
      " — val_aps:  0.073756 — val_a: 0.938616\n",
      "2945/2945 - 576s - loss: 0.0032 - accuracy: 0.9891 - auc_3: 0.9995 - precision_3: 0.9891 - recall_3: 0.9891 - val_loss: 0.0196 - val_accuracy: 0.9958 - val_auc_3: 0.9992 - val_precision_3: 0.9958 - val_recall_3: 0.9958\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 34/150\n",
      "epoch_end | time:  12.05.2021 07:13:05\n",
      " — val_aps:  0.071289 — val_a: 0.938213\n",
      "2945/2945 - 560s - loss: 0.0032 - accuracy: 0.9892 - auc_3: 0.9995 - precision_3: 0.9892 - recall_3: 0.9892 - val_loss: 0.0198 - val_accuracy: 0.9956 - val_auc_3: 0.9991 - val_precision_3: 0.9956 - val_recall_3: 0.9956\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 35/150\n",
      "epoch_end | time:  12.05.2021 07:22:43\n",
      " — val_aps:  0.071534 — val_a: 0.933518\n",
      "2945/2945 - 582s - loss: 0.0032 - accuracy: 0.9890 - auc_3: 0.9995 - precision_3: 0.9890 - recall_3: 0.9890 - val_loss: 0.0195 - val_accuracy: 0.9963 - val_auc_3: 0.9990 - val_precision_3: 0.9963 - val_recall_3: 0.9963\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 36/150\n",
      "epoch_end | time:  12.05.2021 07:32:21\n",
      " — val_aps:  0.065188 — val_a: 0.939250\n",
      "2945/2945 - 575s - loss: 0.0031 - accuracy: 0.9892 - auc_3: 0.9995 - precision_3: 0.9892 - recall_3: 0.9892 - val_loss: 0.0194 - val_accuracy: 0.9955 - val_auc_3: 0.9994 - val_precision_3: 0.9955 - val_recall_3: 0.9955\n",
      "\n",
      "Epoch 00037: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 37/150\n",
      "epoch_end | time:  12.05.2021 07:41:52\n",
      " — val_aps:  0.067144 — val_a: 0.933581\n",
      "2945/2945 - 570s - loss: 0.0031 - accuracy: 0.9893 - auc_3: 0.9995 - precision_3: 0.9893 - recall_3: 0.9893 - val_loss: 0.0202 - val_accuracy: 0.9957 - val_auc_3: 0.9992 - val_precision_3: 0.9957 - val_recall_3: 0.9957\n",
      "\n",
      "Epoch 00038: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 38/150\n",
      "epoch_end | time:  12.05.2021 07:51:16\n",
      " — val_aps:  0.067810 — val_a: 0.935123\n",
      "2945/2945 - 564s - loss: 0.0031 - accuracy: 0.9890 - auc_3: 0.9995 - precision_3: 0.9890 - recall_3: 0.9890 - val_loss: 0.0193 - val_accuracy: 0.9960 - val_auc_3: 0.9992 - val_precision_3: 0.9960 - val_recall_3: 0.9960\n",
      "\n",
      "Epoch 00039: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 39/150\n",
      "epoch_end | time:  12.05.2021 08:00:53\n",
      " — val_aps:  0.070306 — val_a: 0.937885\n",
      "2945/2945 - 576s - loss: 0.0031 - accuracy: 0.9892 - auc_3: 0.9995 - precision_3: 0.9892 - recall_3: 0.9892 - val_loss: 0.0213 - val_accuracy: 0.9955 - val_auc_3: 0.9991 - val_precision_3: 0.9955 - val_recall_3: 0.9955\n",
      "\n",
      "Epoch 00040: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 40/150\n",
      "epoch_end | time:  12.05.2021 08:10:29\n",
      " — val_aps:  0.067743 — val_a: 0.931784\n",
      "2945/2945 - 577s - loss: 0.0031 - accuracy: 0.9895 - auc_3: 0.9995 - precision_3: 0.9895 - recall_3: 0.9895 - val_loss: 0.0202 - val_accuracy: 0.9958 - val_auc_3: 0.9992 - val_precision_3: 0.9958 - val_recall_3: 0.9958\n",
      "\n",
      "Epoch 00041: LearningRateScheduler reducing learning rate to 5.000000000000001e-05.\n",
      "Epoch 41/150\n",
      "epoch_end | time:  12.05.2021 08:19:49\n",
      " — val_aps:  0.067375 — val_a: 0.934710\n",
      "2945/2945 - 559s - loss: 0.0029 - accuracy: 0.9896 - auc_3: 0.9995 - precision_3: 0.9896 - recall_3: 0.9896 - val_loss: 0.0200 - val_accuracy: 0.9960 - val_auc_3: 0.9991 - val_precision_3: 0.9960 - val_recall_3: 0.9960\n",
      "\n",
      "Epoch 00042: LearningRateScheduler reducing learning rate to 5.000000000000001e-05.\n",
      "Epoch 42/150\n",
      "epoch_end | time:  12.05.2021 08:29:29\n",
      " — val_aps:  0.067839 — val_a: 0.934630\n",
      "2945/2945 - 578s - loss: 0.0029 - accuracy: 0.9896 - auc_3: 0.9995 - precision_3: 0.9896 - recall_3: 0.9896 - val_loss: 0.0213 - val_accuracy: 0.9952 - val_auc_3: 0.9991 - val_precision_3: 0.9952 - val_recall_3: 0.9952\n",
      "\n",
      "Epoch 00043: LearningRateScheduler reducing learning rate to 5.000000000000001e-05.\n",
      "Epoch 43/150\n",
      "epoch_end | time:  12.05.2021 08:38:39\n",
      " — val_aps:  0.067260 — val_a: 0.933826\n",
      "2945/2945 - 549s - loss: 0.0029 - accuracy: 0.9897 - auc_3: 0.9995 - precision_3: 0.9897 - recall_3: 0.9897 - val_loss: 0.0214 - val_accuracy: 0.9955 - val_auc_3: 0.9991 - val_precision_3: 0.9955 - val_recall_3: 0.9955\n",
      "\n",
      "Epoch 00044: LearningRateScheduler reducing learning rate to 5.000000000000001e-05.\n",
      "Epoch 44/150\n",
      "epoch_end | time:  12.05.2021 08:48:04\n",
      " — val_aps:  0.068027 — val_a: 0.934054\n",
      "2945/2945 - 568s - loss: 0.0029 - accuracy: 0.9895 - auc_3: 0.9995 - precision_3: 0.9895 - recall_3: 0.9895 - val_loss: 0.0202 - val_accuracy: 0.9958 - val_auc_3: 0.9991 - val_precision_3: 0.9958 - val_recall_3: 0.9958\n",
      "\n",
      "Epoch 00045: LearningRateScheduler reducing learning rate to 5.000000000000001e-05.\n",
      "Epoch 45/150\n",
      "epoch_end | time:  12.05.2021 08:57:35\n",
      " — val_aps:  0.068506 — val_a: 0.933218\n",
      "2945/2945 - 570s - loss: 0.0029 - accuracy: 0.9895 - auc_3: 0.9995 - precision_3: 0.9895 - recall_3: 0.9895 - val_loss: 0.0209 - val_accuracy: 0.9956 - val_auc_3: 0.9991 - val_precision_3: 0.9956 - val_recall_3: 0.9956\n",
      "\n",
      "Epoch 00046: LearningRateScheduler reducing learning rate to 5.000000000000001e-05.\n",
      "Epoch 46/150\n",
      "epoch_end | time:  12.05.2021 09:06:46\n",
      " — val_aps:  0.067894 — val_a: 0.932936\n",
      "2945/2945 - 550s - loss: 0.0029 - accuracy: 0.9895 - auc_3: 0.9995 - precision_3: 0.9895 - recall_3: 0.9895 - val_loss: 0.0222 - val_accuracy: 0.9950 - val_auc_3: 0.9991 - val_precision_3: 0.9950 - val_recall_3: 0.9950\n",
      "\n",
      "Epoch 00047: LearningRateScheduler reducing learning rate to 5.000000000000001e-05.\n",
      "Epoch 47/150\n",
      "epoch_end | time:  12.05.2021 09:16:31\n",
      " — val_aps:  0.068666 — val_a: 0.932158\n",
      "2945/2945 - 586s - loss: 0.0028 - accuracy: 0.9895 - auc_3: 0.9995 - precision_3: 0.9895 - recall_3: 0.9895 - val_loss: 0.0216 - val_accuracy: 0.9953 - val_auc_3: 0.9991 - val_precision_3: 0.9953 - val_recall_3: 0.9953\n",
      "\n",
      "Epoch 00048: LearningRateScheduler reducing learning rate to 5.000000000000001e-05.\n",
      "Epoch 48/150\n",
      "epoch_end | time:  12.05.2021 09:26:00\n",
      " — val_aps:  0.068750 — val_a: 0.932633\n",
      "2945/2945 - 569s - loss: 0.0029 - accuracy: 0.9894 - auc_3: 0.9995 - precision_3: 0.9894 - recall_3: 0.9894 - val_loss: 0.0202 - val_accuracy: 0.9960 - val_auc_3: 0.9990 - val_precision_3: 0.9960 - val_recall_3: 0.9960\n",
      "\n",
      "Epoch 00049: LearningRateScheduler reducing learning rate to 5.000000000000001e-05.\n",
      "Epoch 49/150\n",
      "epoch_end | time:  12.05.2021 09:35:32\n",
      " — val_aps:  0.068207 — val_a: 0.931082\n",
      "2945/2945 - 571s - loss: 0.0029 - accuracy: 0.9895 - auc_3: 0.9995 - precision_3: 0.9895 - recall_3: 0.9895 - val_loss: 0.0213 - val_accuracy: 0.9957 - val_auc_3: 0.9990 - val_precision_3: 0.9957 - val_recall_3: 0.9957\n",
      "\n",
      "Epoch 00050: LearningRateScheduler reducing learning rate to 5.000000000000001e-05.\n",
      "Epoch 50/150\n",
      "epoch_end | time:  12.05.2021 09:45:03\n",
      " — val_aps:  0.067828 — val_a: 0.929583\n",
      "2945/2945 - 571s - loss: 0.0029 - accuracy: 0.9895 - auc_3: 0.9995 - precision_3: 0.9895 - recall_3: 0.9895 - val_loss: 0.0209 - val_accuracy: 0.9960 - val_auc_3: 0.9990 - val_precision_3: 0.9960 - val_recall_3: 0.9960\n",
      "\n",
      "Epoch 00051: LearningRateScheduler reducing learning rate to 5.000000000000001e-05.\n",
      "Epoch 51/150\n",
      "epoch_end | time:  12.05.2021 09:54:51\n",
      " — val_aps:  0.067606 — val_a: 0.930502\n",
      "2945/2945 - 588s - loss: 0.0029 - accuracy: 0.9894 - auc_3: 0.9995 - precision_3: 0.9894 - recall_3: 0.9894 - val_loss: 0.0207 - val_accuracy: 0.9959 - val_auc_3: 0.9990 - val_precision_3: 0.9959 - val_recall_3: 0.9959\n",
      "\n",
      "Epoch 00052: LearningRateScheduler reducing learning rate to 5.000000000000001e-05.\n",
      "Epoch 52/150\n",
      "epoch_end | time:  12.05.2021 10:04:50\n",
      " — val_aps:  0.068209 — val_a: 0.929785\n",
      "2945/2945 - 601s - loss: 0.0029 - accuracy: 0.9895 - auc_3: 0.9995 - precision_3: 0.9895 - recall_3: 0.9895 - val_loss: 0.0204 - val_accuracy: 0.9958 - val_auc_3: 0.9991 - val_precision_3: 0.9958 - val_recall_3: 0.9958\n",
      "model_spider6_internal_wo_btest_5_5_64_1e-05_200512_10 valid_for_train:  0.8595702397685236 0.0682093470453706 | test:  0.8443405519868947 0.07270855752833694\n"
     ]
    }
   ],
   "source": [
    "VERBOSE = 2\n",
    "BATCH_SIZE = 512\n",
    "NB_EPOCH = 150\n",
    "class_weighting = {0:0.05 , 1:1}\n",
    "\n",
    "result_all_8 = pd.DataFrame()\n",
    "result_all_8['name_model'] = None\n",
    "result_all_8['params'] = None\n",
    "result_all_8['val_GINI'] = None\n",
    "result_all_8['val_APS'] = None\n",
    "result_all_8['test_GINI'] = None\n",
    "result_all_8['test_APS'] = None\n",
    "j = 0\n",
    "\n",
    "for p in param:\n",
    "    print('=====================================================================================================')\n",
    "    print(inp_shape, X_2_2.shape, p)\n",
    "    \n",
    "    model_grid = spider_model(gl_pool_max = p[0], reg = p[1],\n",
    "                             n_kernel = p[2], n_filters = p[3], hidden = p[4], drop_out = p[5], drop_out_conv = p[6],\n",
    "                             n_features = inp_shape)\n",
    "\n",
    "    \n",
    "    model_grid.compile(loss='categorical_crossentropy', \n",
    "                 optimizer=tf.keras.optimizers.Adam(learning_rate=0.005),\n",
    "              metrics=['accuracy', tf.keras.metrics.AUC(), tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "    \n",
    "    history_XX = model_grid.fit_generator(generator=training_generator,  #training_aug,\n",
    "                    validation_data= (X_2_2, Y_test_2) , #Y_test_2 = np_utils.to_categorical( y_val, 2) \n",
    "                                     epochs=NB_EPOCH, verbose=VERBOSE, class_weight=class_weighting,\n",
    "                                     callbacks=[_time , EarlyStopping(monitor='val_loss', patience=20),\n",
    "                                               Metrics(valid_data=(X_2_2, Y_test_2))\n",
    "                                               , LearningRateScheduler(lr_step_decay, verbose=1)])\n",
    "    \n",
    "    res_model_ = pd.DataFrame(history_XX.history, columns = history_XX.history.keys())\n",
    "    dd = str(200000 + datetime.now().month*100 + datetime.now().day) + '_' + str(datetime.now().hour)\n",
    "    name_m = 'model_spider6_internal_wo_btest_'  + str(p[2]) + '_' + str(p[3]) + '_' + str(p[4]) + '_' + str(p[1]) + '_' + str(dd)\n",
    "    \n",
    "    model_grid.save( name_m + '.h5')\n",
    "    res_model_.to_csv(name_m + '.csv')\n",
    "    \n",
    "    predict_class_val = model_grid.predict(X_2_2)\n",
    "    APS = metrics.average_precision_score(y_val, predict_class_val[:,1])\n",
    "    GINI = 2*(metrics.roc_auc_score(y_val , predict_class_val[:,1])) - 1\n",
    "\n",
    "    predict_class_test = model_grid.predict(X_3_2)\n",
    "    APS_t = metrics.average_precision_score(y_test, predict_class_test[:,1])\n",
    "    GINI_t = 2*(metrics.roc_auc_score(y_test, predict_class_test[:,1])) - 1\n",
    "    \n",
    "    result_all_8.at[j , 'name_model'] = name_m\n",
    "    result_all_8.at[j ,'params'] = str(p)\n",
    "    result_all_8.at[j ,'val_GINI'] = GINI\n",
    "    result_all_8.at[j ,'val_APS'] = APS\n",
    "    result_all_8.at[j ,'test_GINI'] = GINI_t\n",
    "    result_all_8.at[j ,'test_APS'] = APS_t\n",
    "    \n",
    "    result_all_8.to_csv('internal_spider_wo_btest_6.csv')\n",
    "    j += 1\n",
    "    print(name_m, 'valid_for_train: ', GINI, APS, '| test: ', GINI_t, APS_t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl_p = [True]\n",
    "l2_batch = [0.0001]\n",
    "n_ker = [3]\n",
    "n_fil = [10]\n",
    "d_hidden = [100] \n",
    "drop_out = [ 0.25]\n",
    "drop_out_conv = [0.001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_2 = itertools.product(gl_p, l2_batch, n_ker, n_fil, d_hidden, drop_out, drop_out_conv, reg_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================================================\n",
      "124 (185400, 124) (True, 0.0001, 3, 10, 100, 0.25, 0.001, 1e-05)\n",
      "3 0.081\n",
      "4 0.256\n",
      "train_begin | time:  12.05.2021 10:50:17\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 1/150\n",
      "epoch_end | time:  12.05.2021 11:08:08\n",
      " — val_aps:  0.056843 — val_a: 0.934411\n",
      "2945/2945 - 1092s - loss: 0.0135 - accuracy: 0.9657 - auc_4: 0.9921 - precision_4: 0.9657 - recall_4: 0.9657 - val_loss: 0.0633 - val_accuracy: 0.9842 - val_auc_4: 0.9971 - val_precision_4: 0.9842 - val_recall_4: 0.9842\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 2/150\n",
      "epoch_end | time:  12.05.2021 11:27:04\n",
      " — val_aps:  0.056783 — val_a: 0.941033\n",
      "2945/2945 - 1162s - loss: 0.0073 - accuracy: 0.9836 - auc_4: 0.9967 - precision_4: 0.9836 - recall_4: 0.9836 - val_loss: 0.0609 - val_accuracy: 0.9846 - val_auc_4: 0.9974 - val_precision_4: 0.9846 - val_recall_4: 0.9846\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 3/150\n",
      "epoch_end | time:  12.05.2021 11:48:54\n",
      " — val_aps:  0.045157 — val_a: 0.919385\n",
      "2945/2945 - 1304s - loss: 0.0068 - accuracy: 0.9852 - auc_4: 0.9973 - precision_4: 0.9852 - recall_4: 0.9852 - val_loss: 0.0860 - val_accuracy: 0.9779 - val_auc_4: 0.9949 - val_precision_4: 0.9779 - val_recall_4: 0.9779\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 4/150\n",
      "epoch_end | time:  12.05.2021 12:09:46\n",
      " — val_aps:  0.046666 — val_a: 0.934006\n",
      "2945/2945 - 1259s - loss: 0.0064 - accuracy: 0.9860 - auc_4: 0.9977 - precision_4: 0.9860 - recall_4: 0.9860 - val_loss: 0.1337 - val_accuracy: 0.9590 - val_auc_4: 0.9883 - val_precision_4: 0.9590 - val_recall_4: 0.9590\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 5/150\n",
      "epoch_end | time:  12.05.2021 12:29:16\n",
      " — val_aps:  0.091270 — val_a: 0.955322\n",
      "2945/2945 - 1166s - loss: 0.0063 - accuracy: 0.9869 - auc_4: 0.9979 - precision_4: 0.9869 - recall_4: 0.9869 - val_loss: 0.0351 - val_accuracy: 0.9945 - val_auc_4: 0.9995 - val_precision_4: 0.9945 - val_recall_4: 0.9945\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 6/150\n",
      "epoch_end | time:  12.05.2021 12:48:38\n",
      " — val_aps:  0.056157 — val_a: 0.947773\n",
      "2945/2945 - 1146s - loss: 0.0059 - accuracy: 0.9872 - auc_4: 0.9982 - precision_4: 0.9872 - recall_4: 0.9872 - val_loss: 0.1057 - val_accuracy: 0.9736 - val_auc_4: 0.9938 - val_precision_4: 0.9736 - val_recall_4: 0.9736\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 7/150\n",
      "epoch_end | time:  12.05.2021 13:06:33\n",
      " — val_aps:  0.091664 — val_a: 0.947769\n",
      "2945/2945 - 1076s - loss: 0.0059 - accuracy: 0.9875 - auc_4: 0.9982 - precision_4: 0.9875 - recall_4: 0.9875 - val_loss: 0.0760 - val_accuracy: 0.9786 - val_auc_4: 0.9953 - val_precision_4: 0.9786 - val_recall_4: 0.9786\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 8/150\n",
      "epoch_end | time:  12.05.2021 13:26:24\n",
      " — val_aps:  0.057770 — val_a: 0.946534\n",
      "2945/2945 - 1196s - loss: 0.0059 - accuracy: 0.9872 - auc_4: 0.9982 - precision_4: 0.9872 - recall_4: 0.9872 - val_loss: 0.0993 - val_accuracy: 0.9783 - val_auc_4: 0.9956 - val_precision_4: 0.9783 - val_recall_4: 0.9783\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 9/150\n",
      "epoch_end | time:  12.05.2021 13:48:36\n",
      " — val_aps:  0.081827 — val_a: 0.939052\n",
      "2945/2945 - 1351s - loss: 0.0058 - accuracy: 0.9876 - auc_4: 0.9983 - precision_4: 0.9876 - recall_4: 0.9876 - val_loss: 0.0289 - val_accuracy: 0.9960 - val_auc_4: 0.9996 - val_precision_4: 0.9960 - val_recall_4: 0.9960\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 10/150\n",
      "epoch_end | time:  12.05.2021 14:09:26\n",
      " — val_aps:  0.076119 — val_a: 0.952479\n",
      "2945/2945 - 1233s - loss: 0.0058 - accuracy: 0.9875 - auc_4: 0.9982 - precision_4: 0.9875 - recall_4: 0.9875 - val_loss: 0.0396 - val_accuracy: 0.9902 - val_auc_4: 0.9990 - val_precision_4: 0.9902 - val_recall_4: 0.9902\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 11/150\n",
      "epoch_end | time:  12.05.2021 14:29:50\n",
      " — val_aps:  0.071413 — val_a: 0.943719\n",
      "2945/2945 - 1228s - loss: 0.0057 - accuracy: 0.9881 - auc_4: 0.9984 - precision_4: 0.9881 - recall_4: 0.9881 - val_loss: 0.0366 - val_accuracy: 0.9953 - val_auc_4: 0.9995 - val_precision_4: 0.9953 - val_recall_4: 0.9953\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 12/150\n",
      "epoch_end | time:  12.05.2021 14:50:34\n",
      " — val_aps:  0.080377 — val_a: 0.943423\n",
      "2945/2945 - 1237s - loss: 0.0056 - accuracy: 0.9878 - auc_4: 0.9984 - precision_4: 0.9878 - recall_4: 0.9878 - val_loss: 0.0229 - val_accuracy: 0.9962 - val_auc_4: 0.9991 - val_precision_4: 0.9962 - val_recall_4: 0.9962\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 13/150\n",
      "epoch_end | time:  12.05.2021 15:13:52\n",
      " — val_aps:  0.057463 — val_a: 0.932551\n",
      "2945/2945 - 1400s - loss: 0.0057 - accuracy: 0.9880 - auc_4: 0.9984 - precision_4: 0.9880 - recall_4: 0.9880 - val_loss: 0.0771 - val_accuracy: 0.9900 - val_auc_4: 0.9986 - val_precision_4: 0.9900 - val_recall_4: 0.9900\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 14/150\n",
      "epoch_end | time:  12.05.2021 15:33:33\n",
      " — val_aps:  0.079731 — val_a: 0.940417\n",
      "2945/2945 - 1169s - loss: 0.0056 - accuracy: 0.9877 - auc_4: 0.9984 - precision_4: 0.9877 - recall_4: 0.9877 - val_loss: 0.0281 - val_accuracy: 0.9935 - val_auc_4: 0.9990 - val_precision_4: 0.9935 - val_recall_4: 0.9935\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 15/150\n",
      "epoch_end | time:  12.05.2021 15:52:03\n",
      " — val_aps:  0.061020 — val_a: 0.917645\n",
      "2945/2945 - 1121s - loss: 0.0055 - accuracy: 0.9883 - auc_4: 0.9985 - precision_4: 0.9883 - recall_4: 0.9883 - val_loss: 0.0269 - val_accuracy: 0.9952 - val_auc_4: 0.9994 - val_precision_4: 0.9952 - val_recall_4: 0.9952\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 16/150\n",
      "epoch_end | time:  12.05.2021 16:12:14\n",
      " — val_aps:  0.091673 — val_a: 0.946004\n",
      "2945/2945 - 1217s - loss: 0.0054 - accuracy: 0.9881 - auc_4: 0.9985 - precision_4: 0.9881 - recall_4: 0.9881 - val_loss: 0.0179 - val_accuracy: 0.9967 - val_auc_4: 0.9991 - val_precision_4: 0.9967 - val_recall_4: 0.9967\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 17/150\n",
      "epoch_end | time:  12.05.2021 16:35:11\n",
      " — val_aps:  0.076728 — val_a: 0.920134\n",
      "2945/2945 - 1381s - loss: 0.0054 - accuracy: 0.9882 - auc_4: 0.9985 - precision_4: 0.9882 - recall_4: 0.9882 - val_loss: 0.0222 - val_accuracy: 0.9964 - val_auc_4: 0.9993 - val_precision_4: 0.9964 - val_recall_4: 0.9964\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 18/150\n",
      "epoch_end | time:  12.05.2021 17:00:25\n",
      " — val_aps:  0.060895 — val_a: 0.937911\n",
      "2945/2945 - 1517s - loss: 0.0055 - accuracy: 0.9878 - auc_4: 0.9986 - precision_4: 0.9878 - recall_4: 0.9878 - val_loss: 0.0279 - val_accuracy: 0.9950 - val_auc_4: 0.9995 - val_precision_4: 0.9950 - val_recall_4: 0.9950\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 19/150\n",
      "epoch_end | time:  12.05.2021 17:27:27\n",
      " — val_aps:  0.058778 — val_a: 0.925214\n",
      "2945/2945 - 1652s - loss: 0.0054 - accuracy: 0.9882 - auc_4: 0.9987 - precision_4: 0.9882 - recall_4: 0.9882 - val_loss: 0.0222 - val_accuracy: 0.9965 - val_auc_4: 0.9994 - val_precision_4: 0.9965 - val_recall_4: 0.9965\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 20/150\n",
      "epoch_end | time:  12.05.2021 17:55:06\n",
      " — val_aps:  0.041417 — val_a: 0.930062\n",
      "2945/2945 - 1627s - loss: 0.0055 - accuracy: 0.9881 - auc_4: 0.9986 - precision_4: 0.9881 - recall_4: 0.9881 - val_loss: 0.1024 - val_accuracy: 0.9748 - val_auc_4: 0.9920 - val_precision_4: 0.9748 - val_recall_4: 0.9748\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 21/150\n",
      "epoch_end | time:  12.05.2021 18:22:26\n",
      " — val_aps:  0.087077 — val_a: 0.946655\n",
      "2945/2945 - 1651s - loss: 0.0044 - accuracy: 0.9898 - auc_4: 0.9992 - precision_4: 0.9898 - recall_4: 0.9898 - val_loss: 0.0271 - val_accuracy: 0.9951 - val_auc_4: 0.9995 - val_precision_4: 0.9951 - val_recall_4: 0.9951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 22/150\n",
      "epoch_end | time:  12.05.2021 18:51:29\n",
      " — val_aps:  0.090559 — val_a: 0.949654\n",
      "2945/2945 - 1732s - loss: 0.0041 - accuracy: 0.9897 - auc_4: 0.9993 - precision_4: 0.9897 - recall_4: 0.9897 - val_loss: 0.0214 - val_accuracy: 0.9957 - val_auc_4: 0.9995 - val_precision_4: 0.9957 - val_recall_4: 0.9957\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 23/150\n",
      "epoch_end | time:  12.05.2021 19:19:30\n",
      " — val_aps:  0.091404 — val_a: 0.948689\n",
      "2945/2945 - 1687s - loss: 0.0039 - accuracy: 0.9899 - auc_4: 0.9993 - precision_4: 0.9899 - recall_4: 0.9899 - val_loss: 0.0227 - val_accuracy: 0.9949 - val_auc_4: 0.9995 - val_precision_4: 0.9949 - val_recall_4: 0.9949\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 24/150\n",
      "epoch_end | time:  12.05.2021 19:45:48\n",
      " — val_aps:  0.085042 — val_a: 0.946010\n",
      "2945/2945 - 1580s - loss: 0.0038 - accuracy: 0.9895 - auc_4: 0.9993 - precision_4: 0.9895 - recall_4: 0.9895 - val_loss: 0.0256 - val_accuracy: 0.9955 - val_auc_4: 0.9995 - val_precision_4: 0.9955 - val_recall_4: 0.9955\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 25/150\n",
      "epoch_end | time:  12.05.2021 20:10:53\n",
      " — val_aps:  0.095531 — val_a: 0.949989\n",
      "2945/2945 - 1499s - loss: 0.0036 - accuracy: 0.9894 - auc_4: 0.9994 - precision_4: 0.9894 - recall_4: 0.9894 - val_loss: 0.0213 - val_accuracy: 0.9958 - val_auc_4: 0.9995 - val_precision_4: 0.9958 - val_recall_4: 0.9958\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 26/150\n",
      "epoch_end | time:  12.05.2021 20:35:14\n",
      " — val_aps:  0.088611 — val_a: 0.948796\n",
      "2945/2945 - 1454s - loss: 0.0036 - accuracy: 0.9893 - auc_4: 0.9994 - precision_4: 0.9893 - recall_4: 0.9893 - val_loss: 0.0225 - val_accuracy: 0.9950 - val_auc_4: 0.9995 - val_precision_4: 0.9950 - val_recall_4: 0.9950\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 27/150\n",
      "epoch_end | time:  12.05.2021 20:59:41\n",
      " — val_aps:  0.089612 — val_a: 0.947830\n",
      "2945/2945 - 1467s - loss: 0.0036 - accuracy: 0.9894 - auc_4: 0.9994 - precision_4: 0.9894 - recall_4: 0.9894 - val_loss: 0.0190 - val_accuracy: 0.9958 - val_auc_4: 0.9994 - val_precision_4: 0.9958 - val_recall_4: 0.9958\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 28/150\n",
      "epoch_end | time:  12.05.2021 21:23:17\n",
      " — val_aps:  0.085875 — val_a: 0.945209\n",
      "2945/2945 - 1416s - loss: 0.0035 - accuracy: 0.9893 - auc_4: 0.9994 - precision_4: 0.9893 - recall_4: 0.9893 - val_loss: 0.0244 - val_accuracy: 0.9947 - val_auc_4: 0.9994 - val_precision_4: 0.9947 - val_recall_4: 0.9947\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 29/150\n",
      "epoch_end | time:  12.05.2021 21:47:37\n",
      " — val_aps:  0.084122 — val_a: 0.936480\n",
      "2945/2945 - 1468s - loss: 0.0034 - accuracy: 0.9893 - auc_4: 0.9994 - precision_4: 0.9893 - recall_4: 0.9893 - val_loss: 0.0204 - val_accuracy: 0.9962 - val_auc_4: 0.9993 - val_precision_4: 0.9962 - val_recall_4: 0.9962\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 30/150\n",
      "epoch_end | time:  12.05.2021 22:11:40\n",
      " — val_aps:  0.083835 — val_a: 0.945445\n",
      "2945/2945 - 1427s - loss: 0.0034 - accuracy: 0.9893 - auc_4: 0.9994 - precision_4: 0.9893 - recall_4: 0.9893 - val_loss: 0.0200 - val_accuracy: 0.9958 - val_auc_4: 0.9994 - val_precision_4: 0.9958 - val_recall_4: 0.9958\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 31/150\n",
      "epoch_end | time:  12.05.2021 22:33:55\n",
      " — val_aps:  0.084504 — val_a: 0.946605\n",
      "2945/2945 - 1325s - loss: 0.0034 - accuracy: 0.9891 - auc_4: 0.9994 - precision_4: 0.9891 - recall_4: 0.9891 - val_loss: 0.0229 - val_accuracy: 0.9949 - val_auc_4: 0.9994 - val_precision_4: 0.9949 - val_recall_4: 0.9949\n",
      "\n",
      "Epoch 00032: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 32/150\n",
      "epoch_end | time:  12.05.2021 22:55:29\n",
      " — val_aps:  0.090722 — val_a: 0.945831\n",
      "2945/2945 - 1302s - loss: 0.0033 - accuracy: 0.9892 - auc_4: 0.9994 - precision_4: 0.9892 - recall_4: 0.9892 - val_loss: 0.0216 - val_accuracy: 0.9952 - val_auc_4: 0.9994 - val_precision_4: 0.9952 - val_recall_4: 0.9952\n",
      "\n",
      "Epoch 00033: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 33/150\n",
      "epoch_end | time:  12.05.2021 23:18:25\n",
      " — val_aps:  0.081677 — val_a: 0.948086\n",
      "2945/2945 - 1367s - loss: 0.0033 - accuracy: 0.9892 - auc_4: 0.9994 - precision_4: 0.9892 - recall_4: 0.9892 - val_loss: 0.0234 - val_accuracy: 0.9948 - val_auc_4: 0.9993 - val_precision_4: 0.9948 - val_recall_4: 0.9948\n",
      "\n",
      "Epoch 00034: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 34/150\n",
      "epoch_end | time:  12.05.2021 23:41:37\n",
      " — val_aps:  0.086222 — val_a: 0.949392\n",
      "2945/2945 - 1397s - loss: 0.0033 - accuracy: 0.9894 - auc_4: 0.9994 - precision_4: 0.9894 - recall_4: 0.9894 - val_loss: 0.0195 - val_accuracy: 0.9956 - val_auc_4: 0.9993 - val_precision_4: 0.9956 - val_recall_4: 0.9956\n",
      "\n",
      "Epoch 00035: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 35/150\n",
      "epoch_end | time:  13.05.2021 00:05:10\n",
      " — val_aps:  0.087891 — val_a: 0.943786\n",
      "2945/2945 - 1416s - loss: 0.0032 - accuracy: 0.9893 - auc_4: 0.9994 - precision_4: 0.9893 - recall_4: 0.9893 - val_loss: 0.0217 - val_accuracy: 0.9957 - val_auc_4: 0.9993 - val_precision_4: 0.9957 - val_recall_4: 0.9957\n",
      "\n",
      "Epoch 00036: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 36/150\n",
      "epoch_end | time:  13.05.2021 00:29:08\n",
      " — val_aps:  0.078565 — val_a: 0.946944\n",
      "2945/2945 - 1435s - loss: 0.0032 - accuracy: 0.9892 - auc_4: 0.9994 - precision_4: 0.9892 - recall_4: 0.9892 - val_loss: 0.0225 - val_accuracy: 0.9945 - val_auc_4: 0.9994 - val_precision_4: 0.9945 - val_recall_4: 0.9945\n",
      "RIGHT_model_spider6_internal_wo_btest_3_10_100_0.0001_200513_0 valid_for_train:  0.8938881362510953 0.07856495914488337 | test:  0.894675505319362 0.06898398404187274\n"
     ]
    }
   ],
   "source": [
    "VERBOSE = 2\n",
    "BATCH_SIZE = 512\n",
    "NB_EPOCH = 150\n",
    "class_weighting = {0:0.05 , 1:1}\n",
    "\n",
    "result_all_8 = pd.DataFrame()\n",
    "result_all_8['name_model'] = None\n",
    "result_all_8['params'] = None\n",
    "result_all_8['val_GINI'] = None\n",
    "result_all_8['val_APS'] = None\n",
    "result_all_8['test_GINI'] = None\n",
    "result_all_8['test_APS'] = None\n",
    "j = 0\n",
    "\n",
    "for p in param_2:\n",
    "    print('=====================================================================================================')\n",
    "    print(inp_shape, X_2_2.shape, p)\n",
    "    \n",
    "    model_grid = spider_model(gl_pool_max = p[0], reg = p[1],\n",
    "                             n_kernel = p[2], n_filters = p[3], hidden = p[4], drop_out = p[5], drop_out_conv = p[6],\n",
    "                             n_features = inp_shape)\n",
    "\n",
    "    \n",
    "    model_grid.compile(loss='categorical_crossentropy', \n",
    "                 optimizer=tf.keras.optimizers.Adam(learning_rate=0.005),\n",
    "              metrics=['accuracy', tf.keras.metrics.AUC(), tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "    \n",
    "    history_XX = model_grid.fit_generator(generator=training_generator,  #training_aug,\n",
    "                    validation_data= (X_2_2, Y_test_2) , #Y_test_2 = np_utils.to_categorical( y_val, 2) \n",
    "                                     epochs=NB_EPOCH, verbose=VERBOSE, class_weight=class_weighting,\n",
    "                                     callbacks=[_time , EarlyStopping(monitor='val_loss', patience=20),\n",
    "                                               Metrics(valid_data=(X_2_2, Y_test_2))\n",
    "                                               , LearningRateScheduler(lr_step_decay, verbose=1)])\n",
    "    \n",
    "    res_model_ = pd.DataFrame(history_XX.history, columns = history_XX.history.keys())\n",
    "    dd = str(200000 + datetime.now().month*100 + datetime.now().day) + '_' + str(datetime.now().hour)\n",
    "    name_m = 'RIGHT_model_spider6_internal_wo_btest_'  + str(p[2]) + '_' + str(p[3]) + '_' + str(p[4]) + '_' + str(p[1]) + '_' + str(dd)\n",
    "    \n",
    "    model_grid.save( name_m + '.h5')\n",
    "    res_model_.to_csv(name_m + '.csv')\n",
    "    \n",
    "    predict_class_val = model_grid.predict(X_2_2)\n",
    "    APS = metrics.average_precision_score(y_val, predict_class_val[:,1])\n",
    "    GINI = 2*(metrics.roc_auc_score(y_val , predict_class_val[:,1])) - 1\n",
    "\n",
    "    predict_class_test = model_grid.predict(X_3_2)\n",
    "    APS_t = metrics.average_precision_score(y_test, predict_class_test[:,1])\n",
    "    GINI_t = 2*(metrics.roc_auc_score(y_test, predict_class_test[:,1])) - 1\n",
    "    \n",
    "    result_all_8.at[j , 'name_model'] = name_m\n",
    "    result_all_8.at[j ,'params'] = str(p)\n",
    "    result_all_8.at[j ,'val_GINI'] = GINI\n",
    "    result_all_8.at[j ,'val_APS'] = APS\n",
    "    result_all_8.at[j ,'test_GINI'] = GINI_t\n",
    "    result_all_8.at[j ,'test_APS'] = APS_t\n",
    "    \n",
    "    result_all_8.to_csv('RIGHT_internal_spider_wo_btest_6.csv')\n",
    "    j += 1\n",
    "    print(name_m, 'valid_for_train: ', GINI, APS, '| test: ', GINI_t, APS_t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_spider6_gridTrue_None_7_10_30.h5 - лучшая модель по Profit-метрике!!!\n",
    "gl_p = [True]\n",
    "l2_batch = [None]\n",
    "n_ker = [7]\n",
    "n_fil = [10]\n",
    "d_hidden = [30] \n",
    "drop_out = [ 0.25]\n",
    "drop_out_conv = [0.001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_2 = itertools.product(gl_p, l2_batch, n_ker, n_fil, d_hidden, drop_out, drop_out_conv, reg_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================================================\n",
      "124 (185400, 124) (True, None, 7, 10, 30, 0.25, 0.001, 1e-05)\n",
      "3 0.081\n",
      "4 0.256\n",
      "train_begin | time:  13.05.2021 10:56:09\n",
      "\n",
      "Epoch 00001: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 1/150\n",
      "epoch_end | time:  13.05.2021 11:26:05\n",
      " — val_aps:  0.058550 — val_a: 0.946347\n",
      "2945/2945 - 1857s - loss: 0.0101 - accuracy: 0.9669 - auc_5: 0.9926 - precision_5: 0.9669 - recall_5: 0.9669 - val_loss: 0.0475 - val_accuracy: 0.9932 - val_auc_5: 0.9991 - val_precision_5: 0.9932 - val_recall_5: 0.9932\n",
      "\n",
      "Epoch 00002: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 2/150\n",
      "epoch_end | time:  13.05.2021 11:51:44\n",
      " — val_aps:  0.065242 — val_a: 0.946175\n",
      "2945/2945 - 1515s - loss: 0.0058 - accuracy: 0.9883 - auc_5: 0.9978 - precision_5: 0.9883 - recall_5: 0.9883 - val_loss: 0.0479 - val_accuracy: 0.9927 - val_auc_5: 0.9992 - val_precision_5: 0.9927 - val_recall_5: 0.9927\n",
      "\n",
      "Epoch 00003: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 3/150\n",
      "epoch_end | time:  13.05.2021 12:15:37\n",
      " — val_aps:  0.066429 — val_a: 0.947081\n",
      "2945/2945 - 1425s - loss: 0.0052 - accuracy: 0.9882 - auc_5: 0.9983 - precision_5: 0.9882 - recall_5: 0.9882 - val_loss: 0.0243 - val_accuracy: 0.9937 - val_auc_5: 0.9993 - val_precision_5: 0.9937 - val_recall_5: 0.9937\n",
      "\n",
      "Epoch 00004: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 4/150\n",
      "epoch_end | time:  13.05.2021 12:40:35\n",
      " — val_aps:  0.070634 — val_a: 0.939898\n",
      "2945/2945 - 1501s - loss: 0.0047 - accuracy: 0.9884 - auc_5: 0.9987 - precision_5: 0.9884 - recall_5: 0.9884 - val_loss: 0.0282 - val_accuracy: 0.9948 - val_auc_5: 0.9995 - val_precision_5: 0.9948 - val_recall_5: 0.9948\n",
      "\n",
      "Epoch 00005: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 5/150\n",
      "epoch_end | time:  13.05.2021 13:03:01\n",
      " — val_aps:  0.090146 — val_a: 0.947705\n",
      "2945/2945 - 1337s - loss: 0.0045 - accuracy: 0.9884 - auc_5: 0.9988 - precision_5: 0.9884 - recall_5: 0.9884 - val_loss: 0.0335 - val_accuracy: 0.9913 - val_auc_5: 0.9994 - val_precision_5: 0.9913 - val_recall_5: 0.9913\n",
      "\n",
      "Epoch 00006: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 6/150\n",
      "epoch_end | time:  13.05.2021 13:25:44\n",
      " — val_aps:  0.066803 — val_a: 0.944666\n",
      "2945/2945 - 1363s - loss: 0.0042 - accuracy: 0.9880 - auc_5: 0.9990 - precision_5: 0.9880 - recall_5: 0.9880 - val_loss: 0.0233 - val_accuracy: 0.9948 - val_auc_5: 0.9994 - val_precision_5: 0.9948 - val_recall_5: 0.9948\n",
      "\n",
      "Epoch 00007: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 7/150\n",
      "epoch_end | time:  13.05.2021 13:48:45\n",
      " — val_aps:  0.064735 — val_a: 0.946795\n",
      "2945/2945 - 1387s - loss: 0.0041 - accuracy: 0.9879 - auc_5: 0.9990 - precision_5: 0.9879 - recall_5: 0.9879 - val_loss: 0.0233 - val_accuracy: 0.9939 - val_auc_5: 0.9993 - val_precision_5: 0.9939 - val_recall_5: 0.9939\n",
      "\n",
      "Epoch 00008: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 8/150\n",
      "epoch_end | time:  13.05.2021 14:11:53\n",
      " — val_aps:  0.079909 — val_a: 0.946117\n",
      "2945/2945 - 1386s - loss: 0.0039 - accuracy: 0.9882 - auc_5: 0.9991 - precision_5: 0.9882 - recall_5: 0.9882 - val_loss: 0.0208 - val_accuracy: 0.9960 - val_auc_5: 0.9996 - val_precision_5: 0.9960 - val_recall_5: 0.9960\n",
      "\n",
      "Epoch 00009: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 9/150\n",
      "epoch_end | time:  13.05.2021 14:36:47\n",
      " — val_aps:  0.074376 — val_a: 0.949072\n",
      "2945/2945 - 1505s - loss: 0.0037 - accuracy: 0.9877 - auc_5: 0.9991 - precision_5: 0.9877 - recall_5: 0.9877 - val_loss: 0.0215 - val_accuracy: 0.9946 - val_auc_5: 0.9989 - val_precision_5: 0.9946 - val_recall_5: 0.9946\n",
      "\n",
      "Epoch 00010: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 10/150\n",
      "epoch_end | time:  13.05.2021 15:04:13\n",
      " — val_aps:  0.055343 — val_a: 0.934276\n",
      "2945/2945 - 1669s - loss: 0.0036 - accuracy: 0.9882 - auc_5: 0.9992 - precision_5: 0.9882 - recall_5: 0.9882 - val_loss: 0.0243 - val_accuracy: 0.9949 - val_auc_5: 0.9992 - val_precision_5: 0.9949 - val_recall_5: 0.9949\n",
      "\n",
      "Epoch 00011: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 11/150\n",
      "epoch_end | time:  13.05.2021 15:33:11\n",
      " — val_aps:  0.078474 — val_a: 0.943745\n",
      "2945/2945 - 1706s - loss: 0.0035 - accuracy: 0.9880 - auc_5: 0.9992 - precision_5: 0.9880 - recall_5: 0.9880 - val_loss: 0.0205 - val_accuracy: 0.9947 - val_auc_5: 0.9993 - val_precision_5: 0.9947 - val_recall_5: 0.9947\n",
      "\n",
      "Epoch 00012: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 12/150\n",
      "epoch_end | time:  13.05.2021 16:04:05\n",
      " — val_aps:  0.066743 — val_a: 0.945051\n",
      "2945/2945 - 1873s - loss: 0.0034 - accuracy: 0.9888 - auc_5: 0.9993 - precision_5: 0.9888 - recall_5: 0.9888 - val_loss: 0.0226 - val_accuracy: 0.9955 - val_auc_5: 0.9995 - val_precision_5: 0.9955 - val_recall_5: 0.9955\n",
      "\n",
      "Epoch 00013: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 13/150\n",
      "epoch_end | time:  13.05.2021 16:33:32\n",
      " — val_aps:  0.061185 — val_a: 0.939070\n",
      "2945/2945 - 1745s - loss: 0.0032 - accuracy: 0.9888 - auc_5: 0.9993 - precision_5: 0.9888 - recall_5: 0.9888 - val_loss: 0.0275 - val_accuracy: 0.9929 - val_auc_5: 0.9988 - val_precision_5: 0.9929 - val_recall_5: 0.9929\n",
      "\n",
      "Epoch 00014: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 14/150\n",
      "epoch_end | time:  13.05.2021 17:00:21\n",
      " — val_aps:  0.054965 — val_a: 0.941415\n",
      "2945/2945 - 1620s - loss: 0.0033 - accuracy: 0.9895 - auc_5: 0.9992 - precision_5: 0.9895 - recall_5: 0.9895 - val_loss: 0.0362 - val_accuracy: 0.9913 - val_auc_5: 0.9989 - val_precision_5: 0.9913 - val_recall_5: 0.9913\n",
      "\n",
      "Epoch 00015: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 15/150\n",
      "epoch_end | time:  13.05.2021 17:28:48\n",
      " — val_aps:  0.069565 — val_a: 0.910726\n",
      "2945/2945 - 1714s - loss: 0.0030 - accuracy: 0.9895 - auc_5: 0.9993 - precision_5: 0.9895 - recall_5: 0.9895 - val_loss: 0.0381 - val_accuracy: 0.9952 - val_auc_5: 0.9992 - val_precision_5: 0.9952 - val_recall_5: 0.9952\n",
      "\n",
      "Epoch 00016: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 16/150\n",
      "epoch_end | time:  13.05.2021 17:57:24\n",
      " — val_aps:  0.073103 — val_a: 0.937626\n",
      "2945/2945 - 1708s - loss: 0.0030 - accuracy: 0.9899 - auc_5: 0.9994 - precision_5: 0.9899 - recall_5: 0.9899 - val_loss: 0.0211 - val_accuracy: 0.9952 - val_auc_5: 0.9992 - val_precision_5: 0.9952 - val_recall_5: 0.9952\n",
      "\n",
      "Epoch 00017: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 17/150\n",
      "epoch_end | time:  13.05.2021 18:27:56\n",
      " — val_aps:  0.066671 — val_a: 0.938025\n",
      "2945/2945 - 1831s - loss: 0.0031 - accuracy: 0.9895 - auc_5: 0.9993 - precision_5: 0.9895 - recall_5: 0.9895 - val_loss: 0.0245 - val_accuracy: 0.9937 - val_auc_5: 0.9991 - val_precision_5: 0.9937 - val_recall_5: 0.9937\n",
      "\n",
      "Epoch 00018: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 18/150\n",
      "epoch_end | time:  13.05.2021 18:59:21\n",
      " — val_aps:  0.064237 — val_a: 0.924102\n",
      "2945/2945 - 1895s - loss: 0.0028 - accuracy: 0.9899 - auc_5: 0.9994 - precision_5: 0.9899 - recall_5: 0.9899 - val_loss: 0.0276 - val_accuracy: 0.9939 - val_auc_5: 0.9990 - val_precision_5: 0.9939 - val_recall_5: 0.9939\n",
      "\n",
      "Epoch 00019: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 19/150\n",
      "epoch_end | time:  13.05.2021 19:30:32\n",
      " — val_aps:  0.073504 — val_a: 0.915027\n",
      "2945/2945 - 1869s - loss: 0.0029 - accuracy: 0.9895 - auc_5: 0.9994 - precision_5: 0.9895 - recall_5: 0.9895 - val_loss: 0.0291 - val_accuracy: 0.9946 - val_auc_5: 0.9986 - val_precision_5: 0.9946 - val_recall_5: 0.9946\n",
      "\n",
      "Epoch 00020: LearningRateScheduler reducing learning rate to 0.005.\n",
      "Epoch 20/150\n",
      "epoch_end | time:  13.05.2021 20:00:02\n",
      " — val_aps:  0.059769 — val_a: 0.932839\n",
      "2945/2945 - 1765s - loss: 0.0027 - accuracy: 0.9891 - auc_5: 0.9994 - precision_5: 0.9891 - recall_5: 0.9891 - val_loss: 0.0237 - val_accuracy: 0.9936 - val_auc_5: 0.9993 - val_precision_5: 0.9936 - val_recall_5: 0.9936\n",
      "\n",
      "Epoch 00021: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 21/150\n",
      "epoch_end | time:  13.05.2021 20:28:59\n",
      " — val_aps:  0.075824 — val_a: 0.931352\n",
      "2945/2945 - 1737s - loss: 0.0022 - accuracy: 0.9900 - auc_5: 0.9996 - precision_5: 0.9900 - recall_5: 0.9900 - val_loss: 0.0259 - val_accuracy: 0.9951 - val_auc_5: 0.9986 - val_precision_5: 0.9951 - val_recall_5: 0.9951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00022: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 22/150\n",
      "epoch_end | time:  13.05.2021 20:57:54\n",
      " — val_aps:  0.069421 — val_a: 0.928581\n",
      "2945/2945 - 1738s - loss: 0.0019 - accuracy: 0.9916 - auc_5: 0.9997 - precision_5: 0.9916 - recall_5: 0.9916 - val_loss: 0.0268 - val_accuracy: 0.9956 - val_auc_5: 0.9985 - val_precision_5: 0.9956 - val_recall_5: 0.9956\n",
      "\n",
      "Epoch 00023: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 23/150\n",
      "epoch_end | time:  13.05.2021 21:26:45\n",
      " — val_aps:  0.068958 — val_a: 0.922025\n",
      "2945/2945 - 1725s - loss: 0.0018 - accuracy: 0.9917 - auc_5: 0.9997 - precision_5: 0.9917 - recall_5: 0.9917 - val_loss: 0.0292 - val_accuracy: 0.9962 - val_auc_5: 0.9983 - val_precision_5: 0.9962 - val_recall_5: 0.9962\n",
      "\n",
      "Epoch 00024: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 24/150\n",
      "epoch_end | time:  13.05.2021 21:55:45\n",
      " — val_aps:  0.071576 — val_a: 0.922451\n",
      "2945/2945 - 1742s - loss: 0.0017 - accuracy: 0.9921 - auc_5: 0.9997 - precision_5: 0.9921 - recall_5: 0.9921 - val_loss: 0.0348 - val_accuracy: 0.9954 - val_auc_5: 0.9983 - val_precision_5: 0.9954 - val_recall_5: 0.9954\n",
      "\n",
      "Epoch 00025: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 25/150\n",
      "epoch_end | time:  13.05.2021 22:24:09\n",
      " — val_aps:  0.064527 — val_a: 0.911363\n",
      "2945/2945 - 1710s - loss: 0.0016 - accuracy: 0.9924 - auc_5: 0.9998 - precision_5: 0.9924 - recall_5: 0.9924 - val_loss: 0.0490 - val_accuracy: 0.9956 - val_auc_5: 0.9981 - val_precision_5: 0.9956 - val_recall_5: 0.9956\n",
      "\n",
      "Epoch 00026: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 26/150\n",
      "epoch_end | time:  13.05.2021 22:52:59\n",
      " — val_aps:  0.067290 — val_a: 0.922276\n",
      "2945/2945 - 1725s - loss: 0.0016 - accuracy: 0.9926 - auc_5: 0.9998 - precision_5: 0.9926 - recall_5: 0.9926 - val_loss: 0.0512 - val_accuracy: 0.9959 - val_auc_5: 0.9981 - val_precision_5: 0.9959 - val_recall_5: 0.9959\n",
      "\n",
      "Epoch 00027: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 27/150\n",
      "epoch_end | time:  13.05.2021 23:21:05\n",
      " — val_aps:  0.064120 — val_a: 0.915551\n",
      "2945/2945 - 1674s - loss: 0.0015 - accuracy: 0.9931 - auc_5: 0.9998 - precision_5: 0.9931 - recall_5: 0.9931 - val_loss: 0.0515 - val_accuracy: 0.9958 - val_auc_5: 0.9981 - val_precision_5: 0.9958 - val_recall_5: 0.9958\n",
      "\n",
      "Epoch 00028: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 28/150\n",
      "epoch_end | time:  13.05.2021 23:49:34\n",
      " — val_aps:  0.060550 — val_a: 0.918099\n",
      "2945/2945 - 1719s - loss: 0.0015 - accuracy: 0.9931 - auc_5: 0.9998 - precision_5: 0.9931 - recall_5: 0.9931 - val_loss: 0.0489 - val_accuracy: 0.9956 - val_auc_5: 0.9981 - val_precision_5: 0.9956 - val_recall_5: 0.9956\n",
      "\n",
      "Epoch 00029: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 29/150\n",
      "epoch_end | time:  14.05.2021 00:17:44\n",
      " — val_aps:  0.060590 — val_a: 0.914602\n",
      "2945/2945 - 1696s - loss: 0.0014 - accuracy: 0.9935 - auc_5: 0.9998 - precision_5: 0.9935 - recall_5: 0.9935 - val_loss: 0.0505 - val_accuracy: 0.9957 - val_auc_5: 0.9980 - val_precision_5: 0.9957 - val_recall_5: 0.9957\n",
      "\n",
      "Epoch 00030: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 30/150\n",
      "epoch_end | time:  14.05.2021 00:47:55\n",
      " — val_aps:  0.058929 — val_a: 0.909005\n",
      "2945/2945 - 1800s - loss: 0.0014 - accuracy: 0.9935 - auc_5: 0.9998 - precision_5: 0.9935 - recall_5: 0.9935 - val_loss: 0.0619 - val_accuracy: 0.9960 - val_auc_5: 0.9979 - val_precision_5: 0.9960 - val_recall_5: 0.9960\n",
      "\n",
      "Epoch 00031: LearningRateScheduler reducing learning rate to 0.0005.\n",
      "Epoch 31/150\n",
      "epoch_end | time:  14.05.2021 01:17:44\n",
      " — val_aps:  0.062253 — val_a: 0.914238\n",
      "2945/2945 - 1795s - loss: 0.0014 - accuracy: 0.9934 - auc_5: 0.9998 - precision_5: 0.9934 - recall_5: 0.9934 - val_loss: 0.0548 - val_accuracy: 0.9953 - val_auc_5: 0.9980 - val_precision_5: 0.9953 - val_recall_5: 0.9953\n",
      "RIGHT_model_spider6_internal_wo_btest_7_10_30_None_200514_1 valid_for_train:  0.8284755850128498 0.06225322439810226 | test:  0.8544598330365938 0.055045162027232655\n"
     ]
    }
   ],
   "source": [
    "VERBOSE = 2\n",
    "BATCH_SIZE = 512\n",
    "NB_EPOCH = 150\n",
    "class_weighting = {0:0.05 , 1:1}\n",
    "\n",
    "result_all_8 = pd.DataFrame()\n",
    "result_all_8['name_model'] = None\n",
    "result_all_8['params'] = None\n",
    "result_all_8['val_GINI'] = None\n",
    "result_all_8['val_APS'] = None\n",
    "result_all_8['test_GINI'] = None\n",
    "result_all_8['test_APS'] = None\n",
    "j = 0\n",
    "\n",
    "for p in param_2:\n",
    "    print('=====================================================================================================')\n",
    "    print(inp_shape, X_2_2.shape, p)\n",
    "    \n",
    "    model_grid = spider_model(gl_pool_max = p[0], reg = p[1],\n",
    "                             n_kernel = p[2], n_filters = p[3], hidden = p[4], drop_out = p[5], drop_out_conv = p[6],\n",
    "                             n_features = inp_shape)\n",
    "\n",
    "    \n",
    "    model_grid.compile(loss='categorical_crossentropy', \n",
    "                 optimizer=tf.keras.optimizers.Adam(learning_rate=0.005),\n",
    "              metrics=['accuracy', tf.keras.metrics.AUC(), tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])\n",
    "    \n",
    "    history_XX = model_grid.fit_generator(generator=training_generator,  #training_aug,\n",
    "                    validation_data= (X_2_2, Y_test_2) , #Y_test_2 = np_utils.to_categorical( y_val, 2) \n",
    "                                     epochs=NB_EPOCH, verbose=VERBOSE, class_weight=class_weighting,\n",
    "                                     callbacks=[_time , EarlyStopping(monitor='val_loss', patience=20),\n",
    "                                               Metrics(valid_data=(X_2_2, Y_test_2))\n",
    "                                               , LearningRateScheduler(lr_step_decay, verbose=1)])\n",
    "    \n",
    "    res_model_ = pd.DataFrame(history_XX.history, columns = history_XX.history.keys())\n",
    "    dd = str(200000 + datetime.now().month*100 + datetime.now().day) + '_' + str(datetime.now().hour)\n",
    "    name_m = 'RIGHT_model_spider6_internal_wo_btest_'  + str(p[2]) + '_' + str(p[3]) + '_' + str(p[4]) + '_' + str(p[1]) + '_' + str(dd)\n",
    "    \n",
    "    model_grid.save( name_m + '.h5')\n",
    "    res_model_.to_csv(name_m + '.csv')\n",
    "    \n",
    "    predict_class_val = model_grid.predict(X_2_2)\n",
    "    APS = metrics.average_precision_score(y_val, predict_class_val[:,1])\n",
    "    GINI = 2*(metrics.roc_auc_score(y_val , predict_class_val[:,1])) - 1\n",
    "\n",
    "    predict_class_test = model_grid.predict(X_3_2)\n",
    "    APS_t = metrics.average_precision_score(y_test, predict_class_test[:,1])\n",
    "    GINI_t = 2*(metrics.roc_auc_score(y_test, predict_class_test[:,1])) - 1\n",
    "    \n",
    "    result_all_8.at[j , 'name_model'] = name_m\n",
    "    result_all_8.at[j ,'params'] = str(p)\n",
    "    result_all_8.at[j ,'val_GINI'] = GINI\n",
    "    result_all_8.at[j ,'val_APS'] = APS\n",
    "    result_all_8.at[j ,'test_GINI'] = GINI_t\n",
    "    result_all_8.at[j ,'test_APS'] = APS_t\n",
    "    \n",
    "    result_all_8.to_csv('RIGHT_internal_spider_wo_btest_6.csv')\n",
    "    j += 1\n",
    "    print(name_m, 'valid_for_train: ', GINI, APS, '| test: ', GINI_t, APS_t) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
